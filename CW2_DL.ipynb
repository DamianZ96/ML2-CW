{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CM50265 Machine Learning 2\n",
    "\n",
    "## Coursework 2: Deep learning\n",
    "### Youssef Alami Mejjati, Jordan Taylor, Jake Deane and Mohammad Golbabaee\n",
    "\n",
    "\n",
    "This coursework is worth 75 points from the overall mark of 100 for this unit. Marks are given beside each task. The report will be your main method of assessment. __Students should form groups of 3 individuals and submit one report per group.__ For this coursework students can choose their partners until __20th February__.  Each group will receive a total mark for this course work and individuals in that group will share this mark (with weights) according to their contributions.  \n",
    "\n",
    "- The __submission deadline__ for your report is\n",
    "__17th May 2020, 12:00: online Moodle submission of your final report__\n",
    "\n",
    "The main part of your report should not exceed __3000 word limit__. After the main part please attach a Table of individuals’ contributions and appendices including ONLY the codes (these are excluded from the word limit). The report should be submitted in PDF format. __Table of contributions__ should include both students’ names/university IDs, the list of contributions of each student, and finally the contribution percentage for each student. This percentage should be agreed between both individuals and it will be used to weigh their marks. We highly encourage individuals to evenly share the workload. Further, you should __include all codes__ relevant to your implementations as an appendix or appendices with a clear referencing to the main body of your report. Codes must be well commented (indicating major steps).\n",
    "\n",
    "First and foremost your report should demonstrate and evaluate your results. It must include figures and screenshots with appropriate resolutions. Evaluation can be qualitative (how it looks) and, wherever possible, quantitative (tested numerically). Second you should provide evidence that you understood the mathematics behind the assignment in each task/question. You should concisely explain your approach to solve each task/question, and the choices you make (e.g. hyper-parameters etc) for each part.\n",
    "\n",
    "Usual university rules apply, please check your MSc program handbook, particularly regarding plagiarism and delayed deliveries. \n",
    "\n",
    "__Note:__ All tasks should be implemented in TensorFlow. Guidelines below (tasks 3-5, 7) should work for a TensorFlow version 1. If you use TF v2 please note that some syntaxes have changed during the recent update, but you can still use version compatiblity to resolve the issue. The list includes but might not be limited to:\n",
    "\n",
    "tf.layers.conv2d -> tf.nn.conv2d\n",
    "\n",
    "tf.layers.dense -> tf.nn.dense\n",
    "\n",
    "tf.layers.flatten -> tf.compat.v1.layers.flatten\n",
    "\n",
    "tf.variable_scope -> tf.compat.v1.variable_scope\n",
    "\n",
    "tf.get_collection -> tf.compat.v1.get_collection\n",
    "\n",
    "similarly for tf.compat.v1.InteractiveSession, tf.compat.v1.train.AdamOptimizer, tf.compat.v1.placeholder, tf.compat.v1.global_variables_initializer, tf.compat.v1.local_variables_initializer, tf.compat.v1.train.Saver, tf.compat.v1.summary.FileWriter, tf.compat.v1.trainable_variables\n",
    "\n",
    "See TF web documentation in case you encounter version incompatibility. \n",
    "\n",
    "Guides on tasks 6 and 8 should be already compatible with TF2. \n",
    "\n",
    "\n",
    "## The coursework \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf # This may laod Tensorflow 2.0.0 if that is the verison of the package on your distribution\n",
    "#use import tensorflow.compat.v1 as tf for tensorflow 1\n",
    "# tf.disable_v2_behaviour() # Only needed if using tensorflow 1 with tensorflow 2 being the package avlaiable  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from IPython.display import Image\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "n_train = x_train.shape[0]\n",
    "n_test = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scale the data to be in $[-1,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 127.5 - 1, x_test / 127.5 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of each data points is $28 \\times 28$. While this format will be useful when using CNNs, we will vectorize the datapoints for visualization and preliminary questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "[[-1. -1. -1. ... -1. -1. -1.]\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " ...\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " [-1. -1. -1. ... -1. -1. -1.]]\n",
      "1.0\n",
      "[5 0 4 ... 5 6 8]\n",
      "9\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "nb_features = np.prod(x_train.shape[1:])\n",
    "x_train.resize((n_train, nb_features))\n",
    "x_test.resize((n_test, nb_features))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_train)\n",
    "m = np.amax(x_train)\n",
    "print(m)\n",
    "print(y_train)\n",
    "\n",
    "ymax = np.amax(y_train)\n",
    "ymin = np.amin(y_train)\n",
    "\n",
    "print(ymax)\n",
    "print(ymin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data visualisation (5 points)\n",
    "Project the training data points in a 2D space using PCA. Use the obtained 2D embedding and plot the training data-points with different markers or colors for each class (you are allowed to use PCA from scikit learn). \n",
    "- Why PCA is a good option to visualize data? \n",
    "- Add this plot in your report and discuss your observations. \n",
    "- Which classes can be linearly separated?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "x_reduced = pca.fit_transform(x_train)\n",
    "\n",
    "markers = ['x','o','.','v','^','>','<','s','+','D']\n",
    "\n",
    "for i in range(0,10):\n",
    "    \n",
    "    plt.scatter(x_reduced[y_train==i][:,0], x_reduced[y_train==i][:,1], label=str(i), marker=markers[i], s=1)\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Perceptrons: (10 points)\n",
    "Single Layer Perceptron is one of the most basic binary classifiers one can use. In this part of the CW you should implement an iterative algorithm for training the Single Layer Perceptron.\n",
    "\n",
    "As we are dealing with a binary classification problem, we will pick data points corresponding to classes 0 and 1 (handwritten digits). In addition we choose our binary labels to be -1 and 1, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = (y_train == 0) + (y_train == 1)\n",
    "binary_x_train = x_train[cond,:]\n",
    "binary_y_train = y_train[cond]*1.\n",
    "\n",
    "cond = (y_test == 0) + (y_test == 1)\n",
    "binary_x_test = x_test[cond,:]\n",
    "binary_y_test = y_test[cond]*1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_y_train[binary_y_train == 0] = -1\n",
    "binary_y_train[binary_y_train == 1] = 1\n",
    "\n",
    "binary_y_test[binary_y_test == 0] = -1\n",
    "binary_y_test[binary_y_test == 1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.1\n",
    "Complete the function 'predict' below.\n",
    "#### inputs:\n",
    "\n",
    "+ $x\\in\\mathbb{R^{n*m}}$, with $n$ being the number of datapoints and $m$ being the feature dimensionality. \n",
    "+ $w \\in\\mathbb{R^m}$ is the parameter vector we wish to learn. \n",
    "+ $b \\in\\mathbb{R}$ is the corresponding bias.\n",
    "\n",
    "#### outputs: \n",
    "+ 'prediction'$\\in\\mathbb{R^n}$, a vector containing prediction values associated with $x$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w, b):\n",
    "    ######### Complete the function- x point ######### \n",
    "    #x = np.transpose(x)\n",
    "    mmult = np.dot(w,x)\n",
    "    prediction = np.sign(mmult + b)\n",
    "\n",
    "    ######################################\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.2\n",
    "+ Use the funtion 'predict' above to implement the Single Layer Perceptron algorithm by completing the function 'optimize' defined below.\n",
    "    #### inputs:\n",
    "\n",
    "    + $x\\in\\mathbb{R^{n*m}}$, with $n$ being the number of datapoints and $m$ being the feature dimensionality. \n",
    "    + $w \\in\\mathbb{R^m}$ is the initial parameter vector.\n",
    "    + $b \\in\\mathbb{R}$ is the initial bias value.\n",
    "    + $y\\in\\mathbb{R^n}$ is the training labels associated with x.\n",
    "    #### outputs:\n",
    "    + $w$ is the optimized parameter vector.\n",
    "    + $b$ the corresponding learned bias.\n",
    "    + $\\text{error}$ is the classification error obtained.  \n",
    "    \n",
    "    \n",
    " \n",
    "    \n",
    "Use the learned parameters $w$, $b$ (obtained via function 'optimize') and the function 'predict' to return the classification accuracy on the test set using x_train and y_train as training data. \n",
    "\n",
    "- Demonstrate that your algorithm converges to a good local minima. Plot the training error curve vs. number of iterations. \n",
    "- Show what feature $w$ has learned and discuss why? (demonstrate $w$ as an image with the same size as inputs).\n",
    "\n",
    "- Repeat this training/testing procedure to classify different pairs. Report the accuracies of 5 pairs in a Table and dicuss why some are easier to classify than others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(x, y,iters=1000):\n",
    "    iter = 0\n",
    "    loss = 0    \n",
    "    error=np.inf\n",
    "    n, m = x.shape\n",
    "    w = np.random.rand(m) # Initialize the w vector\n",
    "    b = np.random.rand()  # Initialize the b vector\n",
    "\n",
    "    lr = 0.005 # learning rate\n",
    "    \n",
    "    while (iter <= iters) & (error > 1e-3):\n",
    "        ######### Complete the function- x points ######### \n",
    "        idx = np.random.choice(np.arange(len(x)))\n",
    "        x_sample = x[idx]\n",
    "        y_sample = y[idx]\n",
    "\n",
    "        pred = predict(x_sample,w,b)\n",
    "        \n",
    "        if pred != y_sample:\n",
    "            w = w + (lr*(y_sample*x_sample))\n",
    "            \n",
    "        iter+=1\n",
    "    \n",
    "    for itm in np.arange(len(x)):\n",
    "        \n",
    "        pred = predict(x[itm],w,b)\n",
    "        \n",
    "        if pred != y[itm]:\n",
    "            loss+=1\n",
    "            \n",
    "        error = loss/len(y)\n",
    "            \n",
    "    #print('W: ',w)\n",
    "    #print('B: ',b)\n",
    "    #print('Training error: ',error)\n",
    "    \n",
    "    return w, b, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in range(1,1000):\\n    the_w, the_b, training_error = optimize(binary_x_train, binary_y_train, iters=i)\\n    errs.append(training_error)\\n    \\nfig = plt.figure()\\nax = fig.add_subplot(111)\\nax.plot(range(1,1000), errs)\\nax.set_xlabel('Iter')\\nax.set_ylabel('Loss') \\nplt.title('Training Error')\\n\\nfor i in range(1,1000):\\n    the_w, the_b, training_error = optimize(binary_x_test, binary_y_test, iters=i)\\n    errs_test.append(training_error)\\n    \\nfig = plt.figure()\\nax = fig.add_subplot(111)\\nax.plot(range(1,1000), errs_test)\\nax.set_xlabel('Iter')\\nax.set_ylabel('Loss') \\nplt.title('Test Error')\\n\\nitem = np.random.choice(np.arange(len(binary_y_test)))\\npred = predict(binary_x_test[item,:], the_w, the_b)\\nprint(binary_y_test[item])\\nprint(pred)\\nfig = plt.figure()\\nimg = binary_x_test[item,:].reshape(28,28)\\nimgplot = plt.imshow(img, cmap='gray')\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the_w, the_b, training_error = optimize(binary_x_train, binary_y_train)\n",
    "errs = []\n",
    "errs_test = []\n",
    "'''\n",
    "for i in range(1,1000):\n",
    "    the_w, the_b, training_error = optimize(binary_x_train, binary_y_train, iters=i)\n",
    "    errs.append(training_error)\n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(range(1,1000), errs)\n",
    "ax.set_xlabel('Iter')\n",
    "ax.set_ylabel('Loss') \n",
    "plt.title('Training Error')\n",
    "\n",
    "for i in range(1,1000):\n",
    "    the_w, the_b, training_error = optimize(binary_x_test, binary_y_test, iters=i)\n",
    "    errs_test.append(training_error)\n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(range(1,1000), errs_test)\n",
    "ax.set_xlabel('Iter')\n",
    "ax.set_ylabel('Loss') \n",
    "plt.title('Test Error')\n",
    "\n",
    "item = np.random.choice(np.arange(len(binary_y_test)))\n",
    "pred = predict(binary_x_test[item,:], the_w, the_b)\n",
    "print(binary_y_test[item])\n",
    "print(pred)\n",
    "fig = plt.figure()\n",
    "img = binary_x_test[item,:].reshape(28,28)\n",
    "imgplot = plt.imshow(img, cmap='gray')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3: Multi Layer Perceptron (10 points)\n",
    "\n",
    "Multi Layer Perceptron (MLP) is a fully connected deep (more than one hidden layer) network. In this part of the coursework we will implement a 2 hidden layers MLP with Recified Linear Unit (ReLU) activations. We will train the model via ADAM optimizer over a cross-entropy loss function.\n",
    "\n",
    "First of all, we will convert our label vectors to matrices via one-hot encoding (e.g. $y=2$ would become $[0,0,1,0,0,0,0,0,0,0]$). This can be simply done using commands below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.eye(10)[y_train]\n",
    "y_test = np.eye(10)[y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we define a class MLP. It is initialized via:  \n",
    "\n",
    "+ x_train: The training matrix.\n",
    "+ y_train: One hot encoding of the corresponding labels.\n",
    "+ lr: Learning rate used for ADAM optimizer\n",
    "+ nb_epochs: Number of epochs to use\n",
    "+ batch_size: The number of data point in each mini-batch\n",
    "+ output_dir: The directory where model parameters and tensorboard event files will be stored.\n",
    "\n",
    "We also define the methods: \n",
    "* 'create_model' which will desribe a neural network architecture of the form $[784, 1000, 1000, 10]$, each integer representing the number of neurons in a given layer while the length of the vector defines the number of layers accordingly. \n",
    "* 'compute_loss' which given the output of 'create_model' will calculate the cross-entropy loss of the mini-batches.\n",
    "* 'train' where we initiate a tensorflow session and perform the training iterations. \n",
    "* 'test' where we load our trained model and perform inference on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3.1\n",
    "- Complete the method 'create_model' in order to implement a network of the shape $[784, 1000, 1000, 10]$, use ReLU as the non linear activation for hidden layers.\n",
    "\n",
    "   The function 'create_model' to complete defines the class variables: \n",
    "\n",
    "   + self.logits $\\in \\mathbb{R^{10}}$ containing the output __<font color='red'>without activation of the MLP.</font>__\n",
    "   + self.preds $\\in \\mathbb{R^{10}}$ containing posterior probabilities.\n",
    "\n",
    "- Using self.logits complete the method 'compute_loss' that takes the labels and the predicted logits to return the corresponfing cross-entropy loss. \n",
    "\n",
    "Hints: \n",
    "- You may use tf.layers.dense to implement a fully connected layer. \n",
    "- To obtain the probabilities you must normalize your outputs in a way that their sum is equal to one using a softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, x_train, y_train, output_dir, lr=0.001, nb_epochs=10, batch_size=50):\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.nb_images, self.nb_features = x_train.shape\n",
    "        self.nb_iterations = self.nb_images // batch_size\n",
    "        self.output_dir = output_dir\n",
    "        self.im = tf.placeholder(tf.float32, [None, 784])\n",
    "        self.labels = tf.placeholder(tf.float32, [None, 10])\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def create_model(self, config):\n",
    "        with tf.variable_scope('MLP', reuse=tf.AUTO_REUSE):\n",
    "        ######### Complete the function ######### \n",
    "        \n",
    "            inputL = tf.layers.dense(inputs=self.im, units=784, activation=tf.nn.relu, name='inp_'+str(config[0]))  \n",
    "        \n",
    "            if(config[0] == 0):\n",
    "\n",
    "                hidden1 = tf.layers.dense(inputs=inputL, units=1000, activation=tf.nn.relu, name='h1_'+str(config[0]))\n",
    "                hidden2 = tf.layers.dense(inputs=hidden1, units=1000, activation=tf.nn.relu, name='h2_'+str(config[0])) \n",
    "                self.logits = tf.layers.dense(inputs=hidden2, units=10, name='lg_'+str(config[0]))                 \n",
    "            \n",
    "            if(config[0] == 1):\n",
    "\n",
    "                hidden1 = tf.layers.dense(inputs=inputL, units=1000, activation=tf.nn.relu, name='h1_'+str(config[0]))\n",
    "                hidden2 = tf.layers.dense(inputs=hidden1, units=1000, activation=tf.nn.relu, name='h2_'+str(config[0]))  \n",
    "                hidden3 = tf.layers.dense(inputs=hidden2, units=1000, activation=tf.nn.relu, name='h3_'+str(config[0]))                \n",
    "                self.logits = tf.layers.dense(inputs=hidden3, units=10, name='lg_'+str(config[0]))   \n",
    "                \n",
    "            if(config[0] == 2):\n",
    "\n",
    "                hidden1 = tf.layers.dense(inputs=inputL, units=1000, activation=tf.nn.relu, name='h1_'+str(config[0]))\n",
    "                hidden2 = tf.layers.dense(inputs=hidden1, units=500, activation=tf.nn.relu, name='h2_'+str(config[0]))  \n",
    "                hidden3 = tf.layers.dense(inputs=hidden2, units=100, activation=tf.nn.relu, name='h3_'+str(config[0]))                \n",
    "                self.logits = tf.layers.dense(inputs=hidden3, units=10, name='lg_'+str(config[0]))     \n",
    "                \n",
    "            if(config[0] == 3):\n",
    "\n",
    "                hidden1 = tf.layers.dense(inputs=inputL, units=1000, activation=tf.nn.relu, name='h1_'+str(config[0]))\n",
    "                hidden2 = tf.layers.dense(inputs=hidden1, units=2000, activation=tf.nn.relu, name='h2_'+str(config[0]))  \n",
    "                hidden3 = tf.layers.dense(inputs=hidden2, units=3000, activation=tf.nn.relu, name='h3_'+str(config[0]))  \n",
    "                hidden4 = tf.layers.dense(inputs=hidden3, units=3000, activation=tf.nn.relu, name='h4_'+str(config[0]))                 \n",
    "                hidden5 = tf.layers.dense(inputs=hidden4, units=3000, activation=tf.nn.relu, name='h5_'+str(config[0]))                 \n",
    "                self.logits = tf.layers.dense(inputs=hidden5, units=10, name='lg_'+str(config[0]))                 \n",
    "                \n",
    "            if(config[0] == 4):\n",
    "\n",
    "                hidden1 = tf.layers.dense(inputs=inputL, units=512, activation=tf.nn.relu, name='h1_'+str(config[0]))\n",
    "                hidden2 = tf.layers.dense(inputs=hidden1, units=256, activation=tf.nn.relu, name='h2_'+str(config[0]))  \n",
    "                hidden3 = tf.layers.dense(inputs=hidden2, units=128, activation=tf.nn.relu, name='h3_'+str(config[0]))  \n",
    "                hidden4 = tf.layers.dense(inputs=hidden3, units=64, activation=tf.nn.relu, name='h4_'+str(config[0]))                 \n",
    "                hidden5 = tf.layers.dense(inputs=hidden4, units=32, activation=tf.nn.relu, name='h5_'+str(config[0]))                 \n",
    "                self.logits = tf.layers.dense(inputs=hidden5, units=10, name='lg_'+str(config[0]))                    \n",
    "            \n",
    "            self.preds = tf.nn.softmax(self.logits)           \n",
    "\n",
    "    def compute_loss(self):\n",
    "        with tf.variable_scope('loss'):\n",
    "            ######### Complete the function ######### \n",
    "            self.loss = tf.losses.softmax_cross_entropy(self.labels, self.logits)\n",
    "            #########################################\n",
    "            self.loss_summ = tf.summary.scalar(\"softmax_loss\", self.loss)\n",
    "            \n",
    "    def optimizer(self):\n",
    "        with tf.variable_scope('optimizer'):\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=self.lr, beta1=0.5)\n",
    "            self.model_vars = tf.trainable_variables()\n",
    "            self.trainer = optimizer.minimize(self.loss, var_list=self.model_vars)\n",
    "            \n",
    "    def getComplexity(self):\n",
    "        total_parameters = 0\n",
    "        for variable in tf.trainable_variables():\n",
    "            # shape is an array of tf.Dimension\n",
    "            shape = variable.get_shape()\n",
    "            variable_parameters = 1\n",
    "            for dim in shape:\n",
    "                variable_parameters *= dim.value\n",
    "            total_parameters += variable_parameters\n",
    "        self.compx = tf.constant(total_parameters)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we defined our model, our loss and its optimizer. we can instantate the MLP class, initiate our variables, and start the tensorflow session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-f8c63d7afd05>:19: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /Users/damian/opt/anaconda3/envs/RLP2/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/damian/opt/anaconda3/envs/RLP2/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = MLP(x_train, y_train, './MLP_logdir/', 0.001, 2, 10)\n",
    "model.create_model([0])\n",
    "model.compute_loss()\n",
    "model.optimizer()\n",
    "model.getComplexity()\n",
    "init = (tf.global_variables_initializer(),\n",
    "        tf.local_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "summary =tf.Summary()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "writer = tf.summary.FileWriter(model.output_dir)\n",
    "writer.add_graph(sess.graph)\n",
    "if not os.path.exists(model.output_dir):\n",
    "    os.makedirs(model.output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start training. We loop over the training data points and we feed them to the session in mini-batches form. we repeat this process several times (for several epochs). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "startT = time.time()\n",
    "for epoch in range(model.nb_epochs):\n",
    "    #print('Epoch: ',epoch)\n",
    "    randomize = np.arange(x_train.shape[0])\n",
    "    np.random.shuffle(randomize)\n",
    "    x_in = model.x_train[randomize,:]\n",
    "    y_in = model.y_train[randomize,:]\n",
    "    for i in range(model.nb_iterations):\n",
    "        input_x_train = x_in[i*model.batch_size: (i+1)*model.batch_size]\n",
    "        input_y_train = y_in[i*model.batch_size: (i+1)*model.batch_size]\n",
    "        _ , preds, loss, loss_summ = sess.run([model.trainer, model.preds, model.loss, model.loss_summ], \n",
    "                                 feed_dict={model.im: input_x_train, \n",
    "                                            model.labels: input_y_train})\n",
    "        y_preds = np.argmax(preds, axis=1)\n",
    "        y_real = np.argmax(input_y_train, axis=1)\n",
    "        acc_train = np.mean((y_preds==y_real)*1)\n",
    "        #print('Epoch %d, Iteration %d, loss %.3f, batch accuracy %.3f' %(epoch, i, loss, acc_train))\n",
    "        writer.add_summary(loss_summ, epoch * model.nb_iterations + i)\n",
    "    saver.save(sess, model.output_dir, global_step=epoch)  \n",
    "# sess.close()\n",
    "timeTaken = int(time.time() - startT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During and after training visualize the training and the created graph via tensorboard. Tensorboard is accessible via the command \"tensorboard --logdir=#yourlogdir#\". Check out https://www.tensorflow.org/guide/summaries_and_tensorboard for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we loop over the test dataset and get the test accuracy via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy achieved: 0.940\n"
     ]
    }
   ],
   "source": [
    "perfs = []\n",
    "complexities = []\n",
    "duration = [timeTaken]\n",
    "\n",
    "batch_size_test = 20\n",
    "nb_test_points = x_test.shape[0] \n",
    "nb_iterations = nb_test_points//batch_size_test\n",
    "preds = []\n",
    "for i in range(nb_iterations):\n",
    "    input_x_test = x_test[i*batch_size_test: (i+1)*batch_size_test]\n",
    "    preds_test = sess.run(model.preds,\n",
    "                             feed_dict={model.im: input_x_test})\n",
    "    preds.append(np.argmax(preds_test, axis=1))\n",
    "    if np.mod(nb_test_points, batch_size_test) !=0:\n",
    "        input_x_test = x_test[i*batch_size_test: -1]\n",
    "        preds_test = sess.run(model.preds, \n",
    "                             feed_dict={model.im: input_x_test})\n",
    "        preds.append(np.argmax(preds, axis=1))\n",
    "        \n",
    "complexity = sess.run(model.compx)\n",
    "complexities.append(complexity)\n",
    "\n",
    "all_preds = np.concatenate(preds, axis =0)\n",
    "y_real = np.argmax(y_test, axis=1)\n",
    "acc_test = np.mean((all_preds==y_real)*1)\n",
    "perfs.append(acc_test)\n",
    "print('Test accuracy achieved: %.3f' %acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Include a figure to visualize your training & testing(see below) performances during iterations and discuss your observations in your report.\n",
    "\n",
    "\n",
    "We now close the tensorflow session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3.2\n",
    "Using a similar format as before, discuss how the number of layers affects the classification accuracy. \n",
    "- Train four different networks with more hidden layers for example 3,4,5 and 7 hidden layers (choice is yours here to make a good conclusion). Choose an appropriate width i.e. number of neurons per layer so to achieve good accuracy and feasible training time. How many paramters (weights/biases) do these models have? How do they compare to the former MLP you implemented? \n",
    "- Compare the classification accuracies of these networks with the previous MLP.\n",
    "\n",
    "\n",
    "- Plot a graph showing the accuracy vs. depth v.s. complexity (number of paramters) of the all five MLPs with different depths/widths. Additionally report the results in a Table. Discuss the results and provide conclusion. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nets in range(1,5):\n",
    "    \n",
    "    model = MLP(x_train, y_train, './MLP_logdir_'+(str(nets))+'/', 0.001, 2, 10)\n",
    "    model.create_model([nets])\n",
    "    model.compute_loss()\n",
    "    model.optimizer()\n",
    "    model.getComplexity()\n",
    "    init = (tf.global_variables_initializer(),\n",
    "            tf.local_variables_initializer())\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    summary =tf.Summary()\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter(model.output_dir)\n",
    "    writer.add_graph(sess.graph)\n",
    "    if not os.path.exists(model.output_dir):\n",
    "        os.makedirs(model.output_dir)\n",
    "        \n",
    "    startT = time.time()    \n",
    "    for epoch in range(model.nb_epochs):\n",
    "        #print('Epoch: ',epoch)\n",
    "        randomize = np.arange(x_train.shape[0])\n",
    "        np.random.shuffle(randomize)\n",
    "        x_in = model.x_train[randomize,:]\n",
    "        y_in = model.y_train[randomize,:]\n",
    "        for i in range(model.nb_iterations):\n",
    "            input_x_train = x_in[i*model.batch_size: (i+1)*model.batch_size]\n",
    "            input_y_train = y_in[i*model.batch_size: (i+1)*model.batch_size]\n",
    "            _ , preds, loss, loss_summ = sess.run([model.trainer, model.preds, model.loss, model.loss_summ], \n",
    "                                     feed_dict={model.im: input_x_train, \n",
    "                                                model.labels: input_y_train})\n",
    "            y_preds = np.argmax(preds, axis=1)\n",
    "            y_real = np.argmax(input_y_train, axis=1)\n",
    "            acc_train = np.mean((y_preds==y_real)*1)\n",
    "            #print('Epoch %d, Iteration %d, loss %.3f, batch accuracy %.3f' %(epoch, i, loss, acc_train))\n",
    "            writer.add_summary(loss_summ, epoch * model.nb_iterations + i)\n",
    "        saver.save(sess, model.output_dir, global_step=epoch)\n",
    "        \n",
    "    timeTaken = int(time.time() - startT)\n",
    "    duration.append(timeTaken) \n",
    "    \n",
    "    batch_size_test = 20\n",
    "    nb_test_points = x_test.shape[0] \n",
    "    nb_iterations = nb_test_points//batch_size_test\n",
    "    preds = []\n",
    "    for i in range(nb_iterations):\n",
    "        input_x_test = x_test[i*batch_size_test: (i+1)*batch_size_test]\n",
    "        preds_test = sess.run(model.preds, \n",
    "                                 feed_dict={model.im: input_x_test})\n",
    "        preds.append(np.argmax(preds_test, axis=1))\n",
    "        if np.mod(nb_test_points, batch_size_test) !=0:\n",
    "            input_x_test = x_test[i*batch_size_test: -1]\n",
    "            preds_test = sess.run(model.preds, \n",
    "                                 feed_dict={model.im: input_x_test})\n",
    "            preds.append(np.argmax(preds, axis=1))\n",
    "            \n",
    "    complexity = sess.run(model.compx)\n",
    "    complexities.append(complexity)            \n",
    "            \n",
    "    all_preds = np.concatenate(preds, axis =0)\n",
    "    y_real = np.argmax(y_test, axis=1)\n",
    "    acc_test = np.mean((all_preds==y_real)*1)\n",
    "    perfs.append(acc_test)        \n",
    "        \n",
    "    sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9396, 0.9317, 0.9246, 0.9337, 0.9578]\n",
      "[2411450, 5823900, 7775950, 35217400, 36409650]\n",
      "[115, 152, 100, 1231, 65]\n"
     ]
    }
   ],
   "source": [
    "print(perfs)\n",
    "print(complexities)\n",
    "print(duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Convolutional Neural Network (10 points)\n",
    "Now that we are more familiar with the MLP algorithm, it is time to see how it compares with a Convolutional Neural Network (CNN). CNNs leverage dependencies between neighbouring pixels, making them more efficient and light weight compared to their fully connected counter part. In this section we will implement a Class CNN similar to the one we defined before for MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 4.1\n",
    "Complete the function 'create_model' of the class CNN above. Implement a CNN of the shape [32, 64, 128]; where 32, 64, 128 represent the number of convolutional filters for each hidden layer. We will use a kernel size of size $4\\times4$. \n",
    "\n",
    "Use a stride of 1 in the first convolutional layer, followed by a stride of 2 for the following layers (a stride of two help downsampling without requiring the use of pooling layers). Vectorize the obtained output using tf.layer.flatten, and end the model with a fully connected layer of 10 neurons. Use ReLU as the non linear activation for the hidden layers.\n",
    "\n",
    "   The function 'create_model' to complete defines the class variables: \n",
    "\n",
    "   + self.logits $\\in \\mathbb{R^{10}}$ containing the output without activation of the last __<font color='red'>fully connected layer</font>.__ \n",
    "\n",
    "   + self.preds $\\in \\mathbb{R^{10}}$ containing posterior probabilities.\n",
    "\n",
    "- Using self.logits complete the method 'compute_loss' that takes the labels and the predicted logits to return the corresponfing cross-entropy loss. \n",
    "\n",
    "Hints: \n",
    "+ You may use tf.layers.conv2d to implement a convolutional layer. \n",
    "+ To obtain the probabilities you must normalize your outputs in a way that their sum is equal to one using a softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, x_train, y_train, output_dir, lr=0.001, nb_epochs=10, batch_size=50):\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.nb_images, self.edge, _ = x_train.shape\n",
    "        self.nb_iterations = self.nb_images // batch_size\n",
    "        self.output_dir = output_dir\n",
    "        self.im = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "        self.labels = tf.placeholder(tf.float32, [None, 10])\n",
    "        self.x_train = x_train[:,:,:, np.newaxis]\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def create_model(self):\n",
    "        with tf.variable_scope('CNN', reuse=tf.AUTO_REUSE):\n",
    "            ######### Complete the function #########\n",
    "            \n",
    "            inputL = tf.layers.conv2d(inputs=self.im, filters=32, strides=1, kernel_size=[4,4], activation=tf.nn.relu)\n",
    "            conv1 = tf.layers.conv2d(inputs=self.im, filters=64, strides=2, kernel_size=[4,4], activation=tf.nn.relu)\n",
    "            conv2 = tf.layers.conv2d(inputs=self.im, filters=128, strides=2, kernel_size=[4,4], activation=tf.nn.relu)\n",
    "            flatten = tf.layers.flatten(conv2)\n",
    "            self.logits = tf.layers.dense(inputs=flatten, units=10) \n",
    "            self.preds = tf.nn.softmax(self.logits)\n",
    "    \n",
    "    def compute_loss(self):\n",
    "        with tf.variable_scope('loss'):\n",
    "            ######### Complete the function ######### \n",
    "            self.loss = tf.losses.softmax_cross_entropy(self.labels, self.logits)\n",
    "            self.loss_summ = tf.summary.scalar(\"softmax_loss\", self.loss)\n",
    "            \n",
    "    def optimizer(self):\n",
    "        with tf.variable_scope('optimizer'):\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=self.lr, beta1=0.5)\n",
    "            self.model_vars = tf.trainable_variables()\n",
    "            self.trainer = optimizer.minimize(self.loss, var_list=self.model_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs leverage dependencies between neighbouring pixels, however this information is partially lost when we vectorized our data. For training CNNs we will need to recover our initial shape of $N \\times 28 \\times 28$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge = int(np.sqrt(nb_features))\n",
    "x_train.resize([n_train, edge, edge])\n",
    "x_test.resize([n_test, edge, edge])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate our CNN class, start the corresponging tensorflow session and initiate the trainable variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-8d49308f0425>:19: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From <ipython-input-19-8d49308f0425>:22: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    }
   ],
   "source": [
    "model = CNN(x_train, y_train, './CNN_logdir/', 0.001, 2, 10)\n",
    "model.create_model()\n",
    "model.compute_loss()\n",
    "model.optimizer()\n",
    "init = (tf.global_variables_initializer(),\n",
    "        tf.local_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "summary =tf.Summary()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "writer = tf.summary.FileWriter(model.output_dir)\n",
    "writer.add_graph(sess.graph)\n",
    "if not os.path.exists(model.output_dir):\n",
    "    os.makedirs(model.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0, loss 2.379, batch accuracy 0.000\n",
      "Epoch 0, Iteration 1, loss 2.768, batch accuracy 0.000\n",
      "Epoch 0, Iteration 2, loss 2.329, batch accuracy 0.200\n",
      "Epoch 0, Iteration 3, loss 2.188, batch accuracy 0.000\n",
      "Epoch 0, Iteration 4, loss 2.596, batch accuracy 0.200\n",
      "Epoch 0, Iteration 5, loss 2.035, batch accuracy 0.600\n",
      "Epoch 0, Iteration 6, loss 1.898, batch accuracy 0.600\n",
      "Epoch 0, Iteration 7, loss 1.863, batch accuracy 0.500\n",
      "Epoch 0, Iteration 8, loss 1.572, batch accuracy 0.700\n",
      "Epoch 0, Iteration 9, loss 2.059, batch accuracy 0.200\n",
      "Epoch 0, Iteration 10, loss 1.523, batch accuracy 0.700\n",
      "Epoch 0, Iteration 11, loss 1.941, batch accuracy 0.300\n",
      "Epoch 0, Iteration 12, loss 1.168, batch accuracy 0.700\n",
      "Epoch 0, Iteration 13, loss 1.716, batch accuracy 0.600\n",
      "Epoch 0, Iteration 14, loss 1.542, batch accuracy 0.400\n",
      "Epoch 0, Iteration 15, loss 1.880, batch accuracy 0.200\n",
      "Epoch 0, Iteration 16, loss 1.335, batch accuracy 0.700\n",
      "Epoch 0, Iteration 17, loss 1.175, batch accuracy 0.700\n",
      "Epoch 0, Iteration 18, loss 1.297, batch accuracy 0.700\n",
      "Epoch 0, Iteration 19, loss 1.310, batch accuracy 0.600\n",
      "Epoch 0, Iteration 20, loss 1.151, batch accuracy 0.800\n",
      "Epoch 0, Iteration 21, loss 1.274, batch accuracy 0.500\n",
      "Epoch 0, Iteration 22, loss 0.733, batch accuracy 1.000\n",
      "Epoch 0, Iteration 23, loss 1.529, batch accuracy 0.400\n",
      "Epoch 0, Iteration 24, loss 1.015, batch accuracy 0.700\n",
      "Epoch 0, Iteration 25, loss 0.548, batch accuracy 0.900\n",
      "Epoch 0, Iteration 26, loss 0.797, batch accuracy 0.900\n",
      "Epoch 0, Iteration 27, loss 1.566, batch accuracy 0.500\n",
      "Epoch 0, Iteration 28, loss 0.510, batch accuracy 0.900\n",
      "Epoch 0, Iteration 29, loss 0.514, batch accuracy 0.800\n",
      "Epoch 0, Iteration 30, loss 1.309, batch accuracy 0.600\n",
      "Epoch 0, Iteration 31, loss 1.224, batch accuracy 0.600\n",
      "Epoch 0, Iteration 32, loss 0.757, batch accuracy 0.800\n",
      "Epoch 0, Iteration 33, loss 0.768, batch accuracy 0.700\n",
      "Epoch 0, Iteration 34, loss 0.715, batch accuracy 0.800\n",
      "Epoch 0, Iteration 35, loss 0.882, batch accuracy 0.700\n",
      "Epoch 0, Iteration 36, loss 0.532, batch accuracy 0.800\n",
      "Epoch 0, Iteration 37, loss 0.679, batch accuracy 0.900\n",
      "Epoch 0, Iteration 38, loss 0.629, batch accuracy 0.700\n",
      "Epoch 0, Iteration 39, loss 0.672, batch accuracy 0.800\n",
      "Epoch 0, Iteration 40, loss 0.441, batch accuracy 1.000\n",
      "Epoch 0, Iteration 41, loss 0.403, batch accuracy 0.900\n",
      "Epoch 0, Iteration 42, loss 0.678, batch accuracy 0.700\n",
      "Epoch 0, Iteration 43, loss 0.552, batch accuracy 0.800\n",
      "Epoch 0, Iteration 44, loss 0.369, batch accuracy 1.000\n",
      "Epoch 0, Iteration 45, loss 0.393, batch accuracy 0.900\n",
      "Epoch 0, Iteration 46, loss 0.493, batch accuracy 0.900\n",
      "Epoch 0, Iteration 47, loss 0.226, batch accuracy 1.000\n",
      "Epoch 0, Iteration 48, loss 0.951, batch accuracy 0.700\n",
      "Epoch 0, Iteration 49, loss 0.447, batch accuracy 0.900\n",
      "Epoch 0, Iteration 50, loss 0.536, batch accuracy 0.700\n",
      "Epoch 0, Iteration 51, loss 0.432, batch accuracy 0.800\n",
      "Epoch 0, Iteration 52, loss 0.500, batch accuracy 0.800\n",
      "Epoch 0, Iteration 53, loss 0.432, batch accuracy 0.800\n",
      "Epoch 0, Iteration 54, loss 0.396, batch accuracy 1.000\n",
      "Epoch 0, Iteration 55, loss 0.354, batch accuracy 0.900\n",
      "Epoch 0, Iteration 56, loss 0.561, batch accuracy 0.900\n",
      "Epoch 0, Iteration 57, loss 0.358, batch accuracy 0.900\n",
      "Epoch 0, Iteration 58, loss 0.390, batch accuracy 0.800\n",
      "Epoch 0, Iteration 59, loss 0.782, batch accuracy 0.700\n",
      "Epoch 0, Iteration 60, loss 0.585, batch accuracy 0.800\n",
      "Epoch 0, Iteration 61, loss 0.734, batch accuracy 0.700\n",
      "Epoch 0, Iteration 62, loss 0.573, batch accuracy 0.800\n",
      "Epoch 0, Iteration 63, loss 0.625, batch accuracy 0.900\n",
      "Epoch 0, Iteration 64, loss 0.854, batch accuracy 0.600\n",
      "Epoch 0, Iteration 65, loss 0.848, batch accuracy 0.800\n",
      "Epoch 0, Iteration 66, loss 1.000, batch accuracy 0.700\n",
      "Epoch 0, Iteration 67, loss 0.428, batch accuracy 0.900\n",
      "Epoch 0, Iteration 68, loss 0.077, batch accuracy 1.000\n",
      "Epoch 0, Iteration 69, loss 0.323, batch accuracy 0.800\n",
      "Epoch 0, Iteration 70, loss 0.759, batch accuracy 0.600\n",
      "Epoch 0, Iteration 71, loss 0.575, batch accuracy 0.700\n",
      "Epoch 0, Iteration 72, loss 0.617, batch accuracy 0.800\n",
      "Epoch 0, Iteration 73, loss 1.452, batch accuracy 0.500\n",
      "Epoch 0, Iteration 74, loss 0.298, batch accuracy 0.900\n",
      "Epoch 0, Iteration 75, loss 0.601, batch accuracy 0.800\n",
      "Epoch 0, Iteration 76, loss 0.157, batch accuracy 1.000\n",
      "Epoch 0, Iteration 77, loss 1.736, batch accuracy 0.400\n",
      "Epoch 0, Iteration 78, loss 0.895, batch accuracy 0.600\n",
      "Epoch 0, Iteration 79, loss 0.220, batch accuracy 1.000\n",
      "Epoch 0, Iteration 80, loss 0.375, batch accuracy 0.900\n",
      "Epoch 0, Iteration 81, loss 0.221, batch accuracy 1.000\n",
      "Epoch 0, Iteration 82, loss 0.523, batch accuracy 0.800\n",
      "Epoch 0, Iteration 83, loss 0.075, batch accuracy 1.000\n",
      "Epoch 0, Iteration 84, loss 0.236, batch accuracy 0.900\n",
      "Epoch 0, Iteration 85, loss 0.072, batch accuracy 1.000\n",
      "Epoch 0, Iteration 86, loss 0.232, batch accuracy 1.000\n",
      "Epoch 0, Iteration 87, loss 0.238, batch accuracy 1.000\n",
      "Epoch 0, Iteration 88, loss 0.334, batch accuracy 0.900\n",
      "Epoch 0, Iteration 89, loss 0.551, batch accuracy 0.800\n",
      "Epoch 0, Iteration 90, loss 0.250, batch accuracy 1.000\n",
      "Epoch 0, Iteration 91, loss 1.194, batch accuracy 0.700\n",
      "Epoch 0, Iteration 92, loss 0.272, batch accuracy 1.000\n",
      "Epoch 0, Iteration 93, loss 0.403, batch accuracy 0.900\n",
      "Epoch 0, Iteration 94, loss 0.212, batch accuracy 0.900\n",
      "Epoch 0, Iteration 95, loss 0.250, batch accuracy 0.900\n",
      "Epoch 0, Iteration 96, loss 0.116, batch accuracy 1.000\n",
      "Epoch 0, Iteration 97, loss 0.188, batch accuracy 0.900\n",
      "Epoch 0, Iteration 98, loss 0.386, batch accuracy 0.800\n",
      "Epoch 0, Iteration 99, loss 0.278, batch accuracy 0.900\n",
      "Epoch 0, Iteration 100, loss 0.308, batch accuracy 0.900\n",
      "Epoch 0, Iteration 101, loss 0.133, batch accuracy 1.000\n",
      "Epoch 0, Iteration 102, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 103, loss 0.845, batch accuracy 0.700\n",
      "Epoch 0, Iteration 104, loss 0.606, batch accuracy 0.800\n",
      "Epoch 0, Iteration 105, loss 0.359, batch accuracy 0.900\n",
      "Epoch 0, Iteration 106, loss 0.733, batch accuracy 0.700\n",
      "Epoch 0, Iteration 107, loss 0.334, batch accuracy 0.900\n",
      "Epoch 0, Iteration 108, loss 0.172, batch accuracy 1.000\n",
      "Epoch 0, Iteration 109, loss 0.112, batch accuracy 1.000\n",
      "Epoch 0, Iteration 110, loss 0.200, batch accuracy 1.000\n",
      "Epoch 0, Iteration 111, loss 0.271, batch accuracy 0.900\n",
      "Epoch 0, Iteration 112, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 113, loss 0.298, batch accuracy 0.800\n",
      "Epoch 0, Iteration 114, loss 0.186, batch accuracy 1.000\n",
      "Epoch 0, Iteration 115, loss 0.965, batch accuracy 0.800\n",
      "Epoch 0, Iteration 116, loss 0.668, batch accuracy 0.700\n",
      "Epoch 0, Iteration 117, loss 0.231, batch accuracy 0.900\n",
      "Epoch 0, Iteration 118, loss 0.408, batch accuracy 0.800\n",
      "Epoch 0, Iteration 119, loss 0.299, batch accuracy 0.900\n",
      "Epoch 0, Iteration 120, loss 0.147, batch accuracy 0.900\n",
      "Epoch 0, Iteration 121, loss 1.468, batch accuracy 0.800\n",
      "Epoch 0, Iteration 122, loss 0.168, batch accuracy 0.900\n",
      "Epoch 0, Iteration 123, loss 0.370, batch accuracy 0.800\n",
      "Epoch 0, Iteration 124, loss 0.596, batch accuracy 0.700\n",
      "Epoch 0, Iteration 125, loss 0.212, batch accuracy 0.900\n",
      "Epoch 0, Iteration 126, loss 0.410, batch accuracy 0.900\n",
      "Epoch 0, Iteration 127, loss 0.212, batch accuracy 1.000\n",
      "Epoch 0, Iteration 128, loss 0.139, batch accuracy 1.000\n",
      "Epoch 0, Iteration 129, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 130, loss 0.125, batch accuracy 1.000\n",
      "Epoch 0, Iteration 131, loss 0.398, batch accuracy 0.900\n",
      "Epoch 0, Iteration 132, loss 0.299, batch accuracy 0.800\n",
      "Epoch 0, Iteration 133, loss 0.224, batch accuracy 0.900\n",
      "Epoch 0, Iteration 134, loss 0.538, batch accuracy 0.800\n",
      "Epoch 0, Iteration 135, loss 0.557, batch accuracy 0.800\n",
      "Epoch 0, Iteration 136, loss 0.252, batch accuracy 0.900\n",
      "Epoch 0, Iteration 137, loss 0.119, batch accuracy 1.000\n",
      "Epoch 0, Iteration 138, loss 0.224, batch accuracy 1.000\n",
      "Epoch 0, Iteration 139, loss 0.194, batch accuracy 1.000\n",
      "Epoch 0, Iteration 140, loss 0.137, batch accuracy 1.000\n",
      "Epoch 0, Iteration 141, loss 0.385, batch accuracy 0.800\n",
      "Epoch 0, Iteration 142, loss 0.599, batch accuracy 0.700\n",
      "Epoch 0, Iteration 143, loss 0.369, batch accuracy 0.800\n",
      "Epoch 0, Iteration 144, loss 0.419, batch accuracy 0.800\n",
      "Epoch 0, Iteration 145, loss 0.571, batch accuracy 0.900\n",
      "Epoch 0, Iteration 146, loss 0.307, batch accuracy 0.800\n",
      "Epoch 0, Iteration 147, loss 0.081, batch accuracy 1.000\n",
      "Epoch 0, Iteration 148, loss 1.700, batch accuracy 0.500\n",
      "Epoch 0, Iteration 149, loss 0.070, batch accuracy 1.000\n",
      "Epoch 0, Iteration 150, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 151, loss 0.069, batch accuracy 1.000\n",
      "Epoch 0, Iteration 152, loss 0.907, batch accuracy 0.800\n",
      "Epoch 0, Iteration 153, loss 0.848, batch accuracy 0.900\n",
      "Epoch 0, Iteration 154, loss 0.714, batch accuracy 0.700\n",
      "Epoch 0, Iteration 155, loss 0.411, batch accuracy 0.800\n",
      "Epoch 0, Iteration 156, loss 1.148, batch accuracy 0.800\n",
      "Epoch 0, Iteration 157, loss 0.204, batch accuracy 0.900\n",
      "Epoch 0, Iteration 158, loss 0.186, batch accuracy 1.000\n",
      "Epoch 0, Iteration 159, loss 0.757, batch accuracy 0.700\n",
      "Epoch 0, Iteration 160, loss 0.612, batch accuracy 0.800\n",
      "Epoch 0, Iteration 161, loss 0.651, batch accuracy 0.700\n",
      "Epoch 0, Iteration 162, loss 0.610, batch accuracy 0.800\n",
      "Epoch 0, Iteration 163, loss 0.198, batch accuracy 0.900\n",
      "Epoch 0, Iteration 164, loss 0.250, batch accuracy 0.900\n",
      "Epoch 0, Iteration 165, loss 0.111, batch accuracy 0.900\n",
      "Epoch 0, Iteration 166, loss 0.443, batch accuracy 0.800\n",
      "Epoch 0, Iteration 167, loss 0.387, batch accuracy 0.800\n",
      "Epoch 0, Iteration 168, loss 0.120, batch accuracy 1.000\n",
      "Epoch 0, Iteration 169, loss 0.244, batch accuracy 1.000\n",
      "Epoch 0, Iteration 170, loss 0.095, batch accuracy 1.000\n",
      "Epoch 0, Iteration 171, loss 0.220, batch accuracy 0.900\n",
      "Epoch 0, Iteration 172, loss 0.254, batch accuracy 0.900\n",
      "Epoch 0, Iteration 173, loss 0.244, batch accuracy 0.900\n",
      "Epoch 0, Iteration 174, loss 0.580, batch accuracy 0.800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 175, loss 0.172, batch accuracy 1.000\n",
      "Epoch 0, Iteration 176, loss 0.192, batch accuracy 1.000\n",
      "Epoch 0, Iteration 177, loss 0.658, batch accuracy 0.800\n",
      "Epoch 0, Iteration 178, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 179, loss 0.496, batch accuracy 0.700\n",
      "Epoch 0, Iteration 180, loss 0.693, batch accuracy 0.800\n",
      "Epoch 0, Iteration 181, loss 0.256, batch accuracy 0.800\n",
      "Epoch 0, Iteration 182, loss 1.120, batch accuracy 0.800\n",
      "Epoch 0, Iteration 183, loss 0.117, batch accuracy 1.000\n",
      "Epoch 0, Iteration 184, loss 0.199, batch accuracy 1.000\n",
      "Epoch 0, Iteration 185, loss 0.103, batch accuracy 1.000\n",
      "Epoch 0, Iteration 186, loss 0.232, batch accuracy 1.000\n",
      "Epoch 0, Iteration 187, loss 0.314, batch accuracy 0.900\n",
      "Epoch 0, Iteration 188, loss 0.293, batch accuracy 0.900\n",
      "Epoch 0, Iteration 189, loss 0.116, batch accuracy 1.000\n",
      "Epoch 0, Iteration 190, loss 0.696, batch accuracy 0.800\n",
      "Epoch 0, Iteration 191, loss 0.217, batch accuracy 0.900\n",
      "Epoch 0, Iteration 192, loss 0.559, batch accuracy 0.900\n",
      "Epoch 0, Iteration 193, loss 0.480, batch accuracy 0.800\n",
      "Epoch 0, Iteration 194, loss 0.098, batch accuracy 1.000\n",
      "Epoch 0, Iteration 195, loss 0.130, batch accuracy 0.900\n",
      "Epoch 0, Iteration 196, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 197, loss 0.138, batch accuracy 1.000\n",
      "Epoch 0, Iteration 198, loss 0.372, batch accuracy 0.800\n",
      "Epoch 0, Iteration 199, loss 0.381, batch accuracy 0.800\n",
      "Epoch 0, Iteration 200, loss 0.395, batch accuracy 0.900\n",
      "Epoch 0, Iteration 201, loss 0.848, batch accuracy 0.900\n",
      "Epoch 0, Iteration 202, loss 0.474, batch accuracy 0.800\n",
      "Epoch 0, Iteration 203, loss 0.144, batch accuracy 0.900\n",
      "Epoch 0, Iteration 204, loss 0.320, batch accuracy 0.900\n",
      "Epoch 0, Iteration 205, loss 0.899, batch accuracy 0.600\n",
      "Epoch 0, Iteration 206, loss 0.202, batch accuracy 0.900\n",
      "Epoch 0, Iteration 207, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 208, loss 0.542, batch accuracy 0.800\n",
      "Epoch 0, Iteration 209, loss 0.402, batch accuracy 0.900\n",
      "Epoch 0, Iteration 210, loss 0.093, batch accuracy 1.000\n",
      "Epoch 0, Iteration 211, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 212, loss 0.662, batch accuracy 0.700\n",
      "Epoch 0, Iteration 213, loss 0.203, batch accuracy 1.000\n",
      "Epoch 0, Iteration 214, loss 0.704, batch accuracy 0.700\n",
      "Epoch 0, Iteration 215, loss 0.189, batch accuracy 0.900\n",
      "Epoch 0, Iteration 216, loss 0.257, batch accuracy 0.900\n",
      "Epoch 0, Iteration 217, loss 0.914, batch accuracy 0.800\n",
      "Epoch 0, Iteration 218, loss 0.539, batch accuracy 0.900\n",
      "Epoch 0, Iteration 219, loss 0.279, batch accuracy 0.900\n",
      "Epoch 0, Iteration 220, loss 0.144, batch accuracy 1.000\n",
      "Epoch 0, Iteration 221, loss 0.134, batch accuracy 1.000\n",
      "Epoch 0, Iteration 222, loss 0.270, batch accuracy 0.800\n",
      "Epoch 0, Iteration 223, loss 0.117, batch accuracy 1.000\n",
      "Epoch 0, Iteration 224, loss 0.357, batch accuracy 0.900\n",
      "Epoch 0, Iteration 225, loss 0.227, batch accuracy 1.000\n",
      "Epoch 0, Iteration 226, loss 0.138, batch accuracy 0.900\n",
      "Epoch 0, Iteration 227, loss 0.262, batch accuracy 0.900\n",
      "Epoch 0, Iteration 228, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 229, loss 0.060, batch accuracy 1.000\n",
      "Epoch 0, Iteration 230, loss 0.308, batch accuracy 0.900\n",
      "Epoch 0, Iteration 231, loss 0.124, batch accuracy 1.000\n",
      "Epoch 0, Iteration 232, loss 0.083, batch accuracy 1.000\n",
      "Epoch 0, Iteration 233, loss 0.290, batch accuracy 0.800\n",
      "Epoch 0, Iteration 234, loss 0.194, batch accuracy 1.000\n",
      "Epoch 0, Iteration 235, loss 0.600, batch accuracy 0.800\n",
      "Epoch 0, Iteration 236, loss 0.578, batch accuracy 0.900\n",
      "Epoch 0, Iteration 237, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 238, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 239, loss 0.211, batch accuracy 0.900\n",
      "Epoch 0, Iteration 240, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 241, loss 0.099, batch accuracy 1.000\n",
      "Epoch 0, Iteration 242, loss 0.060, batch accuracy 1.000\n",
      "Epoch 0, Iteration 243, loss 0.387, batch accuracy 0.900\n",
      "Epoch 0, Iteration 244, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 245, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 246, loss 0.276, batch accuracy 0.900\n",
      "Epoch 0, Iteration 247, loss 0.222, batch accuracy 0.900\n",
      "Epoch 0, Iteration 248, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 249, loss 0.630, batch accuracy 0.700\n",
      "Epoch 0, Iteration 250, loss 0.099, batch accuracy 1.000\n",
      "Epoch 0, Iteration 251, loss 0.850, batch accuracy 0.700\n",
      "Epoch 0, Iteration 252, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 253, loss 0.092, batch accuracy 1.000\n",
      "Epoch 0, Iteration 254, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 255, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 256, loss 0.133, batch accuracy 0.900\n",
      "Epoch 0, Iteration 257, loss 0.140, batch accuracy 0.900\n",
      "Epoch 0, Iteration 258, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 259, loss 0.075, batch accuracy 1.000\n",
      "Epoch 0, Iteration 260, loss 0.687, batch accuracy 0.900\n",
      "Epoch 0, Iteration 261, loss 0.615, batch accuracy 0.800\n",
      "Epoch 0, Iteration 262, loss 0.098, batch accuracy 1.000\n",
      "Epoch 0, Iteration 263, loss 0.901, batch accuracy 0.900\n",
      "Epoch 0, Iteration 264, loss 0.383, batch accuracy 0.900\n",
      "Epoch 0, Iteration 265, loss 0.259, batch accuracy 0.900\n",
      "Epoch 0, Iteration 266, loss 0.213, batch accuracy 0.900\n",
      "Epoch 0, Iteration 267, loss 0.151, batch accuracy 1.000\n",
      "Epoch 0, Iteration 268, loss 0.821, batch accuracy 0.700\n",
      "Epoch 0, Iteration 269, loss 0.182, batch accuracy 0.900\n",
      "Epoch 0, Iteration 270, loss 0.176, batch accuracy 0.900\n",
      "Epoch 0, Iteration 271, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 272, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 273, loss 0.530, batch accuracy 0.800\n",
      "Epoch 0, Iteration 274, loss 0.239, batch accuracy 0.900\n",
      "Epoch 0, Iteration 275, loss 0.617, batch accuracy 0.900\n",
      "Epoch 0, Iteration 276, loss 0.355, batch accuracy 0.800\n",
      "Epoch 0, Iteration 277, loss 0.288, batch accuracy 0.900\n",
      "Epoch 0, Iteration 278, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 279, loss 0.850, batch accuracy 0.900\n",
      "Epoch 0, Iteration 280, loss 0.072, batch accuracy 1.000\n",
      "Epoch 0, Iteration 281, loss 0.488, batch accuracy 0.900\n",
      "Epoch 0, Iteration 282, loss 0.409, batch accuracy 0.700\n",
      "Epoch 0, Iteration 283, loss 0.135, batch accuracy 0.900\n",
      "Epoch 0, Iteration 284, loss 0.319, batch accuracy 0.800\n",
      "Epoch 0, Iteration 285, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 286, loss 0.215, batch accuracy 0.900\n",
      "Epoch 0, Iteration 287, loss 0.326, batch accuracy 0.900\n",
      "Epoch 0, Iteration 288, loss 0.222, batch accuracy 0.900\n",
      "Epoch 0, Iteration 289, loss 0.638, batch accuracy 0.800\n",
      "Epoch 0, Iteration 290, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 291, loss 0.215, batch accuracy 1.000\n",
      "Epoch 0, Iteration 292, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 293, loss 0.239, batch accuracy 0.900\n",
      "Epoch 0, Iteration 294, loss 0.570, batch accuracy 0.800\n",
      "Epoch 0, Iteration 295, loss 0.220, batch accuracy 0.900\n",
      "Epoch 0, Iteration 296, loss 0.648, batch accuracy 0.900\n",
      "Epoch 0, Iteration 297, loss 0.139, batch accuracy 0.900\n",
      "Epoch 0, Iteration 298, loss 0.084, batch accuracy 1.000\n",
      "Epoch 0, Iteration 299, loss 0.110, batch accuracy 0.900\n",
      "Epoch 0, Iteration 300, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 301, loss 0.223, batch accuracy 0.900\n",
      "Epoch 0, Iteration 302, loss 0.081, batch accuracy 1.000\n",
      "Epoch 0, Iteration 303, loss 0.515, batch accuracy 0.800\n",
      "Epoch 0, Iteration 304, loss 0.685, batch accuracy 0.800\n",
      "Epoch 0, Iteration 305, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 306, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 307, loss 0.124, batch accuracy 0.900\n",
      "Epoch 0, Iteration 308, loss 0.220, batch accuracy 0.900\n",
      "Epoch 0, Iteration 309, loss 0.524, batch accuracy 0.700\n",
      "Epoch 0, Iteration 310, loss 0.168, batch accuracy 0.900\n",
      "Epoch 0, Iteration 311, loss 0.127, batch accuracy 0.900\n",
      "Epoch 0, Iteration 312, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 313, loss 0.115, batch accuracy 1.000\n",
      "Epoch 0, Iteration 314, loss 0.341, batch accuracy 0.800\n",
      "Epoch 0, Iteration 315, loss 0.104, batch accuracy 1.000\n",
      "Epoch 0, Iteration 316, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 317, loss 0.081, batch accuracy 1.000\n",
      "Epoch 0, Iteration 318, loss 0.334, batch accuracy 0.900\n",
      "Epoch 0, Iteration 319, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 320, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 321, loss 0.220, batch accuracy 0.800\n",
      "Epoch 0, Iteration 322, loss 0.963, batch accuracy 0.800\n",
      "Epoch 0, Iteration 323, loss 0.138, batch accuracy 1.000\n",
      "Epoch 0, Iteration 324, loss 0.090, batch accuracy 1.000\n",
      "Epoch 0, Iteration 325, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 326, loss 0.158, batch accuracy 0.900\n",
      "Epoch 0, Iteration 327, loss 0.979, batch accuracy 0.900\n",
      "Epoch 0, Iteration 328, loss 0.704, batch accuracy 0.900\n",
      "Epoch 0, Iteration 329, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 330, loss 0.447, batch accuracy 0.800\n",
      "Epoch 0, Iteration 331, loss 0.706, batch accuracy 0.900\n",
      "Epoch 0, Iteration 332, loss 0.109, batch accuracy 1.000\n",
      "Epoch 0, Iteration 333, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 334, loss 0.212, batch accuracy 0.900\n",
      "Epoch 0, Iteration 335, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 336, loss 0.159, batch accuracy 0.900\n",
      "Epoch 0, Iteration 337, loss 0.303, batch accuracy 0.800\n",
      "Epoch 0, Iteration 338, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 339, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 340, loss 0.256, batch accuracy 0.800\n",
      "Epoch 0, Iteration 341, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 342, loss 0.127, batch accuracy 1.000\n",
      "Epoch 0, Iteration 343, loss 0.220, batch accuracy 0.900\n",
      "Epoch 0, Iteration 344, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 345, loss 0.387, batch accuracy 0.900\n",
      "Epoch 0, Iteration 346, loss 0.120, batch accuracy 1.000\n",
      "Epoch 0, Iteration 347, loss 0.388, batch accuracy 0.900\n",
      "Epoch 0, Iteration 348, loss 0.130, batch accuracy 1.000\n",
      "Epoch 0, Iteration 349, loss 0.273, batch accuracy 0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 350, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 351, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 352, loss 0.092, batch accuracy 1.000\n",
      "Epoch 0, Iteration 353, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 354, loss 0.240, batch accuracy 0.900\n",
      "Epoch 0, Iteration 355, loss 1.140, batch accuracy 0.800\n",
      "Epoch 0, Iteration 356, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 357, loss 0.339, batch accuracy 0.800\n",
      "Epoch 0, Iteration 358, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 359, loss 0.445, batch accuracy 0.900\n",
      "Epoch 0, Iteration 360, loss 0.487, batch accuracy 0.900\n",
      "Epoch 0, Iteration 361, loss 0.164, batch accuracy 0.900\n",
      "Epoch 0, Iteration 362, loss 0.154, batch accuracy 1.000\n",
      "Epoch 0, Iteration 363, loss 0.361, batch accuracy 0.900\n",
      "Epoch 0, Iteration 364, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 365, loss 0.563, batch accuracy 0.800\n",
      "Epoch 0, Iteration 366, loss 0.493, batch accuracy 0.800\n",
      "Epoch 0, Iteration 367, loss 0.281, batch accuracy 0.900\n",
      "Epoch 0, Iteration 368, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 369, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 370, loss 0.945, batch accuracy 0.700\n",
      "Epoch 0, Iteration 371, loss 0.406, batch accuracy 0.900\n",
      "Epoch 0, Iteration 372, loss 0.409, batch accuracy 0.900\n",
      "Epoch 0, Iteration 373, loss 0.274, batch accuracy 0.800\n",
      "Epoch 0, Iteration 374, loss 0.412, batch accuracy 0.800\n",
      "Epoch 0, Iteration 375, loss 0.130, batch accuracy 1.000\n",
      "Epoch 0, Iteration 376, loss 0.165, batch accuracy 1.000\n",
      "Epoch 0, Iteration 377, loss 0.750, batch accuracy 0.800\n",
      "Epoch 0, Iteration 378, loss 0.323, batch accuracy 0.900\n",
      "Epoch 0, Iteration 379, loss 0.431, batch accuracy 0.800\n",
      "Epoch 0, Iteration 380, loss 0.166, batch accuracy 0.900\n",
      "Epoch 0, Iteration 381, loss 0.127, batch accuracy 1.000\n",
      "Epoch 0, Iteration 382, loss 0.126, batch accuracy 1.000\n",
      "Epoch 0, Iteration 383, loss 0.358, batch accuracy 0.900\n",
      "Epoch 0, Iteration 384, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 385, loss 0.866, batch accuracy 0.900\n",
      "Epoch 0, Iteration 386, loss 0.240, batch accuracy 0.900\n",
      "Epoch 0, Iteration 387, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 388, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 389, loss 0.311, batch accuracy 0.900\n",
      "Epoch 0, Iteration 390, loss 0.513, batch accuracy 0.800\n",
      "Epoch 0, Iteration 391, loss 0.267, batch accuracy 0.900\n",
      "Epoch 0, Iteration 392, loss 0.507, batch accuracy 0.800\n",
      "Epoch 0, Iteration 393, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 394, loss 0.109, batch accuracy 1.000\n",
      "Epoch 0, Iteration 395, loss 0.689, batch accuracy 0.800\n",
      "Epoch 0, Iteration 396, loss 0.437, batch accuracy 0.800\n",
      "Epoch 0, Iteration 397, loss 0.104, batch accuracy 0.900\n",
      "Epoch 0, Iteration 398, loss 0.125, batch accuracy 1.000\n",
      "Epoch 0, Iteration 399, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 400, loss 0.092, batch accuracy 1.000\n",
      "Epoch 0, Iteration 401, loss 0.303, batch accuracy 0.900\n",
      "Epoch 0, Iteration 402, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 403, loss 0.494, batch accuracy 0.800\n",
      "Epoch 0, Iteration 404, loss 1.068, batch accuracy 0.800\n",
      "Epoch 0, Iteration 405, loss 0.555, batch accuracy 0.900\n",
      "Epoch 0, Iteration 406, loss 0.780, batch accuracy 0.800\n",
      "Epoch 0, Iteration 407, loss 0.165, batch accuracy 1.000\n",
      "Epoch 0, Iteration 408, loss 0.908, batch accuracy 0.900\n",
      "Epoch 0, Iteration 409, loss 0.341, batch accuracy 0.800\n",
      "Epoch 0, Iteration 410, loss 0.101, batch accuracy 1.000\n",
      "Epoch 0, Iteration 411, loss 0.212, batch accuracy 0.900\n",
      "Epoch 0, Iteration 412, loss 0.164, batch accuracy 0.900\n",
      "Epoch 0, Iteration 413, loss 0.110, batch accuracy 1.000\n",
      "Epoch 0, Iteration 414, loss 0.113, batch accuracy 1.000\n",
      "Epoch 0, Iteration 415, loss 0.084, batch accuracy 1.000\n",
      "Epoch 0, Iteration 416, loss 0.093, batch accuracy 1.000\n",
      "Epoch 0, Iteration 417, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 418, loss 0.256, batch accuracy 0.900\n",
      "Epoch 0, Iteration 419, loss 0.097, batch accuracy 1.000\n",
      "Epoch 0, Iteration 420, loss 0.184, batch accuracy 0.900\n",
      "Epoch 0, Iteration 421, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 422, loss 0.152, batch accuracy 1.000\n",
      "Epoch 0, Iteration 423, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 424, loss 0.374, batch accuracy 0.900\n",
      "Epoch 0, Iteration 425, loss 0.823, batch accuracy 0.900\n",
      "Epoch 0, Iteration 426, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 427, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 428, loss 0.852, batch accuracy 0.700\n",
      "Epoch 0, Iteration 429, loss 0.343, batch accuracy 0.800\n",
      "Epoch 0, Iteration 430, loss 0.490, batch accuracy 0.900\n",
      "Epoch 0, Iteration 431, loss 0.108, batch accuracy 0.900\n",
      "Epoch 0, Iteration 432, loss 0.372, batch accuracy 0.900\n",
      "Epoch 0, Iteration 433, loss 0.157, batch accuracy 1.000\n",
      "Epoch 0, Iteration 434, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 435, loss 0.163, batch accuracy 0.900\n",
      "Epoch 0, Iteration 436, loss 0.403, batch accuracy 0.900\n",
      "Epoch 0, Iteration 437, loss 0.076, batch accuracy 1.000\n",
      "Epoch 0, Iteration 438, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 439, loss 0.153, batch accuracy 0.900\n",
      "Epoch 0, Iteration 440, loss 0.158, batch accuracy 0.900\n",
      "Epoch 0, Iteration 441, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 442, loss 0.667, batch accuracy 0.900\n",
      "Epoch 0, Iteration 443, loss 0.273, batch accuracy 0.900\n",
      "Epoch 0, Iteration 444, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 445, loss 0.481, batch accuracy 0.900\n",
      "Epoch 0, Iteration 446, loss 0.362, batch accuracy 0.900\n",
      "Epoch 0, Iteration 447, loss 0.119, batch accuracy 1.000\n",
      "Epoch 0, Iteration 448, loss 0.671, batch accuracy 0.700\n",
      "Epoch 0, Iteration 449, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 450, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 451, loss 0.052, batch accuracy 1.000\n",
      "Epoch 0, Iteration 452, loss 0.276, batch accuracy 0.900\n",
      "Epoch 0, Iteration 453, loss 0.270, batch accuracy 0.900\n",
      "Epoch 0, Iteration 454, loss 0.282, batch accuracy 0.800\n",
      "Epoch 0, Iteration 455, loss 0.112, batch accuracy 1.000\n",
      "Epoch 0, Iteration 456, loss 0.792, batch accuracy 0.800\n",
      "Epoch 0, Iteration 457, loss 0.427, batch accuracy 0.800\n",
      "Epoch 0, Iteration 458, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 459, loss 0.275, batch accuracy 0.800\n",
      "Epoch 0, Iteration 460, loss 0.156, batch accuracy 1.000\n",
      "Epoch 0, Iteration 461, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 462, loss 0.333, batch accuracy 0.900\n",
      "Epoch 0, Iteration 463, loss 0.740, batch accuracy 0.900\n",
      "Epoch 0, Iteration 464, loss 0.072, batch accuracy 1.000\n",
      "Epoch 0, Iteration 465, loss 0.653, batch accuracy 0.800\n",
      "Epoch 0, Iteration 466, loss 0.142, batch accuracy 0.900\n",
      "Epoch 0, Iteration 467, loss 0.602, batch accuracy 0.900\n",
      "Epoch 0, Iteration 468, loss 0.079, batch accuracy 1.000\n",
      "Epoch 0, Iteration 469, loss 0.107, batch accuracy 1.000\n",
      "Epoch 0, Iteration 470, loss 0.108, batch accuracy 1.000\n",
      "Epoch 0, Iteration 471, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 472, loss 0.600, batch accuracy 0.800\n",
      "Epoch 0, Iteration 473, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 474, loss 0.680, batch accuracy 0.800\n",
      "Epoch 0, Iteration 475, loss 0.501, batch accuracy 0.800\n",
      "Epoch 0, Iteration 476, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 477, loss 0.560, batch accuracy 0.800\n",
      "Epoch 0, Iteration 478, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 479, loss 1.013, batch accuracy 0.700\n",
      "Epoch 0, Iteration 480, loss 0.235, batch accuracy 0.900\n",
      "Epoch 0, Iteration 481, loss 0.172, batch accuracy 0.900\n",
      "Epoch 0, Iteration 482, loss 0.074, batch accuracy 1.000\n",
      "Epoch 0, Iteration 483, loss 0.086, batch accuracy 1.000\n",
      "Epoch 0, Iteration 484, loss 0.089, batch accuracy 1.000\n",
      "Epoch 0, Iteration 485, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 486, loss 0.244, batch accuracy 0.900\n",
      "Epoch 0, Iteration 487, loss 0.369, batch accuracy 0.700\n",
      "Epoch 0, Iteration 488, loss 0.201, batch accuracy 0.900\n",
      "Epoch 0, Iteration 489, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 490, loss 0.258, batch accuracy 0.800\n",
      "Epoch 0, Iteration 491, loss 0.129, batch accuracy 0.900\n",
      "Epoch 0, Iteration 492, loss 0.825, batch accuracy 0.800\n",
      "Epoch 0, Iteration 493, loss 0.452, batch accuracy 0.800\n",
      "Epoch 0, Iteration 494, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 495, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 496, loss 0.323, batch accuracy 0.800\n",
      "Epoch 0, Iteration 497, loss 0.211, batch accuracy 0.900\n",
      "Epoch 0, Iteration 498, loss 0.334, batch accuracy 0.900\n",
      "Epoch 0, Iteration 499, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 500, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 501, loss 0.169, batch accuracy 0.900\n",
      "Epoch 0, Iteration 502, loss 0.193, batch accuracy 1.000\n",
      "Epoch 0, Iteration 503, loss 0.078, batch accuracy 1.000\n",
      "Epoch 0, Iteration 504, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 505, loss 0.075, batch accuracy 1.000\n",
      "Epoch 0, Iteration 506, loss 0.070, batch accuracy 1.000\n",
      "Epoch 0, Iteration 507, loss 0.339, batch accuracy 0.800\n",
      "Epoch 0, Iteration 508, loss 0.227, batch accuracy 0.900\n",
      "Epoch 0, Iteration 509, loss 0.214, batch accuracy 0.900\n",
      "Epoch 0, Iteration 510, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 511, loss 0.418, batch accuracy 0.700\n",
      "Epoch 0, Iteration 512, loss 0.315, batch accuracy 0.800\n",
      "Epoch 0, Iteration 513, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 514, loss 0.411, batch accuracy 0.900\n",
      "Epoch 0, Iteration 515, loss 0.144, batch accuracy 1.000\n",
      "Epoch 0, Iteration 516, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 517, loss 0.413, batch accuracy 0.800\n",
      "Epoch 0, Iteration 518, loss 0.123, batch accuracy 1.000\n",
      "Epoch 0, Iteration 519, loss 0.390, batch accuracy 0.900\n",
      "Epoch 0, Iteration 520, loss 0.359, batch accuracy 0.900\n",
      "Epoch 0, Iteration 521, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 522, loss 0.367, batch accuracy 0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 523, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 524, loss 0.300, batch accuracy 0.800\n",
      "Epoch 0, Iteration 525, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 526, loss 0.185, batch accuracy 1.000\n",
      "Epoch 0, Iteration 527, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 528, loss 0.344, batch accuracy 0.900\n",
      "Epoch 0, Iteration 529, loss 0.114, batch accuracy 0.900\n",
      "Epoch 0, Iteration 530, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 531, loss 0.072, batch accuracy 1.000\n",
      "Epoch 0, Iteration 532, loss 0.464, batch accuracy 0.900\n",
      "Epoch 0, Iteration 533, loss 0.873, batch accuracy 0.900\n",
      "Epoch 0, Iteration 534, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 535, loss 0.105, batch accuracy 1.000\n",
      "Epoch 0, Iteration 536, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 537, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 538, loss 0.537, batch accuracy 0.700\n",
      "Epoch 0, Iteration 539, loss 0.444, batch accuracy 0.800\n",
      "Epoch 0, Iteration 540, loss 0.320, batch accuracy 0.900\n",
      "Epoch 0, Iteration 541, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 542, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 543, loss 0.279, batch accuracy 0.900\n",
      "Epoch 0, Iteration 544, loss 0.128, batch accuracy 1.000\n",
      "Epoch 0, Iteration 545, loss 0.113, batch accuracy 1.000\n",
      "Epoch 0, Iteration 546, loss 0.650, batch accuracy 0.900\n",
      "Epoch 0, Iteration 547, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 548, loss 0.060, batch accuracy 1.000\n",
      "Epoch 0, Iteration 549, loss 0.596, batch accuracy 0.900\n",
      "Epoch 0, Iteration 550, loss 0.085, batch accuracy 1.000\n",
      "Epoch 0, Iteration 551, loss 0.261, batch accuracy 0.900\n",
      "Epoch 0, Iteration 552, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 553, loss 0.300, batch accuracy 0.900\n",
      "Epoch 0, Iteration 554, loss 0.376, batch accuracy 0.900\n",
      "Epoch 0, Iteration 555, loss 0.150, batch accuracy 0.900\n",
      "Epoch 0, Iteration 556, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 557, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 558, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 559, loss 0.181, batch accuracy 1.000\n",
      "Epoch 0, Iteration 560, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 561, loss 0.509, batch accuracy 0.900\n",
      "Epoch 0, Iteration 562, loss 0.161, batch accuracy 0.900\n",
      "Epoch 0, Iteration 563, loss 0.242, batch accuracy 0.900\n",
      "Epoch 0, Iteration 564, loss 0.086, batch accuracy 1.000\n",
      "Epoch 0, Iteration 565, loss 0.727, batch accuracy 0.800\n",
      "Epoch 0, Iteration 566, loss 0.085, batch accuracy 1.000\n",
      "Epoch 0, Iteration 567, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 568, loss 0.215, batch accuracy 0.900\n",
      "Epoch 0, Iteration 569, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 570, loss 0.299, batch accuracy 0.900\n",
      "Epoch 0, Iteration 571, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 572, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 573, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 574, loss 0.663, batch accuracy 0.900\n",
      "Epoch 0, Iteration 575, loss 0.152, batch accuracy 0.900\n",
      "Epoch 0, Iteration 576, loss 0.429, batch accuracy 0.800\n",
      "Epoch 0, Iteration 577, loss 0.287, batch accuracy 0.800\n",
      "Epoch 0, Iteration 578, loss 0.299, batch accuracy 0.900\n",
      "Epoch 0, Iteration 579, loss 0.291, batch accuracy 0.900\n",
      "Epoch 0, Iteration 580, loss 0.380, batch accuracy 0.900\n",
      "Epoch 0, Iteration 581, loss 0.388, batch accuracy 0.800\n",
      "Epoch 0, Iteration 582, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 583, loss 0.290, batch accuracy 0.900\n",
      "Epoch 0, Iteration 584, loss 0.136, batch accuracy 0.900\n",
      "Epoch 0, Iteration 585, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 586, loss 0.628, batch accuracy 0.800\n",
      "Epoch 0, Iteration 587, loss 0.161, batch accuracy 1.000\n",
      "Epoch 0, Iteration 588, loss 0.116, batch accuracy 1.000\n",
      "Epoch 0, Iteration 589, loss 0.185, batch accuracy 0.900\n",
      "Epoch 0, Iteration 590, loss 0.402, batch accuracy 0.800\n",
      "Epoch 0, Iteration 591, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 592, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 593, loss 0.126, batch accuracy 1.000\n",
      "Epoch 0, Iteration 594, loss 0.140, batch accuracy 0.900\n",
      "Epoch 0, Iteration 595, loss 0.585, batch accuracy 0.900\n",
      "Epoch 0, Iteration 596, loss 0.227, batch accuracy 0.900\n",
      "Epoch 0, Iteration 597, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 598, loss 0.235, batch accuracy 0.900\n",
      "Epoch 0, Iteration 599, loss 0.280, batch accuracy 0.800\n",
      "Epoch 0, Iteration 600, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 601, loss 0.096, batch accuracy 1.000\n",
      "Epoch 0, Iteration 602, loss 0.075, batch accuracy 1.000\n",
      "Epoch 0, Iteration 603, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 604, loss 0.095, batch accuracy 1.000\n",
      "Epoch 0, Iteration 605, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 606, loss 0.520, batch accuracy 0.800\n",
      "Epoch 0, Iteration 607, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 608, loss 0.415, batch accuracy 0.900\n",
      "Epoch 0, Iteration 609, loss 0.052, batch accuracy 1.000\n",
      "Epoch 0, Iteration 610, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 611, loss 0.084, batch accuracy 1.000\n",
      "Epoch 0, Iteration 612, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 613, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 614, loss 0.746, batch accuracy 0.800\n",
      "Epoch 0, Iteration 615, loss 0.321, batch accuracy 0.900\n",
      "Epoch 0, Iteration 616, loss 0.113, batch accuracy 1.000\n",
      "Epoch 0, Iteration 617, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 618, loss 0.964, batch accuracy 0.800\n",
      "Epoch 0, Iteration 619, loss 0.258, batch accuracy 0.900\n",
      "Epoch 0, Iteration 620, loss 0.128, batch accuracy 1.000\n",
      "Epoch 0, Iteration 621, loss 0.350, batch accuracy 0.800\n",
      "Epoch 0, Iteration 622, loss 0.293, batch accuracy 0.900\n",
      "Epoch 0, Iteration 623, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 624, loss 0.346, batch accuracy 0.900\n",
      "Epoch 0, Iteration 625, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 626, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 627, loss 0.953, batch accuracy 0.900\n",
      "Epoch 0, Iteration 628, loss 1.214, batch accuracy 0.700\n",
      "Epoch 0, Iteration 629, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 630, loss 0.106, batch accuracy 1.000\n",
      "Epoch 0, Iteration 631, loss 0.401, batch accuracy 0.700\n",
      "Epoch 0, Iteration 632, loss 0.111, batch accuracy 0.900\n",
      "Epoch 0, Iteration 633, loss 0.110, batch accuracy 0.900\n",
      "Epoch 0, Iteration 634, loss 0.472, batch accuracy 0.900\n",
      "Epoch 0, Iteration 635, loss 0.155, batch accuracy 0.900\n",
      "Epoch 0, Iteration 636, loss 0.119, batch accuracy 1.000\n",
      "Epoch 0, Iteration 637, loss 0.167, batch accuracy 0.900\n",
      "Epoch 0, Iteration 638, loss 0.095, batch accuracy 1.000\n",
      "Epoch 0, Iteration 639, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 640, loss 0.186, batch accuracy 0.900\n",
      "Epoch 0, Iteration 641, loss 0.159, batch accuracy 0.900\n",
      "Epoch 0, Iteration 642, loss 0.165, batch accuracy 1.000\n",
      "Epoch 0, Iteration 643, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 644, loss 0.128, batch accuracy 1.000\n",
      "Epoch 0, Iteration 645, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 646, loss 0.115, batch accuracy 1.000\n",
      "Epoch 0, Iteration 647, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 648, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 649, loss 0.094, batch accuracy 1.000\n",
      "Epoch 0, Iteration 650, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 651, loss 0.154, batch accuracy 0.900\n",
      "Epoch 0, Iteration 652, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 653, loss 0.120, batch accuracy 0.900\n",
      "Epoch 0, Iteration 654, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 655, loss 0.478, batch accuracy 0.900\n",
      "Epoch 0, Iteration 656, loss 0.060, batch accuracy 1.000\n",
      "Epoch 0, Iteration 657, loss 0.206, batch accuracy 0.900\n",
      "Epoch 0, Iteration 658, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 659, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 660, loss 0.685, batch accuracy 0.800\n",
      "Epoch 0, Iteration 661, loss 0.195, batch accuracy 0.900\n",
      "Epoch 0, Iteration 662, loss 0.194, batch accuracy 0.900\n",
      "Epoch 0, Iteration 663, loss 0.083, batch accuracy 0.900\n",
      "Epoch 0, Iteration 664, loss 0.230, batch accuracy 0.900\n",
      "Epoch 0, Iteration 665, loss 0.507, batch accuracy 0.800\n",
      "Epoch 0, Iteration 666, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 667, loss 0.265, batch accuracy 0.900\n",
      "Epoch 0, Iteration 668, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 669, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 670, loss 0.088, batch accuracy 1.000\n",
      "Epoch 0, Iteration 671, loss 0.072, batch accuracy 1.000\n",
      "Epoch 0, Iteration 672, loss 0.242, batch accuracy 0.900\n",
      "Epoch 0, Iteration 673, loss 0.166, batch accuracy 1.000\n",
      "Epoch 0, Iteration 674, loss 0.226, batch accuracy 0.900\n",
      "Epoch 0, Iteration 675, loss 0.266, batch accuracy 0.900\n",
      "Epoch 0, Iteration 676, loss 0.329, batch accuracy 0.900\n",
      "Epoch 0, Iteration 677, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 678, loss 0.061, batch accuracy 1.000\n",
      "Epoch 0, Iteration 679, loss 0.134, batch accuracy 0.900\n",
      "Epoch 0, Iteration 680, loss 0.090, batch accuracy 1.000\n",
      "Epoch 0, Iteration 681, loss 0.292, batch accuracy 0.800\n",
      "Epoch 0, Iteration 682, loss 0.215, batch accuracy 0.900\n",
      "Epoch 0, Iteration 683, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 684, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 685, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 686, loss 0.160, batch accuracy 0.900\n",
      "Epoch 0, Iteration 687, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 688, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 689, loss 0.351, batch accuracy 0.800\n",
      "Epoch 0, Iteration 690, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 691, loss 0.202, batch accuracy 0.900\n",
      "Epoch 0, Iteration 692, loss 0.790, batch accuracy 0.900\n",
      "Epoch 0, Iteration 693, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 694, loss 0.154, batch accuracy 1.000\n",
      "Epoch 0, Iteration 695, loss 0.180, batch accuracy 0.900\n",
      "Epoch 0, Iteration 696, loss 0.294, batch accuracy 0.900\n",
      "Epoch 0, Iteration 697, loss 0.259, batch accuracy 0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 698, loss 0.115, batch accuracy 1.000\n",
      "Epoch 0, Iteration 699, loss 0.101, batch accuracy 1.000\n",
      "Epoch 0, Iteration 700, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 701, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 702, loss 0.061, batch accuracy 1.000\n",
      "Epoch 0, Iteration 703, loss 0.288, batch accuracy 0.900\n",
      "Epoch 0, Iteration 704, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 705, loss 0.072, batch accuracy 1.000\n",
      "Epoch 0, Iteration 706, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 707, loss 0.138, batch accuracy 0.900\n",
      "Epoch 0, Iteration 708, loss 0.102, batch accuracy 1.000\n",
      "Epoch 0, Iteration 709, loss 0.116, batch accuracy 1.000\n",
      "Epoch 0, Iteration 710, loss 0.780, batch accuracy 0.900\n",
      "Epoch 0, Iteration 711, loss 0.128, batch accuracy 0.900\n",
      "Epoch 0, Iteration 712, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 713, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 714, loss 0.287, batch accuracy 0.900\n",
      "Epoch 0, Iteration 715, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 716, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 717, loss 0.074, batch accuracy 1.000\n",
      "Epoch 0, Iteration 718, loss 0.158, batch accuracy 0.900\n",
      "Epoch 0, Iteration 719, loss 0.506, batch accuracy 0.900\n",
      "Epoch 0, Iteration 720, loss 0.266, batch accuracy 0.900\n",
      "Epoch 0, Iteration 721, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 722, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 723, loss 0.422, batch accuracy 0.900\n",
      "Epoch 0, Iteration 724, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 725, loss 0.143, batch accuracy 0.900\n",
      "Epoch 0, Iteration 726, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 727, loss 0.149, batch accuracy 0.900\n",
      "Epoch 0, Iteration 728, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 729, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 730, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 731, loss 0.119, batch accuracy 0.900\n",
      "Epoch 0, Iteration 732, loss 0.129, batch accuracy 1.000\n",
      "Epoch 0, Iteration 733, loss 0.504, batch accuracy 0.900\n",
      "Epoch 0, Iteration 734, loss 0.316, batch accuracy 0.900\n",
      "Epoch 0, Iteration 735, loss 0.152, batch accuracy 1.000\n",
      "Epoch 0, Iteration 736, loss 0.446, batch accuracy 0.800\n",
      "Epoch 0, Iteration 737, loss 0.452, batch accuracy 0.900\n",
      "Epoch 0, Iteration 738, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 739, loss 0.225, batch accuracy 0.900\n",
      "Epoch 0, Iteration 740, loss 0.257, batch accuracy 0.900\n",
      "Epoch 0, Iteration 741, loss 0.374, batch accuracy 0.900\n",
      "Epoch 0, Iteration 742, loss 1.152, batch accuracy 0.800\n",
      "Epoch 0, Iteration 743, loss 0.204, batch accuracy 0.900\n",
      "Epoch 0, Iteration 744, loss 0.077, batch accuracy 1.000\n",
      "Epoch 0, Iteration 745, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 746, loss 0.161, batch accuracy 0.900\n",
      "Epoch 0, Iteration 747, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 748, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 749, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 750, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 751, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 752, loss 0.104, batch accuracy 0.900\n",
      "Epoch 0, Iteration 753, loss 0.340, batch accuracy 0.900\n",
      "Epoch 0, Iteration 754, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 755, loss 0.319, batch accuracy 0.800\n",
      "Epoch 0, Iteration 756, loss 0.243, batch accuracy 0.900\n",
      "Epoch 0, Iteration 757, loss 0.941, batch accuracy 0.800\n",
      "Epoch 0, Iteration 758, loss 0.703, batch accuracy 0.800\n",
      "Epoch 0, Iteration 759, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 760, loss 0.717, batch accuracy 0.900\n",
      "Epoch 0, Iteration 761, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 762, loss 0.090, batch accuracy 1.000\n",
      "Epoch 0, Iteration 763, loss 0.162, batch accuracy 0.900\n",
      "Epoch 0, Iteration 764, loss 0.126, batch accuracy 1.000\n",
      "Epoch 0, Iteration 765, loss 0.325, batch accuracy 0.900\n",
      "Epoch 0, Iteration 766, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 767, loss 0.173, batch accuracy 0.900\n",
      "Epoch 0, Iteration 768, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 769, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 770, loss 0.579, batch accuracy 0.900\n",
      "Epoch 0, Iteration 771, loss 0.118, batch accuracy 0.900\n",
      "Epoch 0, Iteration 772, loss 0.163, batch accuracy 0.900\n",
      "Epoch 0, Iteration 773, loss 0.410, batch accuracy 0.900\n",
      "Epoch 0, Iteration 774, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 775, loss 0.331, batch accuracy 0.900\n",
      "Epoch 0, Iteration 776, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 777, loss 0.157, batch accuracy 0.900\n",
      "Epoch 0, Iteration 778, loss 0.310, batch accuracy 0.900\n",
      "Epoch 0, Iteration 779, loss 0.079, batch accuracy 1.000\n",
      "Epoch 0, Iteration 780, loss 0.195, batch accuracy 1.000\n",
      "Epoch 0, Iteration 781, loss 0.155, batch accuracy 0.900\n",
      "Epoch 0, Iteration 782, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 783, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 784, loss 0.258, batch accuracy 0.800\n",
      "Epoch 0, Iteration 785, loss 0.094, batch accuracy 1.000\n",
      "Epoch 0, Iteration 786, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 787, loss 0.486, batch accuracy 0.800\n",
      "Epoch 0, Iteration 788, loss 0.388, batch accuracy 0.900\n",
      "Epoch 0, Iteration 789, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 790, loss 0.156, batch accuracy 0.900\n",
      "Epoch 0, Iteration 791, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 792, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 793, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 794, loss 0.142, batch accuracy 0.900\n",
      "Epoch 0, Iteration 795, loss 0.469, batch accuracy 0.800\n",
      "Epoch 0, Iteration 796, loss 0.147, batch accuracy 0.900\n",
      "Epoch 0, Iteration 797, loss 0.123, batch accuracy 0.900\n",
      "Epoch 0, Iteration 798, loss 0.248, batch accuracy 0.900\n",
      "Epoch 0, Iteration 799, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 800, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 801, loss 0.315, batch accuracy 0.800\n",
      "Epoch 0, Iteration 802, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 803, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 804, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 805, loss 0.802, batch accuracy 0.900\n",
      "Epoch 0, Iteration 806, loss 0.089, batch accuracy 1.000\n",
      "Epoch 0, Iteration 807, loss 0.269, batch accuracy 0.800\n",
      "Epoch 0, Iteration 808, loss 0.187, batch accuracy 0.900\n",
      "Epoch 0, Iteration 809, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 810, loss 0.292, batch accuracy 0.900\n",
      "Epoch 0, Iteration 811, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 812, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 813, loss 0.094, batch accuracy 1.000\n",
      "Epoch 0, Iteration 814, loss 0.072, batch accuracy 1.000\n",
      "Epoch 0, Iteration 815, loss 0.133, batch accuracy 0.900\n",
      "Epoch 0, Iteration 816, loss 0.060, batch accuracy 1.000\n",
      "Epoch 0, Iteration 817, loss 0.119, batch accuracy 0.900\n",
      "Epoch 0, Iteration 818, loss 0.830, batch accuracy 0.900\n",
      "Epoch 0, Iteration 819, loss 0.216, batch accuracy 0.900\n",
      "Epoch 0, Iteration 820, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 821, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 822, loss 0.680, batch accuracy 0.900\n",
      "Epoch 0, Iteration 823, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 824, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 825, loss 0.392, batch accuracy 0.800\n",
      "Epoch 0, Iteration 826, loss 0.158, batch accuracy 1.000\n",
      "Epoch 0, Iteration 827, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 828, loss 0.205, batch accuracy 0.900\n",
      "Epoch 0, Iteration 829, loss 1.076, batch accuracy 0.700\n",
      "Epoch 0, Iteration 830, loss 0.085, batch accuracy 1.000\n",
      "Epoch 0, Iteration 831, loss 0.337, batch accuracy 0.900\n",
      "Epoch 0, Iteration 832, loss 0.136, batch accuracy 1.000\n",
      "Epoch 0, Iteration 833, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 834, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 835, loss 0.093, batch accuracy 1.000\n",
      "Epoch 0, Iteration 836, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 837, loss 0.272, batch accuracy 0.900\n",
      "Epoch 0, Iteration 838, loss 0.241, batch accuracy 0.900\n",
      "Epoch 0, Iteration 839, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 840, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 841, loss 0.303, batch accuracy 0.800\n",
      "Epoch 0, Iteration 842, loss 1.044, batch accuracy 0.900\n",
      "Epoch 0, Iteration 843, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 844, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 845, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 846, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 847, loss 1.334, batch accuracy 0.700\n",
      "Epoch 0, Iteration 848, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 849, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 850, loss 0.189, batch accuracy 0.900\n",
      "Epoch 0, Iteration 851, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 852, loss 0.268, batch accuracy 0.900\n",
      "Epoch 0, Iteration 853, loss 0.321, batch accuracy 0.900\n",
      "Epoch 0, Iteration 854, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 855, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 856, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 857, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 858, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 859, loss 0.611, batch accuracy 0.900\n",
      "Epoch 0, Iteration 860, loss 0.532, batch accuracy 0.900\n",
      "Epoch 0, Iteration 861, loss 0.089, batch accuracy 1.000\n",
      "Epoch 0, Iteration 862, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 863, loss 0.070, batch accuracy 1.000\n",
      "Epoch 0, Iteration 864, loss 0.093, batch accuracy 1.000\n",
      "Epoch 0, Iteration 865, loss 0.917, batch accuracy 0.900\n",
      "Epoch 0, Iteration 866, loss 0.143, batch accuracy 0.900\n",
      "Epoch 0, Iteration 867, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 868, loss 0.143, batch accuracy 0.900\n",
      "Epoch 0, Iteration 869, loss 0.205, batch accuracy 0.900\n",
      "Epoch 0, Iteration 870, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 871, loss 0.375, batch accuracy 0.900\n",
      "Epoch 0, Iteration 872, loss 0.288, batch accuracy 0.900\n",
      "Epoch 0, Iteration 873, loss 0.221, batch accuracy 0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 874, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 875, loss 0.118, batch accuracy 0.900\n",
      "Epoch 0, Iteration 876, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 877, loss 0.183, batch accuracy 0.900\n",
      "Epoch 0, Iteration 878, loss 0.199, batch accuracy 0.900\n",
      "Epoch 0, Iteration 879, loss 0.581, batch accuracy 0.900\n",
      "Epoch 0, Iteration 880, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 881, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 882, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 883, loss 0.192, batch accuracy 0.900\n",
      "Epoch 0, Iteration 884, loss 0.096, batch accuracy 1.000\n",
      "Epoch 0, Iteration 885, loss 0.096, batch accuracy 1.000\n",
      "Epoch 0, Iteration 886, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 887, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 888, loss 0.429, batch accuracy 0.800\n",
      "Epoch 0, Iteration 889, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 890, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 891, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 892, loss 0.052, batch accuracy 1.000\n",
      "Epoch 0, Iteration 893, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 894, loss 0.677, batch accuracy 0.800\n",
      "Epoch 0, Iteration 895, loss 0.977, batch accuracy 0.700\n",
      "Epoch 0, Iteration 896, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 897, loss 0.069, batch accuracy 1.000\n",
      "Epoch 0, Iteration 898, loss 0.099, batch accuracy 1.000\n",
      "Epoch 0, Iteration 899, loss 0.145, batch accuracy 0.900\n",
      "Epoch 0, Iteration 900, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 901, loss 0.649, batch accuracy 0.800\n",
      "Epoch 0, Iteration 902, loss 0.069, batch accuracy 1.000\n",
      "Epoch 0, Iteration 903, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 904, loss 1.596, batch accuracy 0.600\n",
      "Epoch 0, Iteration 905, loss 0.081, batch accuracy 1.000\n",
      "Epoch 0, Iteration 906, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 907, loss 0.167, batch accuracy 0.900\n",
      "Epoch 0, Iteration 908, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 909, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 910, loss 0.500, batch accuracy 0.900\n",
      "Epoch 0, Iteration 911, loss 0.136, batch accuracy 1.000\n",
      "Epoch 0, Iteration 912, loss 0.117, batch accuracy 1.000\n",
      "Epoch 0, Iteration 913, loss 0.372, batch accuracy 0.900\n",
      "Epoch 0, Iteration 914, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 915, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 916, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 917, loss 0.233, batch accuracy 0.900\n",
      "Epoch 0, Iteration 918, loss 0.131, batch accuracy 0.900\n",
      "Epoch 0, Iteration 919, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 920, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 921, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 922, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 923, loss 0.173, batch accuracy 0.900\n",
      "Epoch 0, Iteration 924, loss 0.101, batch accuracy 1.000\n",
      "Epoch 0, Iteration 925, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 926, loss 0.372, batch accuracy 0.900\n",
      "Epoch 0, Iteration 927, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 928, loss 0.318, batch accuracy 0.900\n",
      "Epoch 0, Iteration 929, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 930, loss 0.143, batch accuracy 0.900\n",
      "Epoch 0, Iteration 931, loss 0.159, batch accuracy 0.900\n",
      "Epoch 0, Iteration 932, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 933, loss 0.276, batch accuracy 0.900\n",
      "Epoch 0, Iteration 934, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 935, loss 0.149, batch accuracy 0.900\n",
      "Epoch 0, Iteration 936, loss 0.226, batch accuracy 1.000\n",
      "Epoch 0, Iteration 937, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 938, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 939, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 940, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 941, loss 0.091, batch accuracy 0.900\n",
      "Epoch 0, Iteration 942, loss 1.376, batch accuracy 0.900\n",
      "Epoch 0, Iteration 943, loss 0.304, batch accuracy 0.900\n",
      "Epoch 0, Iteration 944, loss 0.168, batch accuracy 0.900\n",
      "Epoch 0, Iteration 945, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 946, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 947, loss 0.194, batch accuracy 0.900\n",
      "Epoch 0, Iteration 948, loss 0.333, batch accuracy 0.900\n",
      "Epoch 0, Iteration 949, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 950, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 951, loss 0.575, batch accuracy 0.900\n",
      "Epoch 0, Iteration 952, loss 0.649, batch accuracy 0.800\n",
      "Epoch 0, Iteration 953, loss 0.720, batch accuracy 0.800\n",
      "Epoch 0, Iteration 954, loss 0.104, batch accuracy 1.000\n",
      "Epoch 0, Iteration 955, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 956, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 957, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 958, loss 0.310, batch accuracy 0.800\n",
      "Epoch 0, Iteration 959, loss 0.150, batch accuracy 0.900\n",
      "Epoch 0, Iteration 960, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 961, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 962, loss 0.651, batch accuracy 0.800\n",
      "Epoch 0, Iteration 963, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 964, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 965, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 966, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 967, loss 0.152, batch accuracy 0.900\n",
      "Epoch 0, Iteration 968, loss 0.136, batch accuracy 1.000\n",
      "Epoch 0, Iteration 969, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 970, loss 0.127, batch accuracy 1.000\n",
      "Epoch 0, Iteration 971, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 972, loss 0.230, batch accuracy 0.900\n",
      "Epoch 0, Iteration 973, loss 0.079, batch accuracy 1.000\n",
      "Epoch 0, Iteration 974, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 975, loss 0.279, batch accuracy 0.800\n",
      "Epoch 0, Iteration 976, loss 0.189, batch accuracy 1.000\n",
      "Epoch 0, Iteration 977, loss 0.077, batch accuracy 1.000\n",
      "Epoch 0, Iteration 978, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 979, loss 0.081, batch accuracy 1.000\n",
      "Epoch 0, Iteration 980, loss 0.095, batch accuracy 1.000\n",
      "Epoch 0, Iteration 981, loss 0.077, batch accuracy 1.000\n",
      "Epoch 0, Iteration 982, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 983, loss 0.253, batch accuracy 0.900\n",
      "Epoch 0, Iteration 984, loss 0.217, batch accuracy 0.900\n",
      "Epoch 0, Iteration 985, loss 0.087, batch accuracy 0.900\n",
      "Epoch 0, Iteration 986, loss 0.126, batch accuracy 0.900\n",
      "Epoch 0, Iteration 987, loss 0.162, batch accuracy 0.900\n",
      "Epoch 0, Iteration 988, loss 0.186, batch accuracy 0.900\n",
      "Epoch 0, Iteration 989, loss 0.080, batch accuracy 1.000\n",
      "Epoch 0, Iteration 990, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 991, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 992, loss 0.158, batch accuracy 0.900\n",
      "Epoch 0, Iteration 993, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 994, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 995, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 996, loss 0.265, batch accuracy 0.900\n",
      "Epoch 0, Iteration 997, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 998, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 999, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1000, loss 0.390, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1001, loss 0.190, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1002, loss 0.476, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1003, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1004, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1005, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1006, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1007, loss 0.095, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1008, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1009, loss 0.370, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1010, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1011, loss 0.164, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1012, loss 0.211, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1013, loss 0.112, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1014, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1015, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1016, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1017, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1018, loss 0.099, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1019, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1020, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1021, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1022, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1023, loss 0.328, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1024, loss 0.130, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1025, loss 0.338, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1026, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1027, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1028, loss 0.091, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1029, loss 0.360, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1030, loss 0.095, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1031, loss 0.904, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1032, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1033, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1034, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1035, loss 0.157, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1036, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1037, loss 0.230, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1038, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1039, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1040, loss 0.169, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1041, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1042, loss 0.093, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1043, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1044, loss 0.168, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1045, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1046, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1047, loss 0.129, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1048, loss 0.107, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1049, loss 0.037, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 1050, loss 1.352, batch accuracy 0.700\n",
      "Epoch 0, Iteration 1051, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1052, loss 0.147, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1053, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1054, loss 0.250, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1055, loss 0.171, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1056, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1057, loss 0.360, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1058, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1059, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1060, loss 0.147, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1061, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1062, loss 0.596, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1063, loss 0.072, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1064, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1065, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1066, loss 0.175, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1067, loss 0.274, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1068, loss 0.749, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1069, loss 0.163, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1070, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1071, loss 0.381, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1072, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1073, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1074, loss 0.188, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1075, loss 0.114, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1076, loss 0.355, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1077, loss 0.137, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1078, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1079, loss 0.208, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1080, loss 0.113, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1081, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1082, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1083, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1084, loss 0.061, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1085, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1086, loss 0.409, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1087, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1088, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1089, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1090, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1091, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1092, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1093, loss 0.089, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1094, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1095, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1096, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1097, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1098, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1099, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1100, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1101, loss 0.455, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1102, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1103, loss 0.874, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1104, loss 0.119, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1105, loss 0.212, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1106, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1107, loss 0.086, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1108, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1109, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1110, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1111, loss 0.193, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1112, loss 0.374, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1113, loss 0.144, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1114, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1115, loss 0.714, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1116, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1117, loss 0.118, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1118, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1119, loss 0.629, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1120, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1121, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1122, loss 0.086, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1123, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1124, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1125, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1126, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1127, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1128, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1129, loss 0.228, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1130, loss 0.248, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1131, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1132, loss 0.365, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1133, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1134, loss 0.076, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1135, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1136, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1137, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1138, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1139, loss 0.108, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1140, loss 0.574, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1141, loss 0.310, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1142, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1143, loss 0.061, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1144, loss 0.082, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1145, loss 0.185, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1146, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1147, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1148, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1149, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1150, loss 0.082, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1151, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1152, loss 0.698, batch accuracy 0.700\n",
      "Epoch 0, Iteration 1153, loss 0.106, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1154, loss 0.280, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1155, loss 0.562, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1156, loss 1.099, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1157, loss 0.075, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1158, loss 0.090, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1159, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1160, loss 0.130, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1161, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1162, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1163, loss 0.068, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1164, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1165, loss 0.222, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1166, loss 0.210, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1167, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1168, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1169, loss 0.196, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1170, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1171, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1172, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1173, loss 0.052, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1174, loss 0.225, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1175, loss 1.925, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1176, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1177, loss 0.105, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1178, loss 0.150, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1179, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1180, loss 0.175, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1181, loss 0.119, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1182, loss 0.201, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1183, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1184, loss 0.294, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1185, loss 0.284, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1186, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1187, loss 0.187, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1188, loss 0.070, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1189, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1190, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1191, loss 0.307, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1192, loss 0.350, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1193, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1194, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1195, loss 0.146, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1196, loss 0.311, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1197, loss 0.207, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1198, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1199, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1200, loss 0.145, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1201, loss 0.389, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1202, loss 0.231, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1203, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1204, loss 0.139, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1205, loss 0.109, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1206, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1207, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1208, loss 0.072, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1209, loss 0.190, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1210, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1211, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1212, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1213, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1214, loss 0.259, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1215, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1216, loss 0.096, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1217, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1218, loss 0.081, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1219, loss 0.651, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1220, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1221, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1222, loss 0.095, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1223, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1224, loss 0.195, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1225, loss 0.007, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 1226, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1227, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1228, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1229, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1230, loss 0.491, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1231, loss 0.192, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1232, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1233, loss 0.206, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1234, loss 0.079, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1235, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1236, loss 0.400, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1237, loss 0.415, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1238, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1239, loss 1.181, batch accuracy 0.700\n",
      "Epoch 0, Iteration 1240, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1241, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1242, loss 0.171, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1243, loss 0.122, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1244, loss 0.311, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1245, loss 0.557, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1246, loss 0.321, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1247, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1248, loss 0.341, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1249, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1250, loss 0.472, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1251, loss 0.161, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1252, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1253, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1254, loss 0.161, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1255, loss 0.126, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1256, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1257, loss 0.107, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1258, loss 0.358, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1259, loss 0.136, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1260, loss 0.525, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1261, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1262, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1263, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1264, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1265, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1266, loss 0.703, batch accuracy 0.700\n",
      "Epoch 0, Iteration 1267, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1268, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1269, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1270, loss 0.111, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1271, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1272, loss 0.088, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1273, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1274, loss 0.116, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1275, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1276, loss 0.092, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1277, loss 0.113, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1278, loss 0.126, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1279, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1280, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1281, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1282, loss 0.244, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1283, loss 0.106, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1284, loss 0.088, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1285, loss 0.069, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1286, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1287, loss 0.116, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1288, loss 0.338, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1289, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1290, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1291, loss 0.425, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1292, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1293, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1294, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1295, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1296, loss 0.201, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1297, loss 0.279, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1298, loss 0.164, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1299, loss 0.168, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1300, loss 0.238, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1301, loss 0.117, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1302, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1303, loss 0.284, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1304, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1305, loss 0.088, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1306, loss 0.120, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1307, loss 0.093, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1308, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1309, loss 0.528, batch accuracy 0.700\n",
      "Epoch 0, Iteration 1310, loss 0.313, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1311, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1312, loss 0.110, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1313, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1314, loss 0.101, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1315, loss 0.216, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1316, loss 0.119, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1317, loss 0.070, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1318, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1319, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1320, loss 0.160, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1321, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1322, loss 0.078, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1323, loss 0.061, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1324, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1325, loss 0.342, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1326, loss 0.405, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1327, loss 0.239, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1328, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1329, loss 0.326, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1330, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1331, loss 0.263, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1332, loss 0.116, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1333, loss 0.104, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1334, loss 0.061, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1335, loss 0.078, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1336, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1337, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1338, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1339, loss 0.112, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1340, loss 0.566, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1341, loss 0.450, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1342, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1343, loss 0.100, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1344, loss 0.255, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1345, loss 0.162, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1346, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1347, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1348, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1349, loss 0.069, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1350, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1351, loss 0.095, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1352, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1353, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1354, loss 0.086, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1355, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1356, loss 0.740, batch accuracy 0.700\n",
      "Epoch 0, Iteration 1357, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1358, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1359, loss 0.418, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1360, loss 0.165, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1361, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1362, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1363, loss 0.075, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1364, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1365, loss 1.875, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1366, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1367, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1368, loss 0.170, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1369, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1370, loss 1.319, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1371, loss 0.446, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1372, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1373, loss 0.207, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1374, loss 0.084, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1375, loss 0.121, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1376, loss 0.894, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1377, loss 0.191, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1378, loss 0.369, batch accuracy 0.700\n",
      "Epoch 0, Iteration 1379, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1380, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1381, loss 0.209, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1382, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1383, loss 0.210, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1384, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1385, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1386, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1387, loss 0.742, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1388, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1389, loss 0.095, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1390, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1391, loss 0.575, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1392, loss 0.303, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1393, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1394, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1395, loss 0.052, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1396, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1397, loss 0.630, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1398, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1399, loss 0.248, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1400, loss 0.206, batch accuracy 0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 1401, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1402, loss 0.618, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1403, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1404, loss 0.510, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1405, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1406, loss 0.142, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1407, loss 0.222, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1408, loss 0.233, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1409, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1410, loss 0.375, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1411, loss 0.260, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1412, loss 0.078, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1413, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1414, loss 0.086, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1415, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1416, loss 0.169, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1417, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1418, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1419, loss 0.154, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1420, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1421, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1422, loss 0.116, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1423, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1424, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1425, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1426, loss 0.677, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1427, loss 0.099, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1428, loss 0.148, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1429, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1430, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1431, loss 0.077, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1432, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1433, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1434, loss 0.974, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1435, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1436, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1437, loss 0.728, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1438, loss 0.721, batch accuracy 0.700\n",
      "Epoch 0, Iteration 1439, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1440, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1441, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1442, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1443, loss 0.081, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1444, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1445, loss 0.108, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1446, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1447, loss 0.192, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1448, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1449, loss 0.869, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1450, loss 0.554, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1451, loss 0.239, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1452, loss 0.255, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1453, loss 0.386, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1454, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1455, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1456, loss 0.195, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1457, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1458, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1459, loss 0.162, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1460, loss 0.745, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1461, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1462, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1463, loss 0.133, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1464, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1465, loss 0.095, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1466, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1467, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1468, loss 0.132, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1469, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1470, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1471, loss 0.195, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1472, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1473, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1474, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1475, loss 0.174, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1476, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1477, loss 1.251, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1478, loss 0.061, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1479, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1480, loss 0.498, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1481, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1482, loss 0.256, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1483, loss 0.170, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1484, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1485, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1486, loss 0.072, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1487, loss 0.088, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1488, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1489, loss 0.170, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1490, loss 1.437, batch accuracy 0.700\n",
      "Epoch 0, Iteration 1491, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1492, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1493, loss 0.253, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1494, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1495, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1496, loss 0.129, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1497, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1498, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1499, loss 0.060, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1500, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1501, loss 0.079, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1502, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1503, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1504, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1505, loss 0.623, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1506, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1507, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1508, loss 0.357, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1509, loss 0.077, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1510, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1511, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1512, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1513, loss 0.134, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1514, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1515, loss 0.104, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1516, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1517, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1518, loss 0.129, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1519, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1520, loss 0.212, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1521, loss 0.070, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1522, loss 0.156, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1523, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1524, loss 0.480, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1525, loss 0.895, batch accuracy 0.700\n",
      "Epoch 0, Iteration 1526, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1527, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1528, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1529, loss 0.504, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1530, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1531, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1532, loss 0.291, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1533, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1534, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1535, loss 0.517, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1536, loss 0.089, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1537, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1538, loss 0.192, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1539, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1540, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1541, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1542, loss 0.538, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1543, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1544, loss 0.228, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1545, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1546, loss 0.069, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1547, loss 0.075, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1548, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1549, loss 0.052, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1550, loss 0.074, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1551, loss 0.348, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1552, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1553, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1554, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1555, loss 0.124, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1556, loss 0.197, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1557, loss 0.083, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1558, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1559, loss 0.698, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1560, loss 0.092, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1561, loss 0.483, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1562, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1563, loss 0.293, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1564, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1565, loss 0.323, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1566, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1567, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1568, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1569, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1570, loss 0.106, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1571, loss 0.086, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1572, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1573, loss 0.179, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1574, loss 0.224, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1575, loss 0.149, batch accuracy 0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 1576, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1577, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1578, loss 0.098, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1579, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1580, loss 0.074, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1581, loss 0.103, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1582, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1583, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1584, loss 0.118, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1585, loss 0.269, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1586, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1587, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1588, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1589, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1590, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1591, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1592, loss 0.144, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1593, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1594, loss 0.189, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1595, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1596, loss 0.257, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1597, loss 0.232, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1598, loss 0.365, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1599, loss 0.240, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1600, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1601, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1602, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1603, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1604, loss 0.258, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1605, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1606, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1607, loss 0.388, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1608, loss 0.263, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1609, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1610, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1611, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1612, loss 0.307, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1613, loss 0.873, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1614, loss 0.181, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1615, loss 0.426, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1616, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1617, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1618, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1619, loss 0.327, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1620, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1621, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1622, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1623, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1624, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1625, loss 0.211, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1626, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1627, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1628, loss 0.086, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1629, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1630, loss 0.196, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1631, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1632, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1633, loss 0.723, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1634, loss 0.120, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1635, loss 0.061, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1636, loss 0.268, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1637, loss 0.114, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1638, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1639, loss 0.173, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1640, loss 0.080, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1641, loss 0.096, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1642, loss 0.488, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1643, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1644, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1645, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1646, loss 0.203, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1647, loss 0.353, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1648, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1649, loss 0.227, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1650, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1651, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1652, loss 0.172, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1653, loss 0.185, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1654, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1655, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1656, loss 0.143, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1657, loss 0.306, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1658, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1659, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1660, loss 0.173, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1661, loss 0.151, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1662, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1663, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1664, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1665, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1666, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1667, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1668, loss 0.823, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1669, loss 0.280, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1670, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1671, loss 0.080, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1672, loss 0.422, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1673, loss 0.352, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1674, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1675, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1676, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1677, loss 0.072, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1678, loss 0.084, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1679, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1680, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1681, loss 0.093, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1682, loss 0.575, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1683, loss 0.102, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1684, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1685, loss 0.076, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1686, loss 0.116, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1687, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1688, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1689, loss 0.277, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1690, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1691, loss 0.205, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1692, loss 0.198, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1693, loss 0.379, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1694, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1695, loss 0.176, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1696, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1697, loss 0.109, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1698, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1699, loss 0.388, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1700, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1701, loss 0.097, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1702, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1703, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1704, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1705, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1706, loss 0.854, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1707, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1708, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1709, loss 0.105, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1710, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1711, loss 1.162, batch accuracy 0.600\n",
      "Epoch 0, Iteration 1712, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1713, loss 0.109, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1714, loss 0.240, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1715, loss 0.076, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1716, loss 0.142, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1717, loss 0.305, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1718, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1719, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1720, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1721, loss 0.121, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1722, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1723, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1724, loss 0.215, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1725, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1726, loss 0.582, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1727, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1728, loss 0.291, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1729, loss 0.791, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1730, loss 0.928, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1731, loss 0.290, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1732, loss 0.100, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1733, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1734, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1735, loss 0.240, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1736, loss 0.358, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1737, loss 0.432, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1738, loss 0.118, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1739, loss 0.238, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1740, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1741, loss 0.122, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1742, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1743, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1744, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1745, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1746, loss 0.375, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1747, loss 0.159, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1748, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1749, loss 0.286, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1750, loss 0.120, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1751, loss 0.007, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 1752, loss 0.494, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1753, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1754, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1755, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1756, loss 0.360, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1757, loss 0.146, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1758, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1759, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1760, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1761, loss 0.271, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1762, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1763, loss 0.109, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1764, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1765, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1766, loss 0.312, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1767, loss 0.085, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1768, loss 1.474, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1769, loss 0.149, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1770, loss 0.150, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1771, loss 0.061, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1772, loss 0.287, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1773, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1774, loss 0.252, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1775, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1776, loss 0.061, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1777, loss 0.100, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1778, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1779, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1780, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1781, loss 0.367, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1782, loss 0.176, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1783, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1784, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1785, loss 0.166, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1786, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1787, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1788, loss 0.182, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1789, loss 0.096, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1790, loss 0.379, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1791, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1792, loss 0.106, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1793, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1794, loss 0.336, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1795, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1796, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1797, loss 0.102, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1798, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1799, loss 0.341, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1800, loss 0.119, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1801, loss 0.110, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1802, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1803, loss 0.069, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1804, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1805, loss 0.151, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1806, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1807, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1808, loss 0.072, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1809, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1810, loss 0.061, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1811, loss 0.110, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1812, loss 0.108, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1813, loss 0.237, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1814, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1815, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1816, loss 0.077, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1817, loss 0.181, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1818, loss 0.214, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1819, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1820, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1821, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1822, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1823, loss 0.167, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1824, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1825, loss 0.076, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1826, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1827, loss 0.147, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1828, loss 0.106, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1829, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1830, loss 0.110, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1831, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1832, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1833, loss 0.545, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1834, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1835, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1836, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1837, loss 0.257, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1838, loss 0.201, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1839, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1840, loss 0.285, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1841, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1842, loss 0.468, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1843, loss 0.111, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1844, loss 0.072, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1845, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1846, loss 0.198, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1847, loss 0.162, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1848, loss 0.279, batch accuracy 0.700\n",
      "Epoch 0, Iteration 1849, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1850, loss 0.125, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1851, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1852, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1853, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1854, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1855, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1856, loss 0.210, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1857, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1858, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1859, loss 0.594, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1860, loss 0.201, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1861, loss 0.061, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1862, loss 0.216, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1863, loss 0.596, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1864, loss 0.069, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1865, loss 0.142, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1866, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1867, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1868, loss 0.072, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1869, loss 0.154, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1870, loss 0.182, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1871, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1872, loss 0.472, batch accuracy 0.700\n",
      "Epoch 0, Iteration 1873, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1874, loss 0.211, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1875, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1876, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1877, loss 0.491, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1878, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1879, loss 0.088, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1880, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1881, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1882, loss 0.377, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1883, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1884, loss 0.382, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1885, loss 0.583, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1886, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1887, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1888, loss 1.161, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1889, loss 0.107, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1890, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1891, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1892, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1893, loss 0.221, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1894, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1895, loss 0.103, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1896, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1897, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1898, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1899, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1900, loss 0.494, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1901, loss 0.204, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1902, loss 0.776, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1903, loss 0.172, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1904, loss 0.359, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1905, loss 0.092, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1906, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1907, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1908, loss 0.686, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1909, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1910, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1911, loss 0.240, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1912, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1913, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1914, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1915, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1916, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1917, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1918, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1919, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1920, loss 0.097, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1921, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1922, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1923, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1924, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1925, loss 0.309, batch accuracy 0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 1926, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1927, loss 0.155, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1928, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1929, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1930, loss 0.079, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1931, loss 0.126, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1932, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1933, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1934, loss 0.134, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1935, loss 0.182, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1936, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1937, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1938, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1939, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1940, loss 0.455, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1941, loss 0.187, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1942, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1943, loss 0.647, batch accuracy 0.700\n",
      "Epoch 0, Iteration 1944, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1945, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1946, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1947, loss 0.213, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1948, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1949, loss 0.088, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1950, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1951, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1952, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1953, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1954, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1955, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1956, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1957, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1958, loss 0.398, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1959, loss 0.820, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1960, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1961, loss 0.137, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1962, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1963, loss 0.124, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1964, loss 0.081, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1965, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1966, loss 0.475, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1967, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1968, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1969, loss 0.126, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1970, loss 0.765, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1971, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1972, loss 0.134, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1973, loss 0.060, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1974, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1975, loss 0.236, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1976, loss 0.093, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1977, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1978, loss 0.239, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1979, loss 0.400, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1980, loss 0.130, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1981, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1982, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1983, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1984, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1985, loss 0.124, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1986, loss 0.570, batch accuracy 0.800\n",
      "Epoch 0, Iteration 1987, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1988, loss 0.141, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1989, loss 0.052, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1990, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1991, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1992, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1993, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1994, loss 0.195, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1995, loss 0.121, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1996, loss 0.140, batch accuracy 0.900\n",
      "Epoch 0, Iteration 1997, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1998, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 1999, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2000, loss 0.156, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2001, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2002, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2003, loss 0.100, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2004, loss 0.434, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2005, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2006, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2007, loss 0.395, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2008, loss 0.101, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2009, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2010, loss 0.423, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2011, loss 0.130, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2012, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2013, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2014, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2015, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2016, loss 0.089, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2017, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2018, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2019, loss 0.240, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2020, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2021, loss 0.192, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2022, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2023, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2024, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2025, loss 0.423, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2026, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2027, loss 0.254, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2028, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2029, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2030, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2031, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2032, loss 0.070, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2033, loss 0.245, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2034, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2035, loss 0.330, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2036, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2037, loss 0.082, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2038, loss 0.082, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2039, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2040, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2041, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2042, loss 0.091, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2043, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2044, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2045, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2046, loss 0.117, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2047, loss 0.735, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2048, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2049, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2050, loss 0.060, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2051, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2052, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2053, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2054, loss 0.359, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2055, loss 0.120, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2056, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2057, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2058, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2059, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2060, loss 0.216, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2061, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2062, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2063, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2064, loss 0.411, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2065, loss 0.340, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2066, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2067, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2068, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2069, loss 0.220, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2070, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2071, loss 0.206, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2072, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2073, loss 0.075, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2074, loss 0.624, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2075, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2076, loss 0.246, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2077, loss 0.282, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2078, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2079, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2080, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2081, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2082, loss 0.580, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2083, loss 0.230, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2084, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2085, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2086, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2087, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2088, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2089, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2090, loss 0.211, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2091, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2092, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2093, loss 0.334, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2094, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2095, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2096, loss 0.031, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 2097, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2098, loss 0.576, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2099, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2100, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2101, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2102, loss 0.176, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2103, loss 0.249, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2104, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2105, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2106, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2107, loss 0.199, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2108, loss 0.124, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2109, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2110, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2111, loss 0.302, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2112, loss 0.123, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2113, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2114, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2115, loss 0.122, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2116, loss 0.115, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2117, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2118, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2119, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2120, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2121, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2122, loss 0.134, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2123, loss 0.313, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2124, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2125, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2126, loss 0.610, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2127, loss 0.165, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2128, loss 0.155, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2129, loss 0.136, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2130, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2131, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2132, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2133, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2134, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2135, loss 0.094, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2136, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2137, loss 0.294, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2138, loss 0.126, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2139, loss 0.618, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2140, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2141, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2142, loss 0.289, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2143, loss 0.138, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2144, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2145, loss 0.168, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2146, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2147, loss 0.193, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2148, loss 0.132, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2149, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2150, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2151, loss 0.052, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2152, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2153, loss 0.716, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2154, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2155, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2156, loss 0.101, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2157, loss 0.348, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2158, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2159, loss 0.516, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2160, loss 0.281, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2161, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2162, loss 0.592, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2163, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2164, loss 0.113, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2165, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2166, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2167, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2168, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2169, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2170, loss 0.221, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2171, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2172, loss 0.504, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2173, loss 0.107, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2174, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2175, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2176, loss 0.240, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2177, loss 0.338, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2178, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2179, loss 0.174, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2180, loss 0.378, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2181, loss 0.135, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2182, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2183, loss 0.711, batch accuracy 0.700\n",
      "Epoch 0, Iteration 2184, loss 0.143, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2185, loss 0.088, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2186, loss 0.126, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2187, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2188, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2189, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2190, loss 1.016, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2191, loss 0.104, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2192, loss 0.178, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2193, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2194, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2195, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2196, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2197, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2198, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2199, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2200, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2201, loss 0.555, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2202, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2203, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2204, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2205, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2206, loss 0.372, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2207, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2208, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2209, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2210, loss 0.329, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2211, loss 0.473, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2212, loss 0.785, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2213, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2214, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2215, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2216, loss 0.766, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2217, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2218, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2219, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2220, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2221, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2222, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2223, loss 0.225, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2224, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2225, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2226, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2227, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2228, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2229, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2230, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2231, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2232, loss 0.179, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2233, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2234, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2235, loss 0.136, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2236, loss 0.264, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2237, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2238, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2239, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2240, loss 0.209, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2241, loss 0.272, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2242, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2243, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2244, loss 0.068, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2245, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2246, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2247, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2248, loss 0.112, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2249, loss 0.087, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2250, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2251, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2252, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2253, loss 0.272, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2254, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2255, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2256, loss 0.586, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2257, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2258, loss 0.089, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2259, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2260, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2261, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2262, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2263, loss 1.058, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2264, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2265, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2266, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2267, loss 0.637, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2268, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2269, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2270, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2271, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2272, loss 0.005, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 2273, loss 0.343, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2274, loss 0.141, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2275, loss 0.849, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2276, loss 0.194, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2277, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2278, loss 0.121, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2279, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2280, loss 0.426, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2281, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2282, loss 0.078, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2283, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2284, loss 0.357, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2285, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2286, loss 0.084, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2287, loss 0.194, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2288, loss 0.476, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2289, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2290, loss 0.316, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2291, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2292, loss 0.174, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2293, loss 0.318, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2294, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2295, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2296, loss 0.082, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2297, loss 0.357, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2298, loss 0.244, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2299, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2300, loss 0.239, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2301, loss 0.143, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2302, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2303, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2304, loss 0.119, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2305, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2306, loss 0.118, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2307, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2308, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2309, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2310, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2311, loss 0.182, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2312, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2313, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2314, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2315, loss 0.106, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2316, loss 0.112, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2317, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2318, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2319, loss 0.562, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2320, loss 0.141, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2321, loss 0.185, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2322, loss 0.317, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2323, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2324, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2325, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2326, loss 0.110, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2327, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2328, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2329, loss 0.174, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2330, loss 0.127, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2331, loss 0.193, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2332, loss 0.084, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2333, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2334, loss 0.331, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2335, loss 0.169, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2336, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2337, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2338, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2339, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2340, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2341, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2342, loss 0.194, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2343, loss 0.081, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2344, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2345, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2346, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2347, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2348, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2349, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2350, loss 0.113, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2351, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2352, loss 0.174, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2353, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2354, loss 0.238, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2355, loss 0.343, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2356, loss 0.074, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2357, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2358, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2359, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2360, loss 0.085, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2361, loss 0.439, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2362, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2363, loss 0.313, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2364, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2365, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2366, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2367, loss 0.122, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2368, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2369, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2370, loss 0.335, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2371, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2372, loss 0.101, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2373, loss 0.082, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2374, loss 0.131, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2375, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2376, loss 0.132, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2377, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2378, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2379, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2380, loss 0.211, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2381, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2382, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2383, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2384, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2385, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2386, loss 0.394, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2387, loss 0.212, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2388, loss 0.101, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2389, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2390, loss 0.086, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2391, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2392, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2393, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2394, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2395, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2396, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2397, loss 0.098, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2398, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2399, loss 0.184, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2400, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2401, loss 0.517, batch accuracy 0.700\n",
      "Epoch 0, Iteration 2402, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2403, loss 0.093, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2404, loss 0.138, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2405, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2406, loss 0.615, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2407, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2408, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2409, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2410, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2411, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2412, loss 0.535, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2413, loss 0.161, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2414, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2415, loss 0.171, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2416, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2417, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2418, loss 0.093, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2419, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2420, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2421, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2422, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2423, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2424, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2425, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2426, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2427, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2428, loss 0.317, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2429, loss 0.093, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2430, loss 0.083, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2431, loss 0.061, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2432, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2433, loss 0.194, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2434, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2435, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2436, loss 0.221, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2437, loss 0.204, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2438, loss 0.212, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2439, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2440, loss 0.646, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2441, loss 0.133, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2442, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2443, loss 0.140, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2444, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2445, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2446, loss 0.022, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 2447, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2448, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2449, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2450, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2451, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2452, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2453, loss 0.383, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2454, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2455, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2456, loss 0.084, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2457, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2458, loss 0.212, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2459, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2460, loss 0.162, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2461, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2462, loss 0.075, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2463, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2464, loss 0.296, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2465, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2466, loss 0.124, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2467, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2468, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2469, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2470, loss 0.184, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2471, loss 0.092, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2472, loss 0.109, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2473, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2474, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2475, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2476, loss 0.141, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2477, loss 0.686, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2478, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2479, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2480, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2481, loss 0.420, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2482, loss 1.030, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2483, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2484, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2485, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2486, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2487, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2488, loss 0.122, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2489, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2490, loss 1.304, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2491, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2492, loss 0.081, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2493, loss 0.648, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2494, loss 0.087, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2495, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2496, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2497, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2498, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2499, loss 0.320, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2500, loss 0.166, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2501, loss 0.142, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2502, loss 0.330, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2503, loss 0.123, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2504, loss 0.125, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2505, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2506, loss 0.424, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2507, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2508, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2509, loss 0.122, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2510, loss 0.087, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2511, loss 0.087, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2512, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2513, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2514, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2515, loss 0.208, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2516, loss 0.216, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2517, loss 0.264, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2518, loss 0.092, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2519, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2520, loss 0.151, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2521, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2522, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2523, loss 0.077, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2524, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2525, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2526, loss 0.475, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2527, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2528, loss 0.414, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2529, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2530, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2531, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2532, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2533, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2534, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2535, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2536, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2537, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2538, loss 0.114, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2539, loss 0.232, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2540, loss 0.090, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2541, loss 0.178, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2542, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2543, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2544, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2545, loss 0.131, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2546, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2547, loss 0.105, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2548, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2549, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2550, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2551, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2552, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2553, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2554, loss 0.423, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2555, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2556, loss 0.634, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2557, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2558, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2559, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2560, loss 0.164, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2561, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2562, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2563, loss 0.148, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2564, loss 0.469, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2565, loss 0.119, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2566, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2567, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2568, loss 0.093, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2569, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2570, loss 0.068, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2571, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2572, loss 0.132, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2573, loss 0.069, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2574, loss 0.697, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2575, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2576, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2577, loss 0.281, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2578, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2579, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2580, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2581, loss 0.149, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2582, loss 0.150, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2583, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2584, loss 0.081, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2585, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2586, loss 0.164, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2587, loss 0.080, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2588, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2589, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2590, loss 0.292, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2591, loss 0.202, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2592, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2593, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2594, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2595, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2596, loss 0.698, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2597, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2598, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2599, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2600, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2601, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2602, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2603, loss 0.504, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2604, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2605, loss 0.204, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2606, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2607, loss 0.324, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2608, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2609, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2610, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2611, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2612, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2613, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2614, loss 0.325, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2615, loss 0.518, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2616, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2617, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2618, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2619, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2620, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2621, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2622, loss 0.068, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2623, loss 0.052, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2624, loss 0.001, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 2625, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2626, loss 0.166, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2627, loss 0.083, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2628, loss 0.604, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2629, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2630, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2631, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2632, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2633, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2634, loss 0.119, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2635, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2636, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2637, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2638, loss 0.476, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2639, loss 0.080, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2640, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2641, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2642, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2643, loss 0.158, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2644, loss 0.151, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2645, loss 0.587, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2646, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2647, loss 0.095, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2648, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2649, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2650, loss 0.244, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2651, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2652, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2653, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2654, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2655, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2656, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2657, loss 0.097, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2658, loss 0.121, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2659, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2660, loss 0.282, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2661, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2662, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2663, loss 0.088, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2664, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2665, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2666, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2667, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2668, loss 0.269, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2669, loss 0.106, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2670, loss 0.076, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2671, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2672, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2673, loss 0.261, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2674, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2675, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2676, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2677, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2678, loss 1.012, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2679, loss 0.214, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2680, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2681, loss 0.583, batch accuracy 0.700\n",
      "Epoch 0, Iteration 2682, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2683, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2684, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2685, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2686, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2687, loss 0.091, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2688, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2689, loss 0.081, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2690, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2691, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2692, loss 0.136, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2693, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2694, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2695, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2696, loss 0.511, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2697, loss 0.129, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2698, loss 0.110, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2699, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2700, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2701, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2702, loss 0.448, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2703, loss 0.378, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2704, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2705, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2706, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2707, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2708, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2709, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2710, loss 0.246, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2711, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2712, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2713, loss 0.235, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2714, loss 0.075, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2715, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2716, loss 0.193, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2717, loss 0.060, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2718, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2719, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2720, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2721, loss 0.196, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2722, loss 0.291, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2723, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2724, loss 0.364, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2725, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2726, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2727, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2728, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2729, loss 0.457, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2730, loss 0.167, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2731, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2732, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2733, loss 0.154, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2734, loss 0.304, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2735, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2736, loss 0.189, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2737, loss 0.126, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2738, loss 0.193, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2739, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2740, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2741, loss 0.165, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2742, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2743, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2744, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2745, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2746, loss 0.108, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2747, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2748, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2749, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2750, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2751, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2752, loss 0.242, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2753, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2754, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2755, loss 0.068, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2756, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2757, loss 0.087, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2758, loss 0.810, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2759, loss 0.181, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2760, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2761, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2762, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2763, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2764, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2765, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2766, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2767, loss 0.000, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2768, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2769, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2770, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2771, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2772, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2773, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2774, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2775, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2776, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2777, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2778, loss 0.478, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2779, loss 0.495, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2780, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2781, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2782, loss 0.310, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2783, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2784, loss 0.185, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2785, loss 0.228, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2786, loss 0.243, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2787, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2788, loss 0.092, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2789, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2790, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2791, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2792, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2793, loss 0.083, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2794, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2795, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2796, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2797, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2798, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2799, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2800, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2801, loss 0.077, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2802, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2803, loss 0.015, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 2804, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2805, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2806, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2807, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2808, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2809, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2810, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2811, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2812, loss 0.358, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2813, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2814, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2815, loss 0.083, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2816, loss 0.184, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2817, loss 0.120, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2818, loss 0.393, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2819, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2820, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2821, loss 0.167, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2822, loss 0.114, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2823, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2824, loss 0.081, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2825, loss 0.435, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2826, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2827, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2828, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2829, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2830, loss 0.127, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2831, loss 0.232, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2832, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2833, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2834, loss 0.096, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2835, loss 1.292, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2836, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2837, loss 0.617, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2838, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2839, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2840, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2841, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2842, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2843, loss 0.139, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2844, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2845, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2846, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2847, loss 0.261, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2848, loss 0.172, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2849, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2850, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2851, loss 0.117, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2852, loss 0.132, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2853, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2854, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2855, loss 0.180, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2856, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2857, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2858, loss 0.324, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2859, loss 0.199, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2860, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2861, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2862, loss 0.124, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2863, loss 1.443, batch accuracy 0.700\n",
      "Epoch 0, Iteration 2864, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2865, loss 0.814, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2866, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2867, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2868, loss 0.132, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2869, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2870, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2871, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2872, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2873, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2874, loss 0.082, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2875, loss 0.076, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2876, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2877, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2878, loss 0.199, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2879, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2880, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2881, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2882, loss 0.317, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2883, loss 0.596, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2884, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2885, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2886, loss 0.229, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2887, loss 0.124, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2888, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2889, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2890, loss 0.594, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2891, loss 0.210, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2892, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2893, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2894, loss 0.335, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2895, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2896, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2897, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2898, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2899, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2900, loss 1.000, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2901, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2902, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2903, loss 0.091, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2904, loss 0.109, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2905, loss 0.097, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2906, loss 0.501, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2907, loss 0.146, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2908, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2909, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2910, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2911, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2912, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2913, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2914, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2915, loss 0.370, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2916, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2917, loss 0.387, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2918, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2919, loss 0.128, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2920, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2921, loss 0.171, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2922, loss 0.577, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2923, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2924, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2925, loss 0.391, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2926, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2927, loss 0.345, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2928, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2929, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2930, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2931, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2932, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2933, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2934, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2935, loss 0.280, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2936, loss 0.101, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2937, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2938, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2939, loss 0.237, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2940, loss 0.293, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2941, loss 0.552, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2942, loss 0.315, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2943, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2944, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2945, loss 0.625, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2946, loss 0.313, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2947, loss 0.091, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2948, loss 0.095, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2949, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2950, loss 0.329, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2951, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2952, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2953, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2954, loss 0.157, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2955, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2956, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2957, loss 0.114, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2958, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2959, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2960, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2961, loss 0.159, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2962, loss 0.060, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2963, loss 0.142, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2964, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2965, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2966, loss 0.060, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2967, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2968, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2969, loss 0.135, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2970, loss 0.000, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2971, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2972, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2973, loss 0.175, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2974, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2975, loss 0.313, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2976, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2977, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2978, loss 0.120, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2979, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2980, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2981, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2982, loss 0.041, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 2983, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2984, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2985, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2986, loss 0.106, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2987, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2988, loss 0.594, batch accuracy 0.800\n",
      "Epoch 0, Iteration 2989, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2990, loss 0.147, batch accuracy 0.900\n",
      "Epoch 0, Iteration 2991, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2992, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2993, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2994, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2995, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2996, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2997, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2998, loss 0.140, batch accuracy 1.000\n",
      "Epoch 0, Iteration 2999, loss 0.214, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3000, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3001, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3002, loss 1.007, batch accuracy 0.700\n",
      "Epoch 0, Iteration 3003, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3004, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3005, loss 0.446, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3006, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3007, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3008, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3009, loss 0.520, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3010, loss 0.083, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3011, loss 0.288, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3012, loss 0.132, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3013, loss 0.129, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3014, loss 0.286, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3015, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3016, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3017, loss 0.345, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3018, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3019, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3020, loss 0.729, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3021, loss 0.359, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3022, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3023, loss 0.375, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3024, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3025, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3026, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3027, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3028, loss 0.342, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3029, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3030, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3031, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3032, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3033, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3034, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3035, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3036, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3037, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3038, loss 0.171, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3039, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3040, loss 0.089, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3041, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3042, loss 0.104, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3043, loss 0.086, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3044, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3045, loss 0.087, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3046, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3047, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3048, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3049, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3050, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3051, loss 0.347, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3052, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3053, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3054, loss 0.181, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3055, loss 0.887, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3056, loss 0.188, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3057, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3058, loss 0.086, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3059, loss 0.094, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3060, loss 0.097, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3061, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3062, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3063, loss 0.175, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3064, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3065, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3066, loss 0.318, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3067, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3068, loss 0.107, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3069, loss 0.133, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3070, loss 0.250, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3071, loss 0.389, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3072, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3073, loss 0.088, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3074, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3075, loss 0.317, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3076, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3077, loss 0.230, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3078, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3079, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3080, loss 0.416, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3081, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3082, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3083, loss 0.660, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3084, loss 0.101, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3085, loss 0.452, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3086, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3087, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3088, loss 0.076, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3089, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3090, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3091, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3092, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3093, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3094, loss 0.628, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3095, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3096, loss 0.092, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3097, loss 0.409, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3098, loss 0.287, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3099, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3100, loss 0.167, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3101, loss 0.107, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3102, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3103, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3104, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3105, loss 0.321, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3106, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3107, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3108, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3109, loss 0.171, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3110, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3111, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3112, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3113, loss 0.179, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3114, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3115, loss 0.628, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3116, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3117, loss 0.093, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3118, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3119, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3120, loss 0.120, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3121, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3122, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3123, loss 0.086, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3124, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3125, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3126, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3127, loss 0.162, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3128, loss 0.141, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3129, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3130, loss 0.107, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3131, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3132, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3133, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3134, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3135, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3136, loss 0.109, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3137, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3138, loss 0.304, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3139, loss 0.094, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3140, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3141, loss 0.137, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3142, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3143, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3144, loss 0.079, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3145, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3146, loss 0.215, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3147, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3148, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3149, loss 0.240, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3150, loss 0.169, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3151, loss 0.107, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3152, loss 0.095, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3153, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3154, loss 1.279, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3155, loss 0.420, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3156, loss 0.172, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3157, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3158, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3159, loss 0.077, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3160, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3161, loss 0.006, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 3162, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3163, loss 0.282, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3164, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3165, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3166, loss 0.284, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3167, loss 0.146, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3168, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3169, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3170, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3171, loss 0.092, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3172, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3173, loss 0.214, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3174, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3175, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3176, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3177, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3178, loss 0.123, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3179, loss 0.283, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3180, loss 0.169, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3181, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3182, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3183, loss 0.239, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3184, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3185, loss 0.599, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3186, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3187, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3188, loss 0.477, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3189, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3190, loss 0.108, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3191, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3192, loss 0.216, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3193, loss 0.125, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3194, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3195, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3196, loss 0.148, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3197, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3198, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3199, loss 0.189, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3200, loss 0.458, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3201, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3202, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3203, loss 0.381, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3204, loss 0.425, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3205, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3206, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3207, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3208, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3209, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3210, loss 0.173, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3211, loss 0.398, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3212, loss 0.082, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3213, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3214, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3215, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3216, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3217, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3218, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3219, loss 0.218, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3220, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3221, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3222, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3223, loss 0.152, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3224, loss 0.276, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3225, loss 0.220, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3226, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3227, loss 0.435, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3228, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3229, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3230, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3231, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3232, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3233, loss 0.162, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3234, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3235, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3236, loss 0.812, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3237, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3238, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3239, loss 0.300, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3240, loss 0.825, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3241, loss 0.210, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3242, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3243, loss 0.561, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3244, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3245, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3246, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3247, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3248, loss 0.316, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3249, loss 0.207, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3250, loss 0.263, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3251, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3252, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3253, loss 0.076, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3254, loss 0.117, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3255, loss 0.102, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3256, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3257, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3258, loss 0.154, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3259, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3260, loss 0.087, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3261, loss 0.098, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3262, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3263, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3264, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3265, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3266, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3267, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3268, loss 0.075, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3269, loss 0.099, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3270, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3271, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3272, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3273, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3274, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3275, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3276, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3277, loss 0.090, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3278, loss 0.107, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3279, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3280, loss 0.328, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3281, loss 0.110, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3282, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3283, loss 0.079, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3284, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3285, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3286, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3287, loss 0.136, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3288, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3289, loss 0.083, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3290, loss 0.070, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3291, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3292, loss 0.294, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3293, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3294, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3295, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3296, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3297, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3298, loss 1.015, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3299, loss 0.173, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3300, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3301, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3302, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3303, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3304, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3305, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3306, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3307, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3308, loss 0.108, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3309, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3310, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3311, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3312, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3313, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3314, loss 0.283, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3315, loss 0.126, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3316, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3317, loss 0.108, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3318, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3319, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3320, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3321, loss 0.052, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3322, loss 0.091, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3323, loss 0.108, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3324, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3325, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3326, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3327, loss 0.075, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3328, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3329, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3330, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3331, loss 0.442, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3332, loss 0.681, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3333, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3334, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3335, loss 0.111, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3336, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3337, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3338, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3339, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3340, loss 0.397, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3341, loss 0.048, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 3342, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3343, loss 0.580, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3344, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3345, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3346, loss 0.060, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3347, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3348, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3349, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3350, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3351, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3352, loss 0.113, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3353, loss 0.102, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3354, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3355, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3356, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3357, loss 0.083, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3358, loss 0.577, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3359, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3360, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3361, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3362, loss 0.297, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3363, loss 0.110, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3364, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3365, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3366, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3367, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3368, loss 0.146, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3369, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3370, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3371, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3372, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3373, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3374, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3375, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3376, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3377, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3378, loss 0.851, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3379, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3380, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3381, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3382, loss 0.068, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3383, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3384, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3385, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3386, loss 0.194, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3387, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3388, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3389, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3390, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3391, loss 0.237, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3392, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3393, loss 0.076, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3394, loss 0.110, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3395, loss 0.108, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3396, loss 0.249, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3397, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3398, loss 0.656, batch accuracy 0.700\n",
      "Epoch 0, Iteration 3399, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3400, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3401, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3402, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3403, loss 0.080, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3404, loss 0.307, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3405, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3406, loss 0.188, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3407, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3408, loss 0.107, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3409, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3410, loss 0.189, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3411, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3412, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3413, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3414, loss 0.145, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3415, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3416, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3417, loss 0.465, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3418, loss 0.099, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3419, loss 0.913, batch accuracy 0.700\n",
      "Epoch 0, Iteration 3420, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3421, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3422, loss 0.083, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3423, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3424, loss 0.163, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3425, loss 0.121, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3426, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3427, loss 0.202, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3428, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3429, loss 0.273, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3430, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3431, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3432, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3433, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3434, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3435, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3436, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3437, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3438, loss 0.266, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3439, loss 0.145, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3440, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3441, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3442, loss 0.772, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3443, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3444, loss 0.108, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3445, loss 0.075, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3446, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3447, loss 0.108, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3448, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3449, loss 0.831, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3450, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3451, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3452, loss 0.108, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3453, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3454, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3455, loss 0.512, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3456, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3457, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3458, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3459, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3460, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3461, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3462, loss 0.193, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3463, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3464, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3465, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3466, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3467, loss 0.546, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3468, loss 0.081, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3469, loss 0.393, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3470, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3471, loss 0.184, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3472, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3473, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3474, loss 0.228, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3475, loss 0.069, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3476, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3477, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3478, loss 0.348, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3479, loss 0.190, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3480, loss 0.173, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3481, loss 0.197, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3482, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3483, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3484, loss 0.328, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3485, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3486, loss 0.120, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3487, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3488, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3489, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3490, loss 0.370, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3491, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3492, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3493, loss 0.134, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3494, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3495, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3496, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3497, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3498, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3499, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3500, loss 0.515, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3501, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3502, loss 0.287, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3503, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3504, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3505, loss 0.123, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3506, loss 0.104, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3507, loss 0.191, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3508, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3509, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3510, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3511, loss 0.139, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3512, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3513, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3514, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3515, loss 0.257, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3516, loss 0.015, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 3517, loss 0.099, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3518, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3519, loss 1.751, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3520, loss 0.303, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3521, loss 0.092, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3522, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3523, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3524, loss 0.241, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3525, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3526, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3527, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3528, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3529, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3530, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3531, loss 0.092, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3532, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3533, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3534, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3535, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3536, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3537, loss 0.171, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3538, loss 0.801, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3539, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3540, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3541, loss 0.231, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3542, loss 0.098, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3543, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3544, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3545, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3546, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3547, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3548, loss 0.232, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3549, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3550, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3551, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3552, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3553, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3554, loss 0.343, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3555, loss 0.088, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3556, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3557, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3558, loss 0.131, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3559, loss 0.210, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3560, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3561, loss 0.219, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3562, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3563, loss 0.137, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3564, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3565, loss 0.867, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3566, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3567, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3568, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3569, loss 0.197, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3570, loss 0.196, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3571, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3572, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3573, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3574, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3575, loss 0.900, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3576, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3577, loss 0.108, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3578, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3579, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3580, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3581, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3582, loss 0.371, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3583, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3584, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3585, loss 0.630, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3586, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3587, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3588, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3589, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3590, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3591, loss 0.167, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3592, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3593, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3594, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3595, loss 0.199, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3596, loss 0.647, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3597, loss 0.244, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3598, loss 0.207, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3599, loss 0.077, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3600, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3601, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3602, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3603, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3604, loss 0.192, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3605, loss 0.318, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3606, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3607, loss 0.161, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3608, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3609, loss 0.442, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3610, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3611, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3612, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3613, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3614, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3615, loss 0.170, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3616, loss 0.095, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3617, loss 0.273, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3618, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3619, loss 0.072, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3620, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3621, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3622, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3623, loss 0.118, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3624, loss 0.110, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3625, loss 0.094, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3626, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3627, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3628, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3629, loss 0.127, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3630, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3631, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3632, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3633, loss 0.248, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3634, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3635, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3636, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3637, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3638, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3639, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3640, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3641, loss 0.076, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3642, loss 0.175, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3643, loss 1.313, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3644, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3645, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3646, loss 0.332, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3647, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3648, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3649, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3650, loss 0.377, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3651, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3652, loss 0.069, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3653, loss 0.291, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3654, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3655, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3656, loss 0.069, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3657, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3658, loss 0.146, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3659, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3660, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3661, loss 0.085, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3662, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3663, loss 0.366, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3664, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3665, loss 0.087, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3666, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3667, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3668, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3669, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3670, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3671, loss 0.507, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3672, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3673, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3674, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3675, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3676, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3677, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3678, loss 0.864, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3679, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3680, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3681, loss 0.112, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3682, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3683, loss 0.344, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3684, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3685, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3686, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3687, loss 0.230, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3688, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3689, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3690, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3691, loss 0.224, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3692, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3693, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3694, loss 0.236, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3695, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3696, loss 0.042, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 3697, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3698, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3699, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3700, loss 0.286, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3701, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3702, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3703, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3704, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3705, loss 0.517, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3706, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3707, loss 0.214, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3708, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3709, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3710, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3711, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3712, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3713, loss 0.226, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3714, loss 0.650, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3715, loss 0.161, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3716, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3717, loss 0.187, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3718, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3719, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3720, loss 0.158, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3721, loss 0.196, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3722, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3723, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3724, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3725, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3726, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3727, loss 0.060, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3728, loss 0.079, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3729, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3730, loss 0.206, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3731, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3732, loss 0.083, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3733, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3734, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3735, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3736, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3737, loss 0.128, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3738, loss 0.180, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3739, loss 0.080, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3740, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3741, loss 0.078, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3742, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3743, loss 0.221, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3744, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3745, loss 0.106, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3746, loss 0.052, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3747, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3748, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3749, loss 0.083, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3750, loss 0.152, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3751, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3752, loss 0.259, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3753, loss 0.250, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3754, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3755, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3756, loss 0.069, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3757, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3758, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3759, loss 0.264, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3760, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3761, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3762, loss 0.233, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3763, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3764, loss 0.135, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3765, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3766, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3767, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3768, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3769, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3770, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3771, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3772, loss 0.274, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3773, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3774, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3775, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3776, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3777, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3778, loss 0.356, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3779, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3780, loss 0.799, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3781, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3782, loss 0.344, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3783, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3784, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3785, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3786, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3787, loss 0.496, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3788, loss 0.348, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3789, loss 0.229, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3790, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3791, loss 0.637, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3792, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3793, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3794, loss 0.351, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3795, loss 0.174, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3796, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3797, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3798, loss 0.185, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3799, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3800, loss 0.113, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3801, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3802, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3803, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3804, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3805, loss 0.134, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3806, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3807, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3808, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3809, loss 0.061, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3810, loss 0.437, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3811, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3812, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3813, loss 0.265, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3814, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3815, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3816, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3817, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3818, loss 0.100, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3819, loss 0.486, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3820, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3821, loss 0.123, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3822, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3823, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3824, loss 0.233, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3825, loss 0.407, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3826, loss 0.153, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3827, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3828, loss 0.466, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3829, loss 0.098, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3830, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3831, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3832, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3833, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3834, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3835, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3836, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3837, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3838, loss 0.113, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3839, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3840, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3841, loss 0.174, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3842, loss 0.102, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3843, loss 0.264, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3844, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3845, loss 0.239, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3846, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3847, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3848, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3849, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3850, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3851, loss 0.271, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3852, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3853, loss 0.084, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3854, loss 0.335, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3855, loss 0.605, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3856, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3857, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3858, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3859, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3860, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3861, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3862, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3863, loss 0.251, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3864, loss 0.080, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3865, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3866, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3867, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3868, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3869, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3870, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3871, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3872, loss 0.246, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3873, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3874, loss 0.446, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3875, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3876, loss 0.352, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3877, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3878, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3879, loss 0.348, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3880, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3881, loss 0.115, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3882, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3883, loss 0.002, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 3884, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3885, loss 0.175, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3886, loss 0.121, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3887, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3888, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3889, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3890, loss 0.111, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3891, loss 0.179, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3892, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3893, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3894, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3895, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3896, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3897, loss 1.075, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3898, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3899, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3900, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3901, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3902, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3903, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3904, loss 0.216, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3905, loss 0.060, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3906, loss 0.123, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3907, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3908, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3909, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3910, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3911, loss 0.971, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3912, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3913, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3914, loss 0.076, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3915, loss 0.163, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3916, loss 0.192, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3917, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3918, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3919, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3920, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3921, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3922, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3923, loss 0.196, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3924, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3925, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3926, loss 0.104, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3927, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3928, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3929, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3930, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3931, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3932, loss 0.272, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3933, loss 0.152, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3934, loss 1.084, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3935, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3936, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3937, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3938, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3939, loss 0.208, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3940, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3941, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3942, loss 0.560, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3943, loss 0.145, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3944, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3945, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3946, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3947, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3948, loss 0.085, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3949, loss 0.068, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3950, loss 0.134, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3951, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3952, loss 0.417, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3953, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3954, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3955, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3956, loss 0.201, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3957, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3958, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3959, loss 0.144, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3960, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3961, loss 0.289, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3962, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3963, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3964, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3965, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3966, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3967, loss 0.167, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3968, loss 0.089, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3969, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3970, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3971, loss 0.188, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3972, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3973, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3974, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3975, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3976, loss 0.409, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3977, loss 0.121, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3978, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3979, loss 0.083, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3980, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3981, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3982, loss 0.609, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3983, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3984, loss 0.258, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3985, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3986, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3987, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3988, loss 0.086, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3989, loss 0.180, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3990, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3991, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3992, loss 0.082, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3993, loss 0.348, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3994, loss 0.098, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3995, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3996, loss 0.233, batch accuracy 0.900\n",
      "Epoch 0, Iteration 3997, loss 0.414, batch accuracy 0.800\n",
      "Epoch 0, Iteration 3998, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 3999, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4000, loss 0.284, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4001, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4002, loss 0.851, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4003, loss 0.167, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4004, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4005, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4006, loss 0.161, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4007, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4008, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4009, loss 0.083, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4010, loss 0.070, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4011, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4012, loss 0.099, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4013, loss 0.215, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4014, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4015, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4016, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4017, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4018, loss 1.009, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4019, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4020, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4021, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4022, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4023, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4024, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4025, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4026, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4027, loss 0.083, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4028, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4029, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4030, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4031, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4032, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4033, loss 0.060, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4034, loss 0.559, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4035, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4036, loss 0.095, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4037, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4038, loss 0.074, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4039, loss 0.142, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4040, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4041, loss 0.113, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4042, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4043, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4044, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4045, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4046, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4047, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4048, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4049, loss 0.535, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4050, loss 0.251, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4051, loss 0.091, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4052, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4053, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4054, loss 0.116, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4055, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4056, loss 0.206, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4057, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4058, loss 0.118, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4059, loss 0.139, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4060, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4061, loss 0.013, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 4062, loss 0.113, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4063, loss 0.126, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4064, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4065, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4066, loss 0.295, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4067, loss 0.165, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4068, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4069, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4070, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4071, loss 0.104, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4072, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4073, loss 0.092, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4074, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4075, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4076, loss 0.266, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4077, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4078, loss 0.508, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4079, loss 0.241, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4080, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4081, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4082, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4083, loss 0.564, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4084, loss 0.559, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4085, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4086, loss 0.109, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4087, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4088, loss 1.152, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4089, loss 0.090, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4090, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4091, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4092, loss 0.117, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4093, loss 0.147, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4094, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4095, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4096, loss 0.072, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4097, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4098, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4099, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4100, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4101, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4102, loss 0.184, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4103, loss 0.429, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4104, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4105, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4106, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4107, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4108, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4109, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4110, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4111, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4112, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4113, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4114, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4115, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4116, loss 0.082, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4117, loss 0.219, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4118, loss 0.093, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4119, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4120, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4121, loss 0.260, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4122, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4123, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4124, loss 0.283, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4125, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4126, loss 0.411, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4127, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4128, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4129, loss 0.387, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4130, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4131, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4132, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4133, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4134, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4135, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4136, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4137, loss 0.365, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4138, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4139, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4140, loss 0.078, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4141, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4142, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4143, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4144, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4145, loss 0.168, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4146, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4147, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4148, loss 0.651, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4149, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4150, loss 0.188, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4151, loss 0.163, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4152, loss 0.266, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4153, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4154, loss 0.206, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4155, loss 0.321, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4156, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4157, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4158, loss 0.251, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4159, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4160, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4161, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4162, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4163, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4164, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4165, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4166, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4167, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4168, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4169, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4170, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4171, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4172, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4173, loss 0.523, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4174, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4175, loss 0.068, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4176, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4177, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4178, loss 0.092, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4179, loss 0.298, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4180, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4181, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4182, loss 0.185, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4183, loss 0.126, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4184, loss 0.072, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4185, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4186, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4187, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4188, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4189, loss 0.101, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4190, loss 0.088, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4191, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4192, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4193, loss 0.572, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4194, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4195, loss 0.172, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4196, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4197, loss 0.216, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4198, loss 0.400, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4199, loss 0.366, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4200, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4201, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4202, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4203, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4204, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4205, loss 0.282, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4206, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4207, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4208, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4209, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4210, loss 0.070, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4211, loss 0.315, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4212, loss 0.088, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4213, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4214, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4215, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4216, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4217, loss 0.155, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4218, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4219, loss 0.164, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4220, loss 0.103, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4221, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4222, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4223, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4224, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4225, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4226, loss 0.284, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4227, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4228, loss 0.118, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4229, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4230, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4231, loss 0.161, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4232, loss 0.201, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4233, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4234, loss 0.057, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4235, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4236, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4237, loss 0.085, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4238, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4239, loss 0.015, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 4240, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4241, loss 0.098, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4242, loss 0.091, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4243, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4244, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4245, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4246, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4247, loss 0.077, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4248, loss 0.138, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4249, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4250, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4251, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4252, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4253, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4254, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4255, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4256, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4257, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4258, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4259, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4260, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4261, loss 0.115, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4262, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4263, loss 0.468, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4264, loss 0.276, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4265, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4266, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4267, loss 0.182, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4268, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4269, loss 0.353, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4270, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4271, loss 0.359, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4272, loss 0.095, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4273, loss 0.077, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4274, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4275, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4276, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4277, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4278, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4279, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4280, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4281, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4282, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4283, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4284, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4285, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4286, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4287, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4288, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4289, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4290, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4291, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4292, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4293, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4294, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4295, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4296, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4297, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4298, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4299, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4300, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4301, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4302, loss 0.180, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4303, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4304, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4305, loss 0.338, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4306, loss 0.169, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4307, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4308, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4309, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4310, loss 0.661, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4311, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4312, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4313, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4314, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4315, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4316, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4317, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4318, loss 0.462, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4319, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4320, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4321, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4322, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4323, loss 0.127, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4324, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4325, loss 0.310, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4326, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4327, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4328, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4329, loss 0.082, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4330, loss 0.081, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4331, loss 0.567, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4332, loss 0.060, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4333, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4334, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4335, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4336, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4337, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4338, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4339, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4340, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4341, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4342, loss 0.154, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4343, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4344, loss 0.473, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4345, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4346, loss 0.000, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4347, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4348, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4349, loss 0.198, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4350, loss 0.200, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4351, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4352, loss 0.224, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4353, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4354, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4355, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4356, loss 0.331, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4357, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4358, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4359, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4360, loss 0.137, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4361, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4362, loss 0.281, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4363, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4364, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4365, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4366, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4367, loss 0.270, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4368, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4369, loss 0.211, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4370, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4371, loss 0.092, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4372, loss 0.113, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4373, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4374, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4375, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4376, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4377, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4378, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4379, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4380, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4381, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4382, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4383, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4384, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4385, loss 0.125, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4386, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4387, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4388, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4389, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4390, loss 0.287, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4391, loss 0.389, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4392, loss 0.255, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4393, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4394, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4395, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4396, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4397, loss 0.184, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4398, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4399, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4400, loss 0.412, batch accuracy 0.700\n",
      "Epoch 0, Iteration 4401, loss 0.238, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4402, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4403, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4404, loss 0.155, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4405, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4406, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4407, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4408, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4409, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4410, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4411, loss 0.306, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4412, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4413, loss 0.148, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4414, loss 0.195, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4415, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4416, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4417, loss 0.878, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4418, loss 0.004, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 4419, loss 0.218, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4420, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4421, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4422, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4423, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4424, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4425, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4426, loss 0.068, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4427, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4428, loss 0.339, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4429, loss 0.061, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4430, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4431, loss 0.186, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4432, loss 0.991, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4433, loss 0.808, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4434, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4435, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4436, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4437, loss 0.397, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4438, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4439, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4440, loss 0.631, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4441, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4442, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4443, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4444, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4445, loss 1.312, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4446, loss 0.223, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4447, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4448, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4449, loss 0.160, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4450, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4451, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4452, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4453, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4454, loss 1.153, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4455, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4456, loss 0.124, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4457, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4458, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4459, loss 0.203, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4460, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4461, loss 0.137, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4462, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4463, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4464, loss 0.087, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4465, loss 0.105, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4466, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4467, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4468, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4469, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4470, loss 0.279, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4471, loss 0.079, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4472, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4473, loss 0.282, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4474, loss 0.156, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4475, loss 0.291, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4476, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4477, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4478, loss 0.150, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4479, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4480, loss 0.091, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4481, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4482, loss 0.144, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4483, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4484, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4485, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4486, loss 0.239, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4487, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4488, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4489, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4490, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4491, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4492, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4493, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4494, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4495, loss 0.225, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4496, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4497, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4498, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4499, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4500, loss 0.584, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4501, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4502, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4503, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4504, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4505, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4506, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4507, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4508, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4509, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4510, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4511, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4512, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4513, loss 0.090, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4514, loss 0.215, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4515, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4516, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4517, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4518, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4519, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4520, loss 0.190, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4521, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4522, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4523, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4524, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4525, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4526, loss 0.081, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4527, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4528, loss 0.105, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4529, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4530, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4531, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4532, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4533, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4534, loss 0.060, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4535, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4536, loss 0.625, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4537, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4538, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4539, loss 0.070, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4540, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4541, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4542, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4543, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4544, loss 0.087, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4545, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4546, loss 0.440, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4547, loss 0.155, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4548, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4549, loss 0.301, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4550, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4551, loss 0.176, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4552, loss 0.729, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4553, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4554, loss 0.190, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4555, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4556, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4557, loss 0.083, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4558, loss 0.070, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4559, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4560, loss 0.186, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4561, loss 0.322, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4562, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4563, loss 0.153, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4564, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4565, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4566, loss 0.111, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4567, loss 0.000, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4568, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4569, loss 0.496, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4570, loss 0.108, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4571, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4572, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4573, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4574, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4575, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4576, loss 0.113, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4577, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4578, loss 0.403, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4579, loss 0.620, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4580, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4581, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4582, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4583, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4584, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4585, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4586, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4587, loss 0.526, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4588, loss 0.194, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4589, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4590, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4591, loss 0.084, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4592, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4593, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4594, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4595, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4596, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4597, loss 0.008, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 4598, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4599, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4600, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4601, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4602, loss 0.429, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4603, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4604, loss 0.936, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4605, loss 0.099, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4606, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4607, loss 0.000, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4608, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4609, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4610, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4611, loss 0.080, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4612, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4613, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4614, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4615, loss 0.503, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4616, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4617, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4618, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4619, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4620, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4621, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4622, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4623, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4624, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4625, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4626, loss 0.150, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4627, loss 0.268, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4628, loss 0.315, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4629, loss 0.330, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4630, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4631, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4632, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4633, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4634, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4635, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4636, loss 0.656, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4637, loss 0.139, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4638, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4639, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4640, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4641, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4642, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4643, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4644, loss 0.165, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4645, loss 0.232, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4646, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4647, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4648, loss 0.344, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4649, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4650, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4651, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4652, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4653, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4654, loss 0.497, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4655, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4656, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4657, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4658, loss 0.068, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4659, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4660, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4661, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4662, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4663, loss 0.196, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4664, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4665, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4666, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4667, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4668, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4669, loss 0.299, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4670, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4671, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4672, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4673, loss 0.365, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4674, loss 0.561, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4675, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4676, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4677, loss 0.242, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4678, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4679, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4680, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4681, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4682, loss 0.120, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4683, loss 0.101, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4684, loss 0.204, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4685, loss 0.271, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4686, loss 0.162, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4687, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4688, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4689, loss 0.182, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4690, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4691, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4692, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4693, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4694, loss 0.079, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4695, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4696, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4697, loss 0.095, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4698, loss 0.163, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4699, loss 0.247, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4700, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4701, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4702, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4703, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4704, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4705, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4706, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4707, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4708, loss 0.079, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4709, loss 0.621, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4710, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4711, loss 0.124, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4712, loss 0.087, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4713, loss 0.077, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4714, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4715, loss 0.096, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4716, loss 0.365, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4717, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4718, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4719, loss 0.274, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4720, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4721, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4722, loss 0.192, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4723, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4724, loss 0.543, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4725, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4726, loss 0.091, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4727, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4728, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4729, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4730, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4731, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4732, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4733, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4734, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4735, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4736, loss 0.215, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4737, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4738, loss 0.696, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4739, loss 0.097, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4740, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4741, loss 0.096, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4742, loss 0.120, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4743, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4744, loss 0.075, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4745, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4746, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4747, loss 0.088, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4748, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4749, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4750, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4751, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4752, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4753, loss 0.373, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4754, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4755, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4756, loss 0.105, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4757, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4758, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4759, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4760, loss 0.165, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4761, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4762, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4763, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4764, loss 0.132, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4765, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4766, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4767, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4768, loss 0.096, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4769, loss 0.218, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4770, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4771, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4772, loss 0.097, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4773, loss 0.074, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4774, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4775, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4776, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4777, loss 0.002, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 4778, loss 0.089, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4779, loss 0.263, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4780, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4781, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4782, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4783, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4784, loss 0.214, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4785, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4786, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4787, loss 0.452, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4788, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4789, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4790, loss 0.080, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4791, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4792, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4793, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4794, loss 0.401, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4795, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4796, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4797, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4798, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4799, loss 0.094, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4800, loss 0.113, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4801, loss 0.150, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4802, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4803, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4804, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4805, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4806, loss 0.227, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4807, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4808, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4809, loss 0.087, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4810, loss 0.402, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4811, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4812, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4813, loss 0.260, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4814, loss 0.182, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4815, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4816, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4817, loss 0.497, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4818, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4819, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4820, loss 0.087, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4821, loss 0.461, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4822, loss 0.074, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4823, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4824, loss 0.180, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4825, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4826, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4827, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4828, loss 0.447, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4829, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4830, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4831, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4832, loss 0.084, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4833, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4834, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4835, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4836, loss 0.204, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4837, loss 0.123, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4838, loss 0.090, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4839, loss 0.179, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4840, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4841, loss 0.335, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4842, loss 0.166, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4843, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4844, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4845, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4846, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4847, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4848, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4849, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4850, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4851, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4852, loss 0.187, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4853, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4854, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4855, loss 0.127, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4856, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4857, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4858, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4859, loss 0.228, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4860, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4861, loss 0.112, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4862, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4863, loss 0.334, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4864, loss 0.088, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4865, loss 0.099, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4866, loss 0.153, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4867, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4868, loss 0.427, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4869, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4870, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4871, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4872, loss 0.257, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4873, loss 0.261, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4874, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4875, loss 0.104, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4876, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4877, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4878, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4879, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4880, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4881, loss 0.166, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4882, loss 0.298, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4883, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4884, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4885, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4886, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4887, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4888, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4889, loss 0.141, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4890, loss 0.178, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4891, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4892, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4893, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4894, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4895, loss 0.090, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4896, loss 0.123, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4897, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4898, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4899, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4900, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4901, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4902, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4903, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4904, loss 0.079, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4905, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4906, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4907, loss 0.539, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4908, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4909, loss 0.167, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4910, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4911, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4912, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4913, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4914, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4915, loss 0.098, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4916, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4917, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4918, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4919, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4920, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4921, loss 0.307, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4922, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4923, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4924, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4925, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4926, loss 0.409, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4927, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4928, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4929, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4930, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4931, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4932, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4933, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4934, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4935, loss 0.130, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4936, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4937, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4938, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4939, loss 0.187, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4940, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4941, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4942, loss 0.818, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4943, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4944, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4945, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4946, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4947, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4948, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4949, loss 0.252, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4950, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4951, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4952, loss 0.014, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 4953, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4954, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4955, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4956, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4957, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4958, loss 0.186, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4959, loss 0.208, batch accuracy 0.800\n",
      "Epoch 0, Iteration 4960, loss 0.315, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4961, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4962, loss 0.659, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4963, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4964, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4965, loss 0.335, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4966, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4967, loss 0.241, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4968, loss 0.052, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4969, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4970, loss 0.499, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4971, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4972, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4973, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4974, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4975, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4976, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4977, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4978, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4979, loss 0.098, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4980, loss 0.110, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4981, loss 0.294, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4982, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4983, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4984, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4985, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4986, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4987, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4988, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4989, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4990, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4991, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4992, loss 0.101, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4993, loss 0.349, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4994, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4995, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4996, loss 1.208, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4997, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 4998, loss 0.149, batch accuracy 0.900\n",
      "Epoch 0, Iteration 4999, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5000, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5001, loss 0.208, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5002, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5003, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5004, loss 0.224, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5005, loss 0.582, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5006, loss 0.090, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5007, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5008, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5009, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5010, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5011, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5012, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5013, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5014, loss 0.122, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5015, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5016, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5017, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5018, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5019, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5020, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5021, loss 0.159, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5022, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5023, loss 1.112, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5024, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5025, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5026, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5027, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5028, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5029, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5030, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5031, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5032, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5033, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5034, loss 0.158, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5035, loss 0.272, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5036, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5037, loss 0.156, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5038, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5039, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5040, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5041, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5042, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5043, loss 0.610, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5044, loss 0.091, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5045, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5046, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5047, loss 0.000, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5048, loss 0.165, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5049, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5050, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5051, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5052, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5053, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5054, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5055, loss 0.142, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5056, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5057, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5058, loss 0.429, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5059, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5060, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5061, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5062, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5063, loss 0.160, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5064, loss 0.101, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5065, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5066, loss 0.156, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5067, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5068, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5069, loss 0.430, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5070, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5071, loss 0.177, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5072, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5073, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5074, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5075, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5076, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5077, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5078, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5079, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5080, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5081, loss 0.069, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5082, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5083, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5084, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5085, loss 0.234, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5086, loss 0.106, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5087, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5088, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5089, loss 0.734, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5090, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5091, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5092, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5093, loss 0.186, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5094, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5095, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5096, loss 0.167, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5097, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5098, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5099, loss 1.121, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5100, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5101, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5102, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5103, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5104, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5105, loss 0.452, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5106, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5107, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5108, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5109, loss 0.215, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5110, loss 0.346, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5111, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5112, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5113, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5114, loss 0.139, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5115, loss 0.886, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5116, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5117, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5118, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5119, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5120, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5121, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5122, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5123, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5124, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5125, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5126, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5127, loss 0.057, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 5128, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5129, loss 0.149, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5130, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5131, loss 0.106, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5132, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5133, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5134, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5135, loss 0.503, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5136, loss 0.077, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5137, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5138, loss 0.241, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5139, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5140, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5141, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5142, loss 0.052, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5143, loss 0.198, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5144, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5145, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5146, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5147, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5148, loss 0.103, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5149, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5150, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5151, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5152, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5153, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5154, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5155, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5156, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5157, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5158, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5159, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5160, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5161, loss 0.156, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5162, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5163, loss 0.235, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5164, loss 0.101, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5165, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5166, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5167, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5168, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5169, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5170, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5171, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5172, loss 0.463, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5173, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5174, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5175, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5176, loss 0.393, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5177, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5178, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5179, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5180, loss 0.214, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5181, loss 0.184, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5182, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5183, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5184, loss 0.332, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5185, loss 0.221, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5186, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5187, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5188, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5189, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5190, loss 0.113, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5191, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5192, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5193, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5194, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5195, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5196, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5197, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5198, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5199, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5200, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5201, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5202, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5203, loss 0.050, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5204, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5205, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5206, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5207, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5208, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5209, loss 0.000, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5210, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5211, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5212, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5213, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5214, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5215, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5216, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5217, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5218, loss 0.094, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5219, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5220, loss 0.202, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5221, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5222, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5223, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5224, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5225, loss 0.102, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5226, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5227, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5228, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5229, loss 0.367, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5230, loss 0.361, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5231, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5232, loss 0.000, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5233, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5234, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5235, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5236, loss 0.166, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5237, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5238, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5239, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5240, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5241, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5242, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5243, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5244, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5245, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5246, loss 0.411, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5247, loss 0.200, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5248, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5249, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5250, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5251, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5252, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5253, loss 0.000, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5254, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5255, loss 0.298, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5256, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5257, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5258, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5259, loss 0.570, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5260, loss 0.069, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5261, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5262, loss 0.529, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5263, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5264, loss 0.070, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5265, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5266, loss 0.376, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5267, loss 0.209, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5268, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5269, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5270, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5271, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5272, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5273, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5274, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5275, loss 0.699, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5276, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5277, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5278, loss 0.181, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5279, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5280, loss 0.426, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5281, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5282, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5283, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5284, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5285, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5286, loss 0.071, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5287, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5288, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5289, loss 0.347, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5290, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5291, loss 0.453, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5292, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5293, loss 0.285, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5294, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5295, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5296, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5297, loss 0.378, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5298, loss 0.110, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5299, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5300, loss 0.213, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5301, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5302, loss 0.390, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5303, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5304, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5305, loss 0.083, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5306, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5307, loss 0.000, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5308, loss 0.001, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 5309, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5310, loss 0.482, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5311, loss 1.269, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5312, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5313, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5314, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5315, loss 0.126, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5316, loss 0.123, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5317, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5318, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5319, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5320, loss 0.036, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5321, loss 0.052, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5322, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5323, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5324, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5325, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5326, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5327, loss 0.100, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5328, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5329, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5330, loss 0.194, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5331, loss 0.245, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5332, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5333, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5334, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5335, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5336, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5337, loss 0.797, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5338, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5339, loss 0.159, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5340, loss 0.155, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5341, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5342, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5343, loss 0.132, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5344, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5345, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5346, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5347, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5348, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5349, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5350, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5351, loss 0.122, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5352, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5353, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5354, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5355, loss 0.253, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5356, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5357, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5358, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5359, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5360, loss 0.121, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5361, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5362, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5363, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5364, loss 0.416, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5365, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5366, loss 0.106, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5367, loss 0.143, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5368, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5369, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5370, loss 0.000, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5371, loss 0.283, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5372, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5373, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5374, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5375, loss 0.220, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5376, loss 0.228, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5377, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5378, loss 0.185, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5379, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5380, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5381, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5382, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5383, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5384, loss 1.102, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5385, loss 0.040, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5386, loss 0.869, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5387, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5388, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5389, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5390, loss 0.286, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5391, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5392, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5393, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5394, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5395, loss 0.210, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5396, loss 0.120, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5397, loss 0.297, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5398, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5399, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5400, loss 0.084, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5401, loss 0.067, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5402, loss 0.364, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5403, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5404, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5405, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5406, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5407, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5408, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5409, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5410, loss 0.087, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5411, loss 0.561, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5412, loss 0.077, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5413, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5414, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5415, loss 0.138, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5416, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5417, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5418, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5419, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5420, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5421, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5422, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5423, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5424, loss 0.082, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5425, loss 0.258, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5426, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5427, loss 0.213, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5428, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5429, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5430, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5431, loss 0.078, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5432, loss 0.812, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5433, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5434, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5435, loss 0.260, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5436, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5437, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5438, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5439, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5440, loss 0.353, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5441, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5442, loss 0.136, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5443, loss 0.632, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5444, loss 0.049, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5445, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5446, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5447, loss 0.256, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5448, loss 0.100, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5449, loss 0.069, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5450, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5451, loss 0.072, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5452, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5453, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5454, loss 0.495, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5455, loss 0.068, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5456, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5457, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5458, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5459, loss 0.477, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5460, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5461, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5462, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5463, loss 0.279, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5464, loss 0.879, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5465, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5466, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5467, loss 0.153, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5468, loss 0.171, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5469, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5470, loss 0.730, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5471, loss 0.410, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5472, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5473, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5474, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5475, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5476, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5477, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5478, loss 0.163, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5479, loss 0.136, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5480, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5481, loss 0.248, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5482, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5483, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5484, loss 0.063, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 5485, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5486, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5487, loss 0.126, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5488, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5489, loss 0.243, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5490, loss 0.181, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5491, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5492, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5493, loss 0.099, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5494, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5495, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5496, loss 0.124, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5497, loss 0.185, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5498, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5499, loss 0.082, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5500, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5501, loss 0.432, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5502, loss 0.199, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5503, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5504, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5505, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5506, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5507, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5508, loss 0.072, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5509, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5510, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5511, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5512, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5513, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5514, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5515, loss 0.350, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5516, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5517, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5518, loss 0.116, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5519, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5520, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5521, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5522, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5523, loss 0.266, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5524, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5525, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5526, loss 0.451, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5527, loss 0.206, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5528, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5529, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5530, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5531, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5532, loss 0.120, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5533, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5534, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5535, loss 0.115, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5536, loss 0.135, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5537, loss 0.227, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5538, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5539, loss 0.038, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5540, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5541, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5542, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5543, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5544, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5545, loss 0.243, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5546, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5547, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5548, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5549, loss 0.439, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5550, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5551, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5552, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5553, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5554, loss 0.230, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5555, loss 0.119, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5556, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5557, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5558, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5559, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5560, loss 0.389, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5561, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5562, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5563, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5564, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5565, loss 0.257, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5566, loss 0.346, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5567, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5568, loss 0.204, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5569, loss 0.140, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5570, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5571, loss 0.101, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5572, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5573, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5574, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5575, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5576, loss 0.590, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5577, loss 0.148, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5578, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5579, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5580, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5581, loss 1.062, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5582, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5583, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5584, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5585, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5586, loss 0.045, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5587, loss 0.060, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5588, loss 0.363, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5589, loss 0.495, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5590, loss 0.109, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5591, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5592, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5593, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5594, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5595, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5596, loss 0.086, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5597, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5598, loss 0.549, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5599, loss 0.166, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5600, loss 0.406, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5601, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5602, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5603, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5604, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5605, loss 0.128, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5606, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5607, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5608, loss 0.077, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5609, loss 0.139, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5610, loss 0.073, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5611, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5612, loss 0.707, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5613, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5614, loss 0.263, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5615, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5616, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5617, loss 0.204, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5618, loss 0.066, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5619, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5620, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5621, loss 0.898, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5622, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5623, loss 0.091, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5624, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5625, loss 0.061, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5626, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5627, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5628, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5629, loss 0.388, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5630, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5631, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5632, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5633, loss 0.041, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5634, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5635, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5636, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5637, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5638, loss 0.084, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5639, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5640, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5641, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5642, loss 0.000, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5643, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5644, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5645, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5646, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5647, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5648, loss 0.437, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5649, loss 0.092, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5650, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5651, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5652, loss 0.149, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5653, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5654, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5655, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5656, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5657, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5658, loss 0.384, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5659, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5660, loss 0.185, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5661, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5662, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5663, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5664, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5665, loss 0.005, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 5666, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5667, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5668, loss 0.202, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5669, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5670, loss 0.025, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5671, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5672, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5673, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5674, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5675, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5676, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5677, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5678, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5679, loss 0.128, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5680, loss 0.000, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5681, loss 0.154, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5682, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5683, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5684, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5685, loss 0.055, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5686, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5687, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5688, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5689, loss 0.185, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5690, loss 0.431, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5691, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5692, loss 0.199, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5693, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5694, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5695, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5696, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5697, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5698, loss 0.133, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5699, loss 0.053, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5700, loss 0.435, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5701, loss 0.021, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5702, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5703, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5704, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5705, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5706, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5707, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5708, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5709, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5710, loss 0.147, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5711, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5712, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5713, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5714, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5715, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5716, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5717, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5718, loss 0.087, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5719, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5720, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5721, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5722, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5723, loss 0.155, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5724, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5725, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5726, loss 0.048, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5727, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5728, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5729, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5730, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5731, loss 0.141, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5732, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5733, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5734, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5735, loss 0.092, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5736, loss 0.152, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5737, loss 0.085, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5738, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5739, loss 0.157, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5740, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5741, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5742, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5743, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5744, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5745, loss 0.058, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5746, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5747, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5748, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5749, loss 0.458, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5750, loss 0.787, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5751, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5752, loss 0.015, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5753, loss 0.507, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5754, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5755, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5756, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5757, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5758, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5759, loss 0.052, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5760, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5761, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5762, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5763, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5764, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5765, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5766, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5767, loss 0.092, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5768, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5769, loss 0.000, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5770, loss 0.065, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5771, loss 0.128, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5772, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5773, loss 0.075, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5774, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5775, loss 0.000, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5776, loss 0.553, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5777, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5778, loss 0.074, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5779, loss 0.308, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5780, loss 0.139, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5781, loss 0.068, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5782, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5783, loss 0.075, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5784, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5785, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5786, loss 0.155, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5787, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5788, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5789, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5790, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5791, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5792, loss 0.087, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5793, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5794, loss 0.465, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5795, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5796, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5797, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5798, loss 0.031, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5799, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5800, loss 0.078, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5801, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5802, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5803, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5804, loss 0.017, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5805, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5806, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5807, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5808, loss 0.083, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5809, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5810, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5811, loss 0.037, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5812, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5813, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5814, loss 0.054, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5815, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5816, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5817, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5818, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5819, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5820, loss 0.172, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5821, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5822, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5823, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5824, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5825, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5826, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5827, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5828, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5829, loss 0.180, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5830, loss 0.176, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5831, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5832, loss 0.042, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5833, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5834, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5835, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5836, loss 0.512, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5837, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5838, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5839, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5840, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5841, loss 0.024, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 5842, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5843, loss 0.087, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5844, loss 0.419, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5845, loss 0.023, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5846, loss 0.162, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5847, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5848, loss 0.056, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5849, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5850, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5851, loss 0.104, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5852, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5853, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5854, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5855, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5856, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5857, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5858, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5859, loss 0.182, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5860, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5861, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5862, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5863, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5864, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5865, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5866, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5867, loss 0.070, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5868, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5869, loss 0.034, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5870, loss 0.029, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5871, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5872, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5873, loss 0.433, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5874, loss 0.267, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5875, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5876, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5877, loss 0.706, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5878, loss 0.188, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5879, loss 0.046, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5880, loss 0.198, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5881, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5882, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5883, loss 0.032, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5884, loss 0.086, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5885, loss 0.076, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5886, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5887, loss 0.024, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5888, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5889, loss 0.022, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5890, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5891, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5892, loss 0.156, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5893, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5894, loss 0.280, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5895, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5896, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5897, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5898, loss 0.070, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5899, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5900, loss 0.550, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5901, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5902, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5903, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5904, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5905, loss 0.035, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5906, loss 0.103, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5907, loss 0.000, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5908, loss 0.095, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5909, loss 0.062, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5910, loss 0.175, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5911, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5912, loss 0.079, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5913, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5914, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5915, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5916, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5917, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5918, loss 0.033, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5919, loss 0.243, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5920, loss 0.064, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5921, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5922, loss 0.019, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5923, loss 0.680, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5924, loss 0.178, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5925, loss 0.077, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5926, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5927, loss 0.569, batch accuracy 0.700\n",
      "Epoch 0, Iteration 5928, loss 0.026, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5929, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5930, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5931, loss 0.000, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5932, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5933, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5934, loss 0.829, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5935, loss 0.059, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5936, loss 0.051, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5937, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5938, loss 0.039, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5939, loss 0.030, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5940, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5941, loss 0.331, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5942, loss 0.393, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5943, loss 0.047, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5944, loss 0.180, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5945, loss 0.636, batch accuracy 0.800\n",
      "Epoch 0, Iteration 5946, loss 0.126, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5947, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5948, loss 0.345, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5949, loss 0.101, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5950, loss 0.044, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5951, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5952, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5953, loss 0.089, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5954, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5955, loss 0.016, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5956, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5957, loss 0.027, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5958, loss 0.095, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5959, loss 0.003, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5960, loss 0.011, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5961, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5962, loss 0.153, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5963, loss 0.424, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5964, loss 0.098, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5965, loss 0.012, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5966, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5967, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5968, loss 0.020, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5969, loss 0.010, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5970, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5971, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5972, loss 0.137, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5973, loss 0.347, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5974, loss 0.018, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5975, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5976, loss 0.922, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5977, loss 0.373, batch accuracy 0.900\n",
      "Epoch 0, Iteration 5978, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5979, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5980, loss 0.006, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5981, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5982, loss 0.014, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5983, loss 0.075, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5984, loss 0.004, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5985, loss 0.013, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5986, loss 0.028, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5987, loss 0.070, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5988, loss 0.001, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5989, loss 0.043, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5990, loss 0.007, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5991, loss 0.005, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5992, loss 0.063, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5993, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5994, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5995, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5996, loss 0.002, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5997, loss 0.008, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5998, loss 0.009, batch accuracy 1.000\n",
      "Epoch 0, Iteration 5999, loss 0.071, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 0, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2, loss 0.358, batch accuracy 0.700\n",
      "Epoch 1, Iteration 3, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 6, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 7, loss 0.051, batch accuracy 1.000\n",
      "Epoch 1, Iteration 8, loss 0.243, batch accuracy 0.900\n",
      "Epoch 1, Iteration 9, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 10, loss 0.063, batch accuracy 1.000\n",
      "Epoch 1, Iteration 11, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 12, loss 0.126, batch accuracy 0.900\n",
      "Epoch 1, Iteration 13, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 14, loss 0.059, batch accuracy 1.000\n",
      "Epoch 1, Iteration 15, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 16, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 17, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 18, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 19, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 20, loss 0.068, batch accuracy 1.000\n",
      "Epoch 1, Iteration 21, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 22, loss 0.048, batch accuracy 1.000\n",
      "Epoch 1, Iteration 23, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 24, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 25, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 26, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 27, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 28, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 29, loss 0.055, batch accuracy 1.000\n",
      "Epoch 1, Iteration 30, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 31, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 32, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 33, loss 0.065, batch accuracy 1.000\n",
      "Epoch 1, Iteration 34, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 35, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 36, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 37, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 38, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 39, loss 0.109, batch accuracy 1.000\n",
      "Epoch 1, Iteration 40, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 41, loss 0.306, batch accuracy 0.900\n",
      "Epoch 1, Iteration 42, loss 0.205, batch accuracy 0.900\n",
      "Epoch 1, Iteration 43, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 44, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 45, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 46, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 47, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 48, loss 0.083, batch accuracy 1.000\n",
      "Epoch 1, Iteration 49, loss 0.108, batch accuracy 0.900\n",
      "Epoch 1, Iteration 50, loss 0.079, batch accuracy 1.000\n",
      "Epoch 1, Iteration 51, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 52, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 53, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 54, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 55, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 56, loss 0.077, batch accuracy 1.000\n",
      "Epoch 1, Iteration 57, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 58, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 59, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 60, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 61, loss 0.121, batch accuracy 0.900\n",
      "Epoch 1, Iteration 62, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 63, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 64, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 65, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 66, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 67, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 68, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 69, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 70, loss 0.074, batch accuracy 1.000\n",
      "Epoch 1, Iteration 71, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 72, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 73, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 74, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 75, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 76, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 77, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 78, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 79, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 80, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 81, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 82, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 83, loss 0.089, batch accuracy 1.000\n",
      "Epoch 1, Iteration 84, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 85, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 86, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 87, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 88, loss 0.111, batch accuracy 0.900\n",
      "Epoch 1, Iteration 89, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 90, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 91, loss 0.290, batch accuracy 0.900\n",
      "Epoch 1, Iteration 92, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 93, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 94, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 95, loss 0.167, batch accuracy 0.900\n",
      "Epoch 1, Iteration 96, loss 0.129, batch accuracy 0.900\n",
      "Epoch 1, Iteration 97, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 98, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 99, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 100, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 101, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 102, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 103, loss 0.074, batch accuracy 0.900\n",
      "Epoch 1, Iteration 104, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 105, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 106, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 107, loss 0.090, batch accuracy 0.900\n",
      "Epoch 1, Iteration 108, loss 0.382, batch accuracy 0.900\n",
      "Epoch 1, Iteration 109, loss 0.460, batch accuracy 0.800\n",
      "Epoch 1, Iteration 110, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 111, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 112, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 113, loss 0.062, batch accuracy 1.000\n",
      "Epoch 1, Iteration 114, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 115, loss 0.045, batch accuracy 1.000\n",
      "Epoch 1, Iteration 116, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 117, loss 0.225, batch accuracy 0.900\n",
      "Epoch 1, Iteration 118, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 119, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 120, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 121, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 122, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 123, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 124, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 125, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 126, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 127, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 128, loss 0.150, batch accuracy 0.900\n",
      "Epoch 1, Iteration 129, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 130, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 131, loss 0.110, batch accuracy 0.900\n",
      "Epoch 1, Iteration 132, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 133, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 134, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 135, loss 0.055, batch accuracy 1.000\n",
      "Epoch 1, Iteration 136, loss 0.617, batch accuracy 0.900\n",
      "Epoch 1, Iteration 137, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 138, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 139, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 140, loss 0.088, batch accuracy 0.900\n",
      "Epoch 1, Iteration 141, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 142, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 143, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 144, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 145, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 146, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 147, loss 0.556, batch accuracy 0.900\n",
      "Epoch 1, Iteration 148, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 149, loss 0.154, batch accuracy 0.900\n",
      "Epoch 1, Iteration 150, loss 0.052, batch accuracy 1.000\n",
      "Epoch 1, Iteration 151, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 152, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 153, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 154, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 155, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 156, loss 0.505, batch accuracy 0.900\n",
      "Epoch 1, Iteration 157, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 158, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 159, loss 0.062, batch accuracy 1.000\n",
      "Epoch 1, Iteration 160, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 161, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 162, loss 0.110, batch accuracy 1.000\n",
      "Epoch 1, Iteration 163, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 164, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 165, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 166, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 167, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 168, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 169, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 170, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 171, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 172, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 173, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 174, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 175, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 176, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 177, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 178, loss 0.000, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 179, loss 0.142, batch accuracy 0.900\n",
      "Epoch 1, Iteration 180, loss 0.711, batch accuracy 0.900\n",
      "Epoch 1, Iteration 181, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 182, loss 0.076, batch accuracy 0.900\n",
      "Epoch 1, Iteration 183, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 184, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 185, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 186, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 187, loss 0.149, batch accuracy 0.900\n",
      "Epoch 1, Iteration 188, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 189, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 190, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 191, loss 0.348, batch accuracy 0.900\n",
      "Epoch 1, Iteration 192, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 193, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 194, loss 0.062, batch accuracy 1.000\n",
      "Epoch 1, Iteration 195, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 196, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 197, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 198, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 199, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 200, loss 0.145, batch accuracy 0.900\n",
      "Epoch 1, Iteration 201, loss 0.152, batch accuracy 0.900\n",
      "Epoch 1, Iteration 202, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 203, loss 0.169, batch accuracy 0.900\n",
      "Epoch 1, Iteration 204, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 205, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 206, loss 0.144, batch accuracy 0.900\n",
      "Epoch 1, Iteration 207, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 208, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 209, loss 0.061, batch accuracy 1.000\n",
      "Epoch 1, Iteration 210, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 211, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 212, loss 0.102, batch accuracy 0.900\n",
      "Epoch 1, Iteration 213, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 214, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 215, loss 0.070, batch accuracy 1.000\n",
      "Epoch 1, Iteration 216, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 217, loss 0.049, batch accuracy 1.000\n",
      "Epoch 1, Iteration 218, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 219, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 220, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 221, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 222, loss 0.185, batch accuracy 0.900\n",
      "Epoch 1, Iteration 223, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 224, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 225, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 226, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 227, loss 0.085, batch accuracy 0.900\n",
      "Epoch 1, Iteration 228, loss 0.138, batch accuracy 0.900\n",
      "Epoch 1, Iteration 229, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 230, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 231, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 232, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 233, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 234, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 235, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 236, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 237, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 238, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 239, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 240, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 241, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 242, loss 0.054, batch accuracy 1.000\n",
      "Epoch 1, Iteration 243, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 244, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 245, loss 0.103, batch accuracy 0.900\n",
      "Epoch 1, Iteration 246, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 247, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 248, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 249, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 250, loss 0.089, batch accuracy 1.000\n",
      "Epoch 1, Iteration 251, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 252, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 253, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 254, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 255, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 256, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 257, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 258, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 259, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 260, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 261, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 262, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 263, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 264, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 265, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 266, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 267, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 268, loss 0.348, batch accuracy 0.800\n",
      "Epoch 1, Iteration 269, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 270, loss 0.226, batch accuracy 0.900\n",
      "Epoch 1, Iteration 271, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 272, loss 0.064, batch accuracy 1.000\n",
      "Epoch 1, Iteration 273, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 274, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 275, loss 0.169, batch accuracy 0.900\n",
      "Epoch 1, Iteration 276, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 277, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 278, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 279, loss 0.078, batch accuracy 0.900\n",
      "Epoch 1, Iteration 280, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 281, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 282, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 283, loss 0.053, batch accuracy 1.000\n",
      "Epoch 1, Iteration 284, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 285, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 286, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 287, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 288, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 289, loss 0.063, batch accuracy 1.000\n",
      "Epoch 1, Iteration 290, loss 0.224, batch accuracy 0.900\n",
      "Epoch 1, Iteration 291, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 292, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 293, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 294, loss 0.254, batch accuracy 0.800\n",
      "Epoch 1, Iteration 295, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 296, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 297, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 298, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 299, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 300, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 301, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 302, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 303, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 304, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 305, loss 0.165, batch accuracy 0.900\n",
      "Epoch 1, Iteration 306, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 307, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 308, loss 0.620, batch accuracy 0.800\n",
      "Epoch 1, Iteration 309, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 310, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 311, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 312, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 313, loss 0.751, batch accuracy 0.900\n",
      "Epoch 1, Iteration 314, loss 0.107, batch accuracy 0.900\n",
      "Epoch 1, Iteration 315, loss 0.065, batch accuracy 1.000\n",
      "Epoch 1, Iteration 316, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 317, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 318, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 319, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 320, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 321, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 322, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 323, loss 0.120, batch accuracy 0.900\n",
      "Epoch 1, Iteration 324, loss 0.062, batch accuracy 1.000\n",
      "Epoch 1, Iteration 325, loss 0.076, batch accuracy 1.000\n",
      "Epoch 1, Iteration 326, loss 0.120, batch accuracy 1.000\n",
      "Epoch 1, Iteration 327, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 328, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 329, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 330, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 331, loss 0.047, batch accuracy 1.000\n",
      "Epoch 1, Iteration 332, loss 0.070, batch accuracy 1.000\n",
      "Epoch 1, Iteration 333, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 334, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 335, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 336, loss 0.333, batch accuracy 0.900\n",
      "Epoch 1, Iteration 337, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 338, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 339, loss 0.094, batch accuracy 0.900\n",
      "Epoch 1, Iteration 340, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 341, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 342, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 343, loss 0.237, batch accuracy 0.900\n",
      "Epoch 1, Iteration 344, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 345, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 346, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 347, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 348, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 349, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 350, loss 0.104, batch accuracy 0.900\n",
      "Epoch 1, Iteration 351, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 352, loss 0.055, batch accuracy 1.000\n",
      "Epoch 1, Iteration 353, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 354, loss 0.077, batch accuracy 1.000\n",
      "Epoch 1, Iteration 355, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 356, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 357, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 358, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 359, loss 0.004, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 360, loss 0.085, batch accuracy 1.000\n",
      "Epoch 1, Iteration 361, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 362, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 363, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 364, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 365, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 366, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 367, loss 0.215, batch accuracy 0.900\n",
      "Epoch 1, Iteration 368, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 369, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 370, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 371, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 372, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 373, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 374, loss 0.074, batch accuracy 0.900\n",
      "Epoch 1, Iteration 375, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 376, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 377, loss 0.931, batch accuracy 0.800\n",
      "Epoch 1, Iteration 378, loss 0.064, batch accuracy 1.000\n",
      "Epoch 1, Iteration 379, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 380, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 381, loss 0.205, batch accuracy 0.900\n",
      "Epoch 1, Iteration 382, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 383, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 384, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 385, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 386, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 387, loss 0.126, batch accuracy 0.900\n",
      "Epoch 1, Iteration 388, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 389, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 390, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 391, loss 0.058, batch accuracy 1.000\n",
      "Epoch 1, Iteration 392, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 393, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 394, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 395, loss 0.084, batch accuracy 1.000\n",
      "Epoch 1, Iteration 396, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 397, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 398, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 399, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 400, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 401, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 402, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 403, loss 0.319, batch accuracy 0.900\n",
      "Epoch 1, Iteration 404, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 405, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 406, loss 0.096, batch accuracy 0.900\n",
      "Epoch 1, Iteration 407, loss 0.078, batch accuracy 1.000\n",
      "Epoch 1, Iteration 408, loss 0.070, batch accuracy 1.000\n",
      "Epoch 1, Iteration 409, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 410, loss 0.967, batch accuracy 0.800\n",
      "Epoch 1, Iteration 411, loss 0.100, batch accuracy 0.900\n",
      "Epoch 1, Iteration 412, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 413, loss 0.051, batch accuracy 1.000\n",
      "Epoch 1, Iteration 414, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 415, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 416, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 417, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 418, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 419, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 420, loss 0.209, batch accuracy 0.900\n",
      "Epoch 1, Iteration 421, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 422, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 423, loss 0.127, batch accuracy 0.900\n",
      "Epoch 1, Iteration 424, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 425, loss 0.062, batch accuracy 1.000\n",
      "Epoch 1, Iteration 426, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 427, loss 0.230, batch accuracy 0.900\n",
      "Epoch 1, Iteration 428, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 429, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 430, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 431, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 432, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 433, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 434, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 435, loss 0.375, batch accuracy 0.900\n",
      "Epoch 1, Iteration 436, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 437, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 438, loss 0.180, batch accuracy 1.000\n",
      "Epoch 1, Iteration 439, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 440, loss 0.042, batch accuracy 1.000\n",
      "Epoch 1, Iteration 441, loss 0.083, batch accuracy 1.000\n",
      "Epoch 1, Iteration 442, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 443, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 444, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 445, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 446, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 447, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 448, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 449, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 450, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 451, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 452, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 453, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 454, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 455, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 456, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 457, loss 0.363, batch accuracy 0.800\n",
      "Epoch 1, Iteration 458, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 459, loss 0.453, batch accuracy 0.900\n",
      "Epoch 1, Iteration 460, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 461, loss 0.070, batch accuracy 1.000\n",
      "Epoch 1, Iteration 462, loss 0.509, batch accuracy 0.900\n",
      "Epoch 1, Iteration 463, loss 0.242, batch accuracy 0.900\n",
      "Epoch 1, Iteration 464, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 465, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 466, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 467, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 468, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 469, loss 0.147, batch accuracy 0.900\n",
      "Epoch 1, Iteration 470, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 471, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 472, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 473, loss 0.060, batch accuracy 1.000\n",
      "Epoch 1, Iteration 474, loss 0.044, batch accuracy 1.000\n",
      "Epoch 1, Iteration 475, loss 0.099, batch accuracy 0.900\n",
      "Epoch 1, Iteration 476, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 477, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 478, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 479, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 480, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 481, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 482, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 483, loss 0.080, batch accuracy 0.900\n",
      "Epoch 1, Iteration 484, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 485, loss 0.076, batch accuracy 0.900\n",
      "Epoch 1, Iteration 486, loss 0.076, batch accuracy 1.000\n",
      "Epoch 1, Iteration 487, loss 0.256, batch accuracy 0.900\n",
      "Epoch 1, Iteration 488, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 489, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 490, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 491, loss 0.318, batch accuracy 0.900\n",
      "Epoch 1, Iteration 492, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 493, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 494, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 495, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 496, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 497, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 498, loss 0.336, batch accuracy 0.900\n",
      "Epoch 1, Iteration 499, loss 0.058, batch accuracy 1.000\n",
      "Epoch 1, Iteration 500, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 501, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 502, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 503, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 504, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 505, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 506, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 507, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 508, loss 0.075, batch accuracy 1.000\n",
      "Epoch 1, Iteration 509, loss 0.052, batch accuracy 1.000\n",
      "Epoch 1, Iteration 510, loss 0.065, batch accuracy 1.000\n",
      "Epoch 1, Iteration 511, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 512, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 513, loss 0.106, batch accuracy 0.900\n",
      "Epoch 1, Iteration 514, loss 0.089, batch accuracy 1.000\n",
      "Epoch 1, Iteration 515, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 516, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 517, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 518, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 519, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 520, loss 0.038, batch accuracy 1.000\n",
      "Epoch 1, Iteration 521, loss 0.093, batch accuracy 1.000\n",
      "Epoch 1, Iteration 522, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 523, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 524, loss 0.242, batch accuracy 0.900\n",
      "Epoch 1, Iteration 525, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 526, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 527, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 528, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 529, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 530, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 531, loss 0.065, batch accuracy 1.000\n",
      "Epoch 1, Iteration 532, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 533, loss 0.071, batch accuracy 1.000\n",
      "Epoch 1, Iteration 534, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 535, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 536, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 537, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 538, loss 1.449, batch accuracy 0.900\n",
      "Epoch 1, Iteration 539, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 540, loss 0.229, batch accuracy 0.900\n",
      "Epoch 1, Iteration 541, loss 0.106, batch accuracy 0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 542, loss 0.045, batch accuracy 1.000\n",
      "Epoch 1, Iteration 543, loss 0.098, batch accuracy 0.900\n",
      "Epoch 1, Iteration 544, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 545, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 546, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 547, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 548, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 549, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 550, loss 0.120, batch accuracy 0.900\n",
      "Epoch 1, Iteration 551, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 552, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 553, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 554, loss 0.493, batch accuracy 0.900\n",
      "Epoch 1, Iteration 555, loss 0.580, batch accuracy 0.900\n",
      "Epoch 1, Iteration 556, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 557, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 558, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 559, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 560, loss 0.478, batch accuracy 0.800\n",
      "Epoch 1, Iteration 561, loss 0.060, batch accuracy 1.000\n",
      "Epoch 1, Iteration 562, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 563, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 564, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 565, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 566, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 567, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 568, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 569, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 570, loss 0.075, batch accuracy 1.000\n",
      "Epoch 1, Iteration 571, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 572, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 573, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 574, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 575, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 576, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 577, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 578, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 579, loss 0.157, batch accuracy 0.900\n",
      "Epoch 1, Iteration 580, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 581, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 582, loss 0.101, batch accuracy 0.900\n",
      "Epoch 1, Iteration 583, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 584, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 585, loss 0.327, batch accuracy 0.800\n",
      "Epoch 1, Iteration 586, loss 0.288, batch accuracy 0.900\n",
      "Epoch 1, Iteration 587, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 588, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 589, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 590, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 591, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 592, loss 0.067, batch accuracy 1.000\n",
      "Epoch 1, Iteration 593, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 594, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 595, loss 0.049, batch accuracy 1.000\n",
      "Epoch 1, Iteration 596, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 597, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 598, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 599, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 600, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 601, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 602, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 603, loss 0.374, batch accuracy 0.900\n",
      "Epoch 1, Iteration 604, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 605, loss 0.182, batch accuracy 0.900\n",
      "Epoch 1, Iteration 606, loss 0.782, batch accuracy 0.900\n",
      "Epoch 1, Iteration 607, loss 0.293, batch accuracy 0.900\n",
      "Epoch 1, Iteration 608, loss 0.098, batch accuracy 0.900\n",
      "Epoch 1, Iteration 609, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 610, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 611, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 612, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 613, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 614, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 615, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 616, loss 0.172, batch accuracy 0.900\n",
      "Epoch 1, Iteration 617, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 618, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 619, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 620, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 621, loss 0.045, batch accuracy 1.000\n",
      "Epoch 1, Iteration 622, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 623, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 624, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 625, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 626, loss 0.074, batch accuracy 1.000\n",
      "Epoch 1, Iteration 627, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 628, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 629, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 630, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 631, loss 0.276, batch accuracy 0.900\n",
      "Epoch 1, Iteration 632, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 633, loss 0.329, batch accuracy 0.900\n",
      "Epoch 1, Iteration 634, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 635, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 636, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 637, loss 0.176, batch accuracy 0.900\n",
      "Epoch 1, Iteration 638, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 639, loss 0.608, batch accuracy 0.800\n",
      "Epoch 1, Iteration 640, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 641, loss 0.119, batch accuracy 0.900\n",
      "Epoch 1, Iteration 642, loss 0.450, batch accuracy 0.900\n",
      "Epoch 1, Iteration 643, loss 0.045, batch accuracy 1.000\n",
      "Epoch 1, Iteration 644, loss 0.193, batch accuracy 0.900\n",
      "Epoch 1, Iteration 645, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 646, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 647, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 648, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 649, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 650, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 651, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 652, loss 0.123, batch accuracy 0.900\n",
      "Epoch 1, Iteration 653, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 654, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 655, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 656, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 657, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 658, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 659, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 660, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 661, loss 0.179, batch accuracy 0.900\n",
      "Epoch 1, Iteration 662, loss 0.044, batch accuracy 1.000\n",
      "Epoch 1, Iteration 663, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 664, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 665, loss 0.071, batch accuracy 1.000\n",
      "Epoch 1, Iteration 666, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 667, loss 0.122, batch accuracy 0.900\n",
      "Epoch 1, Iteration 668, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 669, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 670, loss 0.307, batch accuracy 0.900\n",
      "Epoch 1, Iteration 671, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 672, loss 0.095, batch accuracy 0.900\n",
      "Epoch 1, Iteration 673, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 674, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 675, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 676, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 677, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 678, loss 0.120, batch accuracy 1.000\n",
      "Epoch 1, Iteration 679, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 680, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 681, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 682, loss 0.121, batch accuracy 0.900\n",
      "Epoch 1, Iteration 683, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 684, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 685, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 686, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 687, loss 0.182, batch accuracy 0.900\n",
      "Epoch 1, Iteration 688, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 689, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 690, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 691, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 692, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 693, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 694, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 695, loss 0.049, batch accuracy 1.000\n",
      "Epoch 1, Iteration 696, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 697, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 698, loss 0.173, batch accuracy 0.900\n",
      "Epoch 1, Iteration 699, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 700, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 701, loss 0.320, batch accuracy 0.900\n",
      "Epoch 1, Iteration 702, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 703, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 704, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 705, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 706, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 707, loss 0.239, batch accuracy 0.900\n",
      "Epoch 1, Iteration 708, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 709, loss 0.079, batch accuracy 1.000\n",
      "Epoch 1, Iteration 710, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 711, loss 0.048, batch accuracy 1.000\n",
      "Epoch 1, Iteration 712, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 713, loss 0.219, batch accuracy 0.900\n",
      "Epoch 1, Iteration 714, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 715, loss 0.087, batch accuracy 1.000\n",
      "Epoch 1, Iteration 716, loss 0.166, batch accuracy 0.900\n",
      "Epoch 1, Iteration 717, loss 0.124, batch accuracy 0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 718, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 719, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 720, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 721, loss 0.407, batch accuracy 0.900\n",
      "Epoch 1, Iteration 722, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 723, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 724, loss 0.071, batch accuracy 1.000\n",
      "Epoch 1, Iteration 725, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 726, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 727, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 728, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 729, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 730, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 731, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 732, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 733, loss 0.102, batch accuracy 0.900\n",
      "Epoch 1, Iteration 734, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 735, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 736, loss 0.093, batch accuracy 0.900\n",
      "Epoch 1, Iteration 737, loss 0.090, batch accuracy 0.900\n",
      "Epoch 1, Iteration 738, loss 0.659, batch accuracy 0.900\n",
      "Epoch 1, Iteration 739, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 740, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 741, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 742, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 743, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 744, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 745, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 746, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 747, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 748, loss 0.048, batch accuracy 1.000\n",
      "Epoch 1, Iteration 749, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 750, loss 0.392, batch accuracy 0.900\n",
      "Epoch 1, Iteration 751, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 752, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 753, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 754, loss 0.232, batch accuracy 0.900\n",
      "Epoch 1, Iteration 755, loss 0.050, batch accuracy 1.000\n",
      "Epoch 1, Iteration 756, loss 0.405, batch accuracy 0.900\n",
      "Epoch 1, Iteration 757, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 758, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 759, loss 0.106, batch accuracy 1.000\n",
      "Epoch 1, Iteration 760, loss 0.052, batch accuracy 1.000\n",
      "Epoch 1, Iteration 761, loss 0.324, batch accuracy 0.900\n",
      "Epoch 1, Iteration 762, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 763, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 764, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 765, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 766, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 767, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 768, loss 0.045, batch accuracy 1.000\n",
      "Epoch 1, Iteration 769, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 770, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 771, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 772, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 773, loss 0.365, batch accuracy 0.900\n",
      "Epoch 1, Iteration 774, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 775, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 776, loss 0.108, batch accuracy 0.900\n",
      "Epoch 1, Iteration 777, loss 0.086, batch accuracy 0.900\n",
      "Epoch 1, Iteration 778, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 779, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 780, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 781, loss 0.054, batch accuracy 1.000\n",
      "Epoch 1, Iteration 782, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 783, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 784, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 785, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 786, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 787, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 788, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 789, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 790, loss 0.389, batch accuracy 0.900\n",
      "Epoch 1, Iteration 791, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 792, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 793, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 794, loss 0.316, batch accuracy 0.900\n",
      "Epoch 1, Iteration 795, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 796, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 797, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 798, loss 0.266, batch accuracy 0.900\n",
      "Epoch 1, Iteration 799, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 800, loss 0.082, batch accuracy 1.000\n",
      "Epoch 1, Iteration 801, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 802, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 803, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 804, loss 0.058, batch accuracy 1.000\n",
      "Epoch 1, Iteration 805, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 806, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 807, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 808, loss 0.124, batch accuracy 0.900\n",
      "Epoch 1, Iteration 809, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 810, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 811, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 812, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 813, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 814, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 815, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 816, loss 0.347, batch accuracy 0.900\n",
      "Epoch 1, Iteration 817, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 818, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 819, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 820, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 821, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 822, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 823, loss 0.127, batch accuracy 0.900\n",
      "Epoch 1, Iteration 824, loss 0.113, batch accuracy 1.000\n",
      "Epoch 1, Iteration 825, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 826, loss 0.143, batch accuracy 0.900\n",
      "Epoch 1, Iteration 827, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 828, loss 0.086, batch accuracy 1.000\n",
      "Epoch 1, Iteration 829, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 830, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 831, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 832, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 833, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 834, loss 0.174, batch accuracy 0.900\n",
      "Epoch 1, Iteration 835, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 836, loss 0.254, batch accuracy 0.900\n",
      "Epoch 1, Iteration 837, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 838, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 839, loss 0.076, batch accuracy 0.900\n",
      "Epoch 1, Iteration 840, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 841, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 842, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 843, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 844, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 845, loss 0.273, batch accuracy 0.900\n",
      "Epoch 1, Iteration 846, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 847, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 848, loss 0.153, batch accuracy 0.900\n",
      "Epoch 1, Iteration 849, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 850, loss 0.111, batch accuracy 0.900\n",
      "Epoch 1, Iteration 851, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 852, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 853, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 854, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 855, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 856, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 857, loss 0.273, batch accuracy 0.900\n",
      "Epoch 1, Iteration 858, loss 0.042, batch accuracy 1.000\n",
      "Epoch 1, Iteration 859, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 860, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 861, loss 0.432, batch accuracy 0.900\n",
      "Epoch 1, Iteration 862, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 863, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 864, loss 0.149, batch accuracy 0.900\n",
      "Epoch 1, Iteration 865, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 866, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 867, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 868, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 869, loss 0.611, batch accuracy 0.900\n",
      "Epoch 1, Iteration 870, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 871, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 872, loss 0.359, batch accuracy 0.900\n",
      "Epoch 1, Iteration 873, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 874, loss 0.155, batch accuracy 0.900\n",
      "Epoch 1, Iteration 875, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 876, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 877, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 878, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 879, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 880, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 881, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 882, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 883, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 884, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 885, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 886, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 887, loss 0.166, batch accuracy 0.900\n",
      "Epoch 1, Iteration 888, loss 0.331, batch accuracy 0.900\n",
      "Epoch 1, Iteration 889, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 890, loss 0.342, batch accuracy 0.900\n",
      "Epoch 1, Iteration 891, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 892, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 893, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 894, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 895, loss 0.248, batch accuracy 0.900\n",
      "Epoch 1, Iteration 896, loss 0.299, batch accuracy 0.900\n",
      "Epoch 1, Iteration 897, loss 0.100, batch accuracy 0.900\n",
      "Epoch 1, Iteration 898, loss 0.038, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 899, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 900, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 901, loss 0.161, batch accuracy 0.900\n",
      "Epoch 1, Iteration 902, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 903, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 904, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 905, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 906, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 907, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 908, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 909, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 910, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 911, loss 0.224, batch accuracy 0.900\n",
      "Epoch 1, Iteration 912, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 913, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 914, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 915, loss 0.031, batch accuracy 1.000\n",
      "Epoch 1, Iteration 916, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 917, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 918, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 919, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 920, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 921, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 922, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 923, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 924, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 925, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 926, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 927, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 928, loss 0.206, batch accuracy 0.900\n",
      "Epoch 1, Iteration 929, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 930, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 931, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 932, loss 0.126, batch accuracy 0.900\n",
      "Epoch 1, Iteration 933, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 934, loss 0.646, batch accuracy 0.800\n",
      "Epoch 1, Iteration 935, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 936, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 937, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 938, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 939, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 940, loss 0.069, batch accuracy 1.000\n",
      "Epoch 1, Iteration 941, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 942, loss 0.240, batch accuracy 0.900\n",
      "Epoch 1, Iteration 943, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 944, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 945, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 946, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 947, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 948, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 949, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 950, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 951, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 952, loss 0.298, batch accuracy 0.900\n",
      "Epoch 1, Iteration 953, loss 0.404, batch accuracy 0.800\n",
      "Epoch 1, Iteration 954, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 955, loss 0.084, batch accuracy 0.900\n",
      "Epoch 1, Iteration 956, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 957, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 958, loss 0.229, batch accuracy 0.900\n",
      "Epoch 1, Iteration 959, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 960, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 961, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 962, loss 0.097, batch accuracy 1.000\n",
      "Epoch 1, Iteration 963, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 964, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 965, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 966, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 967, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 968, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 969, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 970, loss 0.112, batch accuracy 0.900\n",
      "Epoch 1, Iteration 971, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 972, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 973, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 974, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 975, loss 0.210, batch accuracy 0.900\n",
      "Epoch 1, Iteration 976, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 977, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 978, loss 0.146, batch accuracy 0.900\n",
      "Epoch 1, Iteration 979, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 980, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 981, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 982, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 983, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 984, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 985, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 986, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 987, loss 0.623, batch accuracy 0.900\n",
      "Epoch 1, Iteration 988, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 989, loss 0.148, batch accuracy 0.900\n",
      "Epoch 1, Iteration 990, loss 0.058, batch accuracy 1.000\n",
      "Epoch 1, Iteration 991, loss 0.057, batch accuracy 1.000\n",
      "Epoch 1, Iteration 992, loss 0.221, batch accuracy 0.900\n",
      "Epoch 1, Iteration 993, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 994, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 995, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 996, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 997, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 998, loss 0.073, batch accuracy 1.000\n",
      "Epoch 1, Iteration 999, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1000, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1001, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1002, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1003, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1004, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1005, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1006, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1007, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1008, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1009, loss 0.151, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1010, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1011, loss 0.126, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1012, loss 0.231, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1013, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1014, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1015, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1016, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1017, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1018, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1019, loss 0.058, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1020, loss 0.307, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1021, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1022, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1023, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1024, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1025, loss 0.063, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1026, loss 0.509, batch accuracy 0.700\n",
      "Epoch 1, Iteration 1027, loss 0.512, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1028, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1029, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1030, loss 0.042, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1031, loss 0.045, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1032, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1033, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1034, loss 0.052, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1035, loss 0.200, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1036, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1037, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1038, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1039, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1040, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1041, loss 0.038, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1042, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1043, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1044, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1045, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1046, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1047, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1048, loss 0.339, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1049, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1050, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1051, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1052, loss 0.182, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1053, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1054, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1055, loss 0.597, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1056, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1057, loss 0.049, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1058, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1059, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1060, loss 0.290, batch accuracy 0.800\n",
      "Epoch 1, Iteration 1061, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1062, loss 0.142, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1063, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1064, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1065, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1066, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1067, loss 0.283, batch accuracy 0.800\n",
      "Epoch 1, Iteration 1068, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1069, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1070, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1071, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1072, loss 0.101, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1073, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1074, loss 0.047, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1075, loss 0.056, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 1076, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1077, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1078, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1079, loss 0.622, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1080, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1081, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1082, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1083, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1084, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1085, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1086, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1087, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1088, loss 0.127, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1089, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1090, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1091, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1092, loss 0.141, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1093, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1094, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1095, loss 0.617, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1096, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1097, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1098, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1099, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1100, loss 0.244, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1101, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1102, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1103, loss 0.561, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1104, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1105, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1106, loss 0.092, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1107, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1108, loss 0.213, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1109, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1110, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1111, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1112, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1113, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1114, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1115, loss 0.170, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1116, loss 0.143, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1117, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1118, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1119, loss 0.072, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1120, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1121, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1122, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1123, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1124, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1125, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1126, loss 0.091, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1127, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1128, loss 0.237, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1129, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1130, loss 0.045, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1131, loss 0.404, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1132, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1133, loss 0.110, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1134, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1135, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1136, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1137, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1138, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1139, loss 0.079, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1140, loss 0.280, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1141, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1142, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1143, loss 0.227, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1144, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1145, loss 0.116, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1146, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1147, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1148, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1149, loss 0.095, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1150, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1151, loss 0.048, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1152, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1153, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1154, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1155, loss 0.067, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1156, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1157, loss 0.076, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1158, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1159, loss 0.059, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1160, loss 0.123, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1161, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1162, loss 0.038, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1163, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1164, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1165, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1166, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1167, loss 0.090, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1168, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1169, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1170, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1171, loss 0.146, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1172, loss 0.120, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1173, loss 0.049, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1174, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1175, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1176, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1177, loss 0.319, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1178, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1179, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1180, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1181, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1182, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1183, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1184, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1185, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1186, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1187, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1188, loss 0.059, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1189, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1190, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1191, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1192, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1193, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1194, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1195, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1196, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1197, loss 0.368, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1198, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1199, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1200, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1201, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1202, loss 0.044, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1203, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1204, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1205, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1206, loss 0.077, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1207, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1208, loss 0.071, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1209, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1210, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1211, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1212, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1213, loss 0.069, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1214, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1215, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1216, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1217, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1218, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1219, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1220, loss 0.116, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1221, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1222, loss 0.115, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1223, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1224, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1225, loss 0.068, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1226, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1227, loss 0.069, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1228, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1229, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1230, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1231, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1232, loss 0.149, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1233, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1234, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1235, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1236, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1237, loss 0.233, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1238, loss 0.031, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1239, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1240, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1241, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1242, loss 0.401, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1243, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1244, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1245, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1246, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1247, loss 0.193, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1248, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1249, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1250, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1251, loss 0.094, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1252, loss 0.066, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1253, loss 0.017, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 1254, loss 0.269, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1255, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1256, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1257, loss 0.114, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1258, loss 0.240, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1259, loss 0.094, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1260, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1261, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1262, loss 0.056, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1263, loss 0.052, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1264, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1265, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1266, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1267, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1268, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1269, loss 0.178, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1270, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1271, loss 0.229, batch accuracy 0.800\n",
      "Epoch 1, Iteration 1272, loss 0.151, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1273, loss 0.099, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1274, loss 0.059, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1275, loss 0.099, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1276, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1277, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1278, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1279, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1280, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1281, loss 0.436, batch accuracy 0.700\n",
      "Epoch 1, Iteration 1282, loss 0.517, batch accuracy 0.800\n",
      "Epoch 1, Iteration 1283, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1284, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1285, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1286, loss 0.072, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1287, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1288, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1289, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1290, loss 0.088, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1291, loss 0.150, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1292, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1293, loss 0.349, batch accuracy 0.800\n",
      "Epoch 1, Iteration 1294, loss 0.068, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1295, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1296, loss 0.185, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1297, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1298, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1299, loss 0.052, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1300, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1301, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1302, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1303, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1304, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1305, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1306, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1307, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1308, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1309, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1310, loss 0.195, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1311, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1312, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1313, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1314, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1315, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1316, loss 0.042, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1317, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1318, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1319, loss 0.045, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1320, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1321, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1322, loss 0.105, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1323, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1324, loss 0.219, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1325, loss 0.091, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1326, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1327, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1328, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1329, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1330, loss 0.066, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1331, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1332, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1333, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1334, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1335, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1336, loss 0.097, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1337, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1338, loss 0.050, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1339, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1340, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1341, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1342, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1343, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1344, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1345, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1346, loss 0.061, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1347, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1348, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1349, loss 0.411, batch accuracy 0.800\n",
      "Epoch 1, Iteration 1350, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1351, loss 0.102, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1352, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1353, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1354, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1355, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1356, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1357, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1358, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1359, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1360, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1361, loss 0.529, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1362, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1363, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1364, loss 0.058, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1365, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1366, loss 0.170, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1367, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1368, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1369, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1370, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1371, loss 0.286, batch accuracy 0.800\n",
      "Epoch 1, Iteration 1372, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1373, loss 0.300, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1374, loss 0.295, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1375, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1376, loss 0.633, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1377, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1378, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1379, loss 0.090, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1380, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1381, loss 0.370, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1382, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1383, loss 0.156, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1384, loss 0.065, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1385, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1386, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1387, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1388, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1389, loss 0.053, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1390, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1391, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1392, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1393, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1394, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1395, loss 0.156, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1396, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1397, loss 0.705, batch accuracy 0.800\n",
      "Epoch 1, Iteration 1398, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1399, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1400, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1401, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1402, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1403, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1404, loss 0.561, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1405, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1406, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1407, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1408, loss 0.060, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1409, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1410, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1411, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1412, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1413, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1414, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1415, loss 0.374, batch accuracy 0.800\n",
      "Epoch 1, Iteration 1416, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1417, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1418, loss 0.841, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1419, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1420, loss 0.045, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1421, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1422, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1423, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1424, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1425, loss 0.002, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 1426, loss 0.142, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1427, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1428, loss 0.151, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1429, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1430, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1431, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1432, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1433, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1434, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1435, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1436, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1437, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1438, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1439, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1440, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1441, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1442, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1443, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1444, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1445, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1446, loss 0.073, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1447, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1448, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1449, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1450, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1451, loss 0.400, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1452, loss 0.393, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1453, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1454, loss 0.205, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1455, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1456, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1457, loss 0.346, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1458, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1459, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1460, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1461, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1462, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1463, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1464, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1465, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1466, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1467, loss 0.095, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1468, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1469, loss 0.419, batch accuracy 0.800\n",
      "Epoch 1, Iteration 1470, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1471, loss 0.054, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1472, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1473, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1474, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1475, loss 0.086, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1476, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1477, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1478, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1479, loss 0.069, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1480, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1481, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1482, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1483, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1484, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1485, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1486, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1487, loss 0.323, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1488, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1489, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1490, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1491, loss 0.042, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1492, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1493, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1494, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1495, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1496, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1497, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1498, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1499, loss 0.161, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1500, loss 0.132, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1501, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1502, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1503, loss 0.064, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1504, loss 0.079, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1505, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1506, loss 0.112, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1507, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1508, loss 0.322, batch accuracy 0.800\n",
      "Epoch 1, Iteration 1509, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1510, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1511, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1512, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1513, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1514, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1515, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1516, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1517, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1518, loss 0.151, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1519, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1520, loss 0.360, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1521, loss 0.423, batch accuracy 0.800\n",
      "Epoch 1, Iteration 1522, loss 0.162, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1523, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1524, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1525, loss 0.589, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1526, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1527, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1528, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1529, loss 0.205, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1530, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1531, loss 0.074, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1532, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1533, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1534, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1535, loss 0.073, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1536, loss 0.071, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1537, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1538, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1539, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1540, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1541, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1542, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1543, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1544, loss 0.089, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1545, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1546, loss 0.392, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1547, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1548, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1549, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1550, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1551, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1552, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1553, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1554, loss 0.093, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1555, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1556, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1557, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1558, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1559, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1560, loss 0.733, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1561, loss 0.310, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1562, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1563, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1564, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1565, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1566, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1567, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1568, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1569, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1570, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1571, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1572, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1573, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1574, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1575, loss 0.070, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1576, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1577, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1578, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1579, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1580, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1581, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1582, loss 0.189, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1583, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1584, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1585, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1586, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1587, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1588, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1589, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1590, loss 0.189, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1591, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1592, loss 0.028, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 1593, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1594, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1595, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1596, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1597, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1598, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1599, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1600, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1601, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1602, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1603, loss 0.063, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1604, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1605, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1606, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1607, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1608, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1609, loss 0.434, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1610, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1611, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1612, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1613, loss 0.225, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1614, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1615, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1616, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1617, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1618, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1619, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1620, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1621, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1622, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1623, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1624, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1625, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1626, loss 0.117, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1627, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1628, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1629, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1630, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1631, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1632, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1633, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1634, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1635, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1636, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1637, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1638, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1639, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1640, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1641, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1642, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1643, loss 0.696, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1644, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1645, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1646, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1647, loss 1.230, batch accuracy 0.800\n",
      "Epoch 1, Iteration 1648, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1649, loss 0.365, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1650, loss 0.392, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1651, loss 0.288, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1652, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1653, loss 0.470, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1654, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1655, loss 0.045, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1656, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1657, loss 0.452, batch accuracy 0.800\n",
      "Epoch 1, Iteration 1658, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1659, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1660, loss 0.167, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1661, loss 0.346, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1662, loss 0.074, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1663, loss 0.060, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1664, loss 0.555, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1665, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1666, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1667, loss 0.855, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1668, loss 0.121, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1669, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1670, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1671, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1672, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1673, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1674, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1675, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1676, loss 0.304, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1677, loss 0.211, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1678, loss 0.139, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1679, loss 0.124, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1680, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1681, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1682, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1683, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1684, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1685, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1686, loss 0.308, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1687, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1688, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1689, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1690, loss 0.049, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1691, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1692, loss 0.229, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1693, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1694, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1695, loss 0.132, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1696, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1697, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1698, loss 0.284, batch accuracy 0.800\n",
      "Epoch 1, Iteration 1699, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1700, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1701, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1702, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1703, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1704, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1705, loss 0.066, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1706, loss 0.201, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1707, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1708, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1709, loss 0.060, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1710, loss 0.102, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1711, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1712, loss 0.061, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1713, loss 0.177, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1714, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1715, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1716, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1717, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1718, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1719, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1720, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1721, loss 0.358, batch accuracy 0.800\n",
      "Epoch 1, Iteration 1722, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1723, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1724, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1725, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1726, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1727, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1728, loss 0.163, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1729, loss 0.582, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1730, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1731, loss 0.083, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1732, loss 0.054, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1733, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1734, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1735, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1736, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1737, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1738, loss 0.155, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1739, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1740, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1741, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1742, loss 1.537, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1743, loss 0.042, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1744, loss 0.091, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1745, loss 0.511, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1746, loss 0.344, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1747, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1748, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1749, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1750, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1751, loss 0.319, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1752, loss 0.070, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1753, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1754, loss 0.108, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1755, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1756, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1757, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1758, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1759, loss 0.060, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1760, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1761, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1762, loss 0.051, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 1763, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1764, loss 0.179, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1765, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1766, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1767, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1768, loss 0.099, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1769, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1770, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1771, loss 0.210, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1772, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1773, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1774, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1775, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1776, loss 0.106, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1777, loss 0.052, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1778, loss 0.111, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1779, loss 0.089, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1780, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1781, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1782, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1783, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1784, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1785, loss 0.127, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1786, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1787, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1788, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1789, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1790, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1791, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1792, loss 0.095, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1793, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1794, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1795, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1796, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1797, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1798, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1799, loss 0.184, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1800, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1801, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1802, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1803, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1804, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1805, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1806, loss 0.057, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1807, loss 0.122, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1808, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1809, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1810, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1811, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1812, loss 0.031, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1813, loss 0.057, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1814, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1815, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1816, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1817, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1818, loss 0.094, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1819, loss 0.282, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1820, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1821, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1822, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1823, loss 0.285, batch accuracy 0.800\n",
      "Epoch 1, Iteration 1824, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1825, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1826, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1827, loss 0.207, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1828, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1829, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1830, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1831, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1832, loss 0.058, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1833, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1834, loss 0.658, batch accuracy 0.800\n",
      "Epoch 1, Iteration 1835, loss 0.087, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1836, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1837, loss 0.167, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1838, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1839, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1840, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1841, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1842, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1843, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1844, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1845, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1846, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1847, loss 0.136, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1848, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1849, loss 0.111, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1850, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1851, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1852, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1853, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1854, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1855, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1856, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1857, loss 0.031, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1858, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1859, loss 0.070, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1860, loss 0.187, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1861, loss 0.099, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1862, loss 0.050, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1863, loss 0.348, batch accuracy 0.800\n",
      "Epoch 1, Iteration 1864, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1865, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1866, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1867, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1868, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1869, loss 0.092, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1870, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1871, loss 0.058, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1872, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1873, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1874, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1875, loss 0.172, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1876, loss 0.337, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1877, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1878, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1879, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1880, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1881, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1882, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1883, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1884, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1885, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1886, loss 0.084, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1887, loss 0.042, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1888, loss 0.094, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1889, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1890, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1891, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1892, loss 0.172, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1893, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1894, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1895, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1896, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1897, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1898, loss 0.203, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1899, loss 0.083, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1900, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1901, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1902, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1903, loss 0.133, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1904, loss 0.151, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1905, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1906, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1907, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1908, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1909, loss 0.539, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1910, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1911, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1912, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1913, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1914, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1915, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1916, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1917, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1918, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1919, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1920, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1921, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1922, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1923, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1924, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1925, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1926, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1927, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1928, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1929, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1930, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1931, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1932, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1933, loss 0.118, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1934, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1935, loss 0.071, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1936, loss 0.136, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1937, loss 0.002, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 1938, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1939, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1940, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1941, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1942, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1943, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1944, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1945, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1946, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1947, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1948, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1949, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1950, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1951, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1952, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1953, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1954, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1955, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1956, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1957, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1958, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1959, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1960, loss 0.224, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1961, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1962, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1963, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1964, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1965, loss 0.213, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1966, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1967, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1968, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1969, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1970, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1971, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1972, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1973, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1974, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1975, loss 0.836, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1976, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1977, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1978, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1979, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1980, loss 0.191, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1981, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1982, loss 0.049, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1983, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1984, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1985, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1986, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1987, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1988, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1989, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1990, loss 0.129, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1991, loss 0.116, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1992, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1993, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1994, loss 0.135, batch accuracy 0.900\n",
      "Epoch 1, Iteration 1995, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1996, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1997, loss 0.066, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1998, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 1999, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2000, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2001, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2002, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2003, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2004, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2005, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2006, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2007, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2008, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2009, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2010, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2011, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2012, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2013, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2014, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2015, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2016, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2017, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2018, loss 0.055, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2019, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2020, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2021, loss 0.411, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2022, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2023, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2024, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2025, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2026, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2027, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2028, loss 0.692, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2029, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2030, loss 0.236, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2031, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2032, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2033, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2034, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2035, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2036, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2037, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2038, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2039, loss 0.054, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2040, loss 0.215, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2041, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2042, loss 0.344, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2043, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2044, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2045, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2046, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2047, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2048, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2049, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2050, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2051, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2052, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2053, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2054, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2055, loss 0.170, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2056, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2057, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2058, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2059, loss 0.143, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2060, loss 0.105, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2061, loss 0.071, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2062, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2063, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2064, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2065, loss 0.051, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2066, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2067, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2068, loss 0.038, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2069, loss 0.072, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2070, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2071, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2072, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2073, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2074, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2075, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2076, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2077, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2078, loss 0.153, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2079, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2080, loss 0.126, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2081, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2082, loss 0.246, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2083, loss 0.386, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2084, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2085, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2086, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2087, loss 0.122, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2088, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2089, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2090, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2091, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2092, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2093, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2094, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2095, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2096, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2097, loss 0.096, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2098, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2099, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2100, loss 0.121, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2101, loss 0.446, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2102, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2103, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2104, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2105, loss 0.083, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2106, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2107, loss 0.100, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2108, loss 0.169, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2109, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2110, loss 0.513, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2111, loss 0.648, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2112, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2113, loss 0.116, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2114, loss 0.009, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 2115, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2116, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2117, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2118, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2119, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2120, loss 0.495, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2121, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2122, loss 0.057, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2123, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2124, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2125, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2126, loss 0.795, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2127, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2128, loss 0.057, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2129, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2130, loss 1.184, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2131, loss 0.042, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2132, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2133, loss 0.203, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2134, loss 0.059, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2135, loss 0.084, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2136, loss 0.166, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2137, loss 0.069, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2138, loss 0.117, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2139, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2140, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2141, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2142, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2143, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2144, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2145, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2146, loss 0.112, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2147, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2148, loss 0.838, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2149, loss 0.089, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2150, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2151, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2152, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2153, loss 0.093, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2154, loss 0.055, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2155, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2156, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2157, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2158, loss 0.066, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2159, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2160, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2161, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2162, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2163, loss 0.084, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2164, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2165, loss 0.369, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2166, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2167, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2168, loss 0.176, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2169, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2170, loss 0.068, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2171, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2172, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2173, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2174, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2175, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2176, loss 0.622, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2177, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2178, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2179, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2180, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2181, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2182, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2183, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2184, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2185, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2186, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2187, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2188, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2189, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2190, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2191, loss 0.309, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2192, loss 0.180, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2193, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2194, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2195, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2196, loss 0.084, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2197, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2198, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2199, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2200, loss 0.539, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2201, loss 1.140, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2202, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2203, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2204, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2205, loss 0.099, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2206, loss 0.049, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2207, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2208, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2209, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2210, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2211, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2212, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2213, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2214, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2215, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2216, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2217, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2218, loss 0.105, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2219, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2220, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2221, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2222, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2223, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2224, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2225, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2226, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2227, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2228, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2229, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2230, loss 0.072, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2231, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2232, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2233, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2234, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2235, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2236, loss 0.128, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2237, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2238, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2239, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2240, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2241, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2242, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2243, loss 0.152, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2244, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2245, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2246, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2247, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2248, loss 0.070, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2249, loss 0.045, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2250, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2251, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2252, loss 0.075, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2253, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2254, loss 0.165, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2255, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2256, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2257, loss 0.303, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2258, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2259, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2260, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2261, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2262, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2263, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2264, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2265, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2266, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2267, loss 0.134, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2268, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2269, loss 0.430, batch accuracy 0.700\n",
      "Epoch 1, Iteration 2270, loss 0.120, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2271, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2272, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2273, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2274, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2275, loss 0.074, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2276, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2277, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2278, loss 0.064, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2279, loss 0.104, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2280, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2281, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2282, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2283, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2284, loss 0.133, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2285, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2286, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2287, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2288, loss 0.288, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2289, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2290, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2291, loss 0.005, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 2292, loss 0.208, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2293, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2294, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2295, loss 0.247, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2296, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2297, loss 0.042, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2298, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2299, loss 0.725, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2300, loss 0.155, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2301, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2302, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2303, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2304, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2305, loss 0.325, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2306, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2307, loss 0.170, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2308, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2309, loss 0.150, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2310, loss 0.146, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2311, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2312, loss 0.056, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2313, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2314, loss 0.165, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2315, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2316, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2317, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2318, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2319, loss 0.095, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2320, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2321, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2322, loss 0.084, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2323, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2324, loss 0.124, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2325, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2326, loss 0.072, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2327, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2328, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2329, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2330, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2331, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2332, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2333, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2334, loss 0.060, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2335, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2336, loss 0.083, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2337, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2338, loss 0.234, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2339, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2340, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2341, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2342, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2343, loss 0.498, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2344, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2345, loss 0.158, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2346, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2347, loss 0.356, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2348, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2349, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2350, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2351, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2352, loss 0.253, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2353, loss 0.706, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2354, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2355, loss 0.159, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2356, loss 0.065, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2357, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2358, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2359, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2360, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2361, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2362, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2363, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2364, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2365, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2366, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2367, loss 0.763, batch accuracy 0.700\n",
      "Epoch 1, Iteration 2368, loss 0.158, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2369, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2370, loss 0.118, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2371, loss 0.047, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2372, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2373, loss 0.069, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2374, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2375, loss 0.290, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2376, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2377, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2378, loss 0.128, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2379, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2380, loss 0.059, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2381, loss 0.048, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2382, loss 0.154, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2383, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2384, loss 0.246, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2385, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2386, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2387, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2388, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2389, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2390, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2391, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2392, loss 0.145, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2393, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2394, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2395, loss 0.178, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2396, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2397, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2398, loss 0.605, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2399, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2400, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2401, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2402, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2403, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2404, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2405, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2406, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2407, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2408, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2409, loss 0.877, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2410, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2411, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2412, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2413, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2414, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2415, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2416, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2417, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2418, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2419, loss 0.216, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2420, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2421, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2422, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2423, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2424, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2425, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2426, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2427, loss 0.051, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2428, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2429, loss 0.463, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2430, loss 0.042, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2431, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2432, loss 0.105, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2433, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2434, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2435, loss 0.061, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2436, loss 0.057, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2437, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2438, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2439, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2440, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2441, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2442, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2443, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2444, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2445, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2446, loss 0.139, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2447, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2448, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2449, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2450, loss 0.093, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2451, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2452, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2453, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2454, loss 0.129, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2455, loss 0.098, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2456, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2457, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2458, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2459, loss 0.049, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2460, loss 0.058, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2461, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2462, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2463, loss 0.071, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2464, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2465, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2466, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2467, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2468, loss 0.398, batch accuracy 0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 2469, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2470, loss 0.099, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2471, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2472, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2473, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2474, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2475, loss 0.391, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2476, loss 0.229, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2477, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2478, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2479, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2480, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2481, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2482, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2483, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2484, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2485, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2486, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2487, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2488, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2489, loss 0.047, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2490, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2491, loss 0.900, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2492, loss 0.054, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2493, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2494, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2495, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2496, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2497, loss 0.289, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2498, loss 0.148, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2499, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2500, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2501, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2502, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2503, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2504, loss 0.278, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2505, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2506, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2507, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2508, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2509, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2510, loss 0.259, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2511, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2512, loss 0.031, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2513, loss 1.619, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2514, loss 0.044, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2515, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2516, loss 0.112, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2517, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2518, loss 0.220, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2519, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2520, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2521, loss 0.107, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2522, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2523, loss 0.161, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2524, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2525, loss 0.089, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2526, loss 0.170, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2527, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2528, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2529, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2530, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2531, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2532, loss 0.163, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2533, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2534, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2535, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2536, loss 0.112, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2537, loss 0.113, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2538, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2539, loss 0.109, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2540, loss 0.364, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2541, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2542, loss 0.343, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2543, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2544, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2545, loss 0.048, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2546, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2547, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2548, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2549, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2550, loss 0.126, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2551, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2552, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2553, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2554, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2555, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2556, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2557, loss 0.202, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2558, loss 1.328, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2559, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2560, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2561, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2562, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2563, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2564, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2565, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2566, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2567, loss 0.377, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2568, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2569, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2570, loss 0.059, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2571, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2572, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2573, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2574, loss 0.329, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2575, loss 0.145, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2576, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2577, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2578, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2579, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2580, loss 0.071, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2581, loss 0.102, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2582, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2583, loss 0.054, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2584, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2585, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2586, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2587, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2588, loss 0.245, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2589, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2590, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2591, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2592, loss 0.100, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2593, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2594, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2595, loss 0.263, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2596, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2597, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2598, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2599, loss 0.081, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2600, loss 0.128, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2601, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2602, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2603, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2604, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2605, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2606, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2607, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2608, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2609, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2610, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2611, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2612, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2613, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2614, loss 0.051, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2615, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2616, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2617, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2618, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2619, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2620, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2621, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2622, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2623, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2624, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2625, loss 0.097, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2626, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2627, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2628, loss 0.058, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2629, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2630, loss 0.237, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2631, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2632, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2633, loss 0.150, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2634, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2635, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2636, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2637, loss 0.063, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2638, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2639, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2640, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2641, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2642, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2643, loss 0.047, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2644, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2645, loss 0.159, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2646, loss 0.100, batch accuracy 0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 2647, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2648, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2649, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2650, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2651, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2652, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2653, loss 0.042, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2654, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2655, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2656, loss 0.095, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2657, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2658, loss 0.216, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2659, loss 0.062, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2660, loss 0.092, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2661, loss 0.071, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2662, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2663, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2664, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2665, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2666, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2667, loss 0.071, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2668, loss 0.038, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2669, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2670, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2671, loss 0.387, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2672, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2673, loss 0.116, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2674, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2675, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2676, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2677, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2678, loss 0.126, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2679, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2680, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2681, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2682, loss 0.052, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2683, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2684, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2685, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2686, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2687, loss 0.038, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2688, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2689, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2690, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2691, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2692, loss 0.312, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2693, loss 0.100, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2694, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2695, loss 0.045, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2696, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2697, loss 0.122, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2698, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2699, loss 0.364, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2700, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2701, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2702, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2703, loss 0.075, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2704, loss 0.294, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2705, loss 0.072, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2706, loss 0.047, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2707, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2708, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2709, loss 1.373, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2710, loss 0.237, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2711, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2712, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2713, loss 0.273, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2714, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2715, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2716, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2717, loss 0.048, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2718, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2719, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2720, loss 0.107, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2721, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2722, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2723, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2724, loss 0.057, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2725, loss 0.211, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2726, loss 0.138, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2727, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2728, loss 0.031, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2729, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2730, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2731, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2732, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2733, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2734, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2735, loss 0.058, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2736, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2737, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2738, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2739, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2740, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2741, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2742, loss 0.413, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2743, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2744, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2745, loss 0.446, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2746, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2747, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2748, loss 0.120, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2749, loss 0.154, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2750, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2751, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2752, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2753, loss 0.080, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2754, loss 0.098, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2755, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2756, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2757, loss 0.117, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2758, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2759, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2760, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2761, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2762, loss 0.213, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2763, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2764, loss 0.063, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2765, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2766, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2767, loss 0.112, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2768, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2769, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2770, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2771, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2772, loss 0.045, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2773, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2774, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2775, loss 0.653, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2776, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2777, loss 0.166, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2778, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2779, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2780, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2781, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2782, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2783, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2784, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2785, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2786, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2787, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2788, loss 0.057, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2789, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2790, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2791, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2792, loss 0.045, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2793, loss 0.080, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2794, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2795, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2796, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2797, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2798, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2799, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2800, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2801, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2802, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2803, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2804, loss 0.320, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2805, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2806, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2807, loss 0.368, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2808, loss 0.044, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2809, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2810, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2811, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2812, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2813, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2814, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2815, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2816, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2817, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2818, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2819, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2820, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2821, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2822, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2823, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2824, loss 0.278, batch accuracy 0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 2825, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2826, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2827, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2828, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2829, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2830, loss 0.092, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2831, loss 0.038, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2832, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2833, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2834, loss 0.258, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2835, loss 0.166, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2836, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2837, loss 0.054, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2838, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2839, loss 0.134, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2840, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2841, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2842, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2843, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2844, loss 0.313, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2845, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2846, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2847, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2848, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2849, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2850, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2851, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2852, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2853, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2854, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2855, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2856, loss 0.069, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2857, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2858, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2859, loss 0.124, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2860, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2861, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2862, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2863, loss 0.382, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2864, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2865, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2866, loss 0.105, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2867, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2868, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2869, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2870, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2871, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2872, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2873, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2874, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2875, loss 0.146, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2876, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2877, loss 0.088, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2878, loss 0.102, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2879, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2880, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2881, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2882, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2883, loss 0.107, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2884, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2885, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2886, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2887, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2888, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2889, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2890, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2891, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2892, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2893, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2894, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2895, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2896, loss 0.507, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2897, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2898, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2899, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2900, loss 0.422, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2901, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2902, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2903, loss 0.069, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2904, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2905, loss 0.077, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2906, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2907, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2908, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2909, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2910, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2911, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2912, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2913, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2914, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2915, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2916, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2917, loss 1.109, batch accuracy 0.800\n",
      "Epoch 1, Iteration 2918, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2919, loss 0.134, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2920, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2921, loss 0.153, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2922, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2923, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2924, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2925, loss 0.052, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2926, loss 0.051, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2927, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2928, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2929, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2930, loss 0.327, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2931, loss 0.058, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2932, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2933, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2934, loss 0.071, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2935, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2936, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2937, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2938, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2939, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2940, loss 0.239, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2941, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2942, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2943, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2944, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2945, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2946, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2947, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2948, loss 0.104, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2949, loss 0.269, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2950, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2951, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2952, loss 0.092, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2953, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2954, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2955, loss 0.052, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2956, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2957, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2958, loss 0.136, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2959, loss 0.054, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2960, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2961, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2962, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2963, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2964, loss 0.148, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2965, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2966, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2967, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2968, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2969, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2970, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2971, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2972, loss 0.053, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2973, loss 0.068, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2974, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2975, loss 0.403, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2976, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2977, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2978, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2979, loss 0.122, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2980, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2981, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2982, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2983, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2984, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2985, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2986, loss 0.348, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2987, loss 0.924, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2988, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2989, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2990, loss 0.089, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2991, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2992, loss 0.056, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2993, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2994, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2995, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2996, loss 0.225, batch accuracy 0.900\n",
      "Epoch 1, Iteration 2997, loss 0.029, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 2998, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 2999, loss 0.061, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3000, loss 0.088, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3001, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3002, loss 0.168, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3003, loss 0.070, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3004, loss 0.055, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3005, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3006, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3007, loss 0.478, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3008, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3009, loss 0.190, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3010, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3011, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3012, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3013, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3014, loss 0.536, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3015, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3016, loss 0.164, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3017, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3018, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3019, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3020, loss 0.119, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3021, loss 0.058, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3022, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3023, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3024, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3025, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3026, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3027, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3028, loss 0.650, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3029, loss 0.078, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3030, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3031, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3032, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3033, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3034, loss 0.086, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3035, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3036, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3037, loss 0.064, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3038, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3039, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3040, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3041, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3042, loss 0.058, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3043, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3044, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3045, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3046, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3047, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3048, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3049, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3050, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3051, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3052, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3053, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3054, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3055, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3056, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3057, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3058, loss 0.031, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3059, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3060, loss 0.140, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3061, loss 0.057, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3062, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3063, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3064, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3065, loss 0.065, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3066, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3067, loss 0.119, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3068, loss 0.038, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3069, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3070, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3071, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3072, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3073, loss 0.243, batch accuracy 0.800\n",
      "Epoch 1, Iteration 3074, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3075, loss 0.081, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3076, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3077, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3078, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3079, loss 0.088, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3080, loss 0.261, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3081, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3082, loss 0.163, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3083, loss 0.060, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3084, loss 0.121, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3085, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3086, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3087, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3088, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3089, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3090, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3091, loss 0.051, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3092, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3093, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3094, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3095, loss 0.054, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3096, loss 0.233, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3097, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3098, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3099, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3100, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3101, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3102, loss 0.138, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3103, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3104, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3105, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3106, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3107, loss 0.326, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3108, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3109, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3110, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3111, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3112, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3113, loss 0.195, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3114, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3115, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3116, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3117, loss 0.593, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3118, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3119, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3120, loss 0.063, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3121, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3122, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3123, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3124, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3125, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3126, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3127, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3128, loss 0.183, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3129, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3130, loss 0.064, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3131, loss 0.110, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3132, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3133, loss 0.080, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3134, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3135, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3136, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3137, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3138, loss 0.289, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3139, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3140, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3141, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3142, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3143, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3144, loss 0.084, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3145, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3146, loss 0.453, batch accuracy 0.800\n",
      "Epoch 1, Iteration 3147, loss 0.038, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3148, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3149, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3150, loss 0.038, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3151, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3152, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3153, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3154, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3155, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3156, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3157, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3158, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3159, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3160, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3161, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3162, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3163, loss 0.078, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3164, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3165, loss 0.150, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3166, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3167, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3168, loss 0.230, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3169, loss 0.331, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3170, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3171, loss 0.051, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3172, loss 0.085, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 3173, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3174, loss 0.469, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3175, loss 0.189, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3176, loss 0.065, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3177, loss 0.060, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3178, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3179, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3180, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3181, loss 0.357, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3182, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3183, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3184, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3185, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3186, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3187, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3188, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3189, loss 0.128, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3190, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3191, loss 0.050, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3192, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3193, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3194, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3195, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3196, loss 0.311, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3197, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3198, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3199, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3200, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3201, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3202, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3203, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3204, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3205, loss 0.147, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3206, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3207, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3208, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3209, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3210, loss 0.254, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3211, loss 0.062, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3212, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3213, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3214, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3215, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3216, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3217, loss 0.085, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3218, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3219, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3220, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3221, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3222, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3223, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3224, loss 0.220, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3225, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3226, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3227, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3228, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3229, loss 0.177, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3230, loss 0.498, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3231, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3232, loss 0.389, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3233, loss 0.076, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3234, loss 0.124, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3235, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3236, loss 0.123, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3237, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3238, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3239, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3240, loss 0.164, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3241, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3242, loss 0.125, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3243, loss 0.567, batch accuracy 0.800\n",
      "Epoch 1, Iteration 3244, loss 0.084, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3245, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3246, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3247, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3248, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3249, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3250, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3251, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3252, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3253, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3254, loss 0.378, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3255, loss 0.390, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3256, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3257, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3258, loss 0.126, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3259, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3260, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3261, loss 0.828, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3262, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3263, loss 0.095, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3264, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3265, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3266, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3267, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3268, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3269, loss 0.076, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3270, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3271, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3272, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3273, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3274, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3275, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3276, loss 0.173, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3277, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3278, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3279, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3280, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3281, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3282, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3283, loss 0.069, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3284, loss 0.126, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3285, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3286, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3287, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3288, loss 0.056, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3289, loss 0.140, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3290, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3291, loss 0.811, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3292, loss 0.048, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3293, loss 0.047, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3294, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3295, loss 0.585, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3296, loss 0.171, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3297, loss 0.048, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3298, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3299, loss 0.194, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3300, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3301, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3302, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3303, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3304, loss 0.132, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3305, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3306, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3307, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3308, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3309, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3310, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3311, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3312, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3313, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3314, loss 0.150, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3315, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3316, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3317, loss 0.235, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3318, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3319, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3320, loss 0.253, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3321, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3322, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3323, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3324, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3325, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3326, loss 0.177, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3327, loss 0.165, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3328, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3329, loss 0.144, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3330, loss 0.381, batch accuracy 0.800\n",
      "Epoch 1, Iteration 3331, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3332, loss 0.164, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3333, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3334, loss 0.221, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3335, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3336, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3337, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3338, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3339, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3340, loss 0.215, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3341, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3342, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3343, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3344, loss 0.007, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 3345, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3346, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3347, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3348, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3349, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3350, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3351, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3352, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3353, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3354, loss 0.060, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3355, loss 0.050, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3356, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3357, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3358, loss 0.207, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3359, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3360, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3361, loss 0.060, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3362, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3363, loss 0.050, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3364, loss 0.038, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3365, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3366, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3367, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3368, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3369, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3370, loss 0.320, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3371, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3372, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3373, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3374, loss 0.135, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3375, loss 0.151, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3376, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3377, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3378, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3379, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3380, loss 0.285, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3381, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3382, loss 0.134, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3383, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3384, loss 0.088, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3385, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3386, loss 0.363, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3387, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3388, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3389, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3390, loss 0.141, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3391, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3392, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3393, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3394, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3395, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3396, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3397, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3398, loss 0.074, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3399, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3400, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3401, loss 0.061, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3402, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3403, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3404, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3405, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3406, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3407, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3408, loss 0.667, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3409, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3410, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3411, loss 0.066, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3412, loss 0.186, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3413, loss 0.064, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3414, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3415, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3416, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3417, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3418, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3419, loss 0.087, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3420, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3421, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3422, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3423, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3424, loss 0.310, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3425, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3426, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3427, loss 0.147, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3428, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3429, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3430, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3431, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3432, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3433, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3434, loss 0.071, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3435, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3436, loss 0.717, batch accuracy 0.800\n",
      "Epoch 1, Iteration 3437, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3438, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3439, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3440, loss 0.169, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3441, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3442, loss 0.517, batch accuracy 0.800\n",
      "Epoch 1, Iteration 3443, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3444, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3445, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3446, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3447, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3448, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3449, loss 0.118, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3450, loss 0.335, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3451, loss 0.089, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3452, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3453, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3454, loss 0.173, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3455, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3456, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3457, loss 0.074, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3458, loss 0.083, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3459, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3460, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3461, loss 0.237, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3462, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3463, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3464, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3465, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3466, loss 0.082, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3467, loss 0.088, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3468, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3469, loss 1.294, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3470, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3471, loss 0.094, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3472, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3473, loss 0.052, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3474, loss 0.053, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3475, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3476, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3477, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3478, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3479, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3480, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3481, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3482, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3483, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3484, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3485, loss 0.626, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3486, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3487, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3488, loss 0.064, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3489, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3490, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3491, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3492, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3493, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3494, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3495, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3496, loss 0.232, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3497, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3498, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3499, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3500, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3501, loss 0.496, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3502, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3503, loss 0.103, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3504, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3505, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3506, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3507, loss 1.300, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3508, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3509, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3510, loss 0.332, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3511, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3512, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3513, loss 0.261, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3514, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3515, loss 0.075, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3516, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3517, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3518, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3519, loss 0.003, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 3520, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3521, loss 0.062, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3522, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3523, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3524, loss 0.171, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3525, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3526, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3527, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3528, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3529, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3530, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3531, loss 0.137, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3532, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3533, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3534, loss 0.059, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3535, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3536, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3537, loss 0.225, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3538, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3539, loss 0.126, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3540, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3541, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3542, loss 0.053, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3543, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3544, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3545, loss 0.989, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3546, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3547, loss 0.031, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3548, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3549, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3550, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3551, loss 0.107, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3552, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3553, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3554, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3555, loss 0.061, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3556, loss 0.271, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3557, loss 0.795, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3558, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3559, loss 0.132, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3560, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3561, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3562, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3563, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3564, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3565, loss 0.082, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3566, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3567, loss 0.133, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3568, loss 0.156, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3569, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3570, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3571, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3572, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3573, loss 0.121, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3574, loss 0.093, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3575, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3576, loss 0.234, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3577, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3578, loss 0.050, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3579, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3580, loss 0.552, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3581, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3582, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3583, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3584, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3585, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3586, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3587, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3588, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3589, loss 0.631, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3590, loss 0.265, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3591, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3592, loss 0.084, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3593, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3594, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3595, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3596, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3597, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3598, loss 0.506, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3599, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3600, loss 0.117, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3601, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3602, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3603, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3604, loss 0.601, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3605, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3606, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3607, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3608, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3609, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3610, loss 0.250, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3611, loss 0.291, batch accuracy 0.800\n",
      "Epoch 1, Iteration 3612, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3613, loss 0.044, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3614, loss 0.271, batch accuracy 0.800\n",
      "Epoch 1, Iteration 3615, loss 0.410, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3616, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3617, loss 0.127, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3618, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3619, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3620, loss 0.188, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3621, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3622, loss 0.129, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3623, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3624, loss 0.128, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3625, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3626, loss 0.051, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3627, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3628, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3629, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3630, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3631, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3632, loss 0.054, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3633, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3634, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3635, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3636, loss 0.363, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3637, loss 0.400, batch accuracy 0.800\n",
      "Epoch 1, Iteration 3638, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3639, loss 0.082, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3640, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3641, loss 0.492, batch accuracy 0.800\n",
      "Epoch 1, Iteration 3642, loss 0.074, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3643, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3644, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3645, loss 0.038, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3646, loss 0.446, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3647, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3648, loss 0.068, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3649, loss 0.047, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3650, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3651, loss 0.297, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3652, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3653, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3654, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3655, loss 0.139, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3656, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3657, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3658, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3659, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3660, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3661, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3662, loss 0.066, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3663, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3664, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3665, loss 0.092, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3666, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3667, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3668, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3669, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3670, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3671, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3672, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3673, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3674, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3675, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3676, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3677, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3678, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3679, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3680, loss 0.060, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3681, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3682, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3683, loss 0.065, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3684, loss 0.001, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 3685, loss 0.126, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3686, loss 0.048, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3687, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3688, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3689, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3690, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3691, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3692, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3693, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3694, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3695, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3696, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3697, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3698, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3699, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3700, loss 0.205, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3701, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3702, loss 0.091, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3703, loss 0.155, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3704, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3705, loss 0.178, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3706, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3707, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3708, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3709, loss 0.049, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3710, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3711, loss 0.209, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3712, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3713, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3714, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3715, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3716, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3717, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3718, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3719, loss 0.248, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3720, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3721, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3722, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3723, loss 0.402, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3724, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3725, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3726, loss 0.520, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3727, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3728, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3729, loss 0.221, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3730, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3731, loss 0.107, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3732, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3733, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3734, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3735, loss 0.080, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3736, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3737, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3738, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3739, loss 0.101, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3740, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3741, loss 0.044, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3742, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3743, loss 0.594, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3744, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3745, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3746, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3747, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3748, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3749, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3750, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3751, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3752, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3753, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3754, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3755, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3756, loss 0.179, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3757, loss 0.054, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3758, loss 0.099, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3759, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3760, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3761, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3762, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3763, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3764, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3765, loss 0.045, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3766, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3767, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3768, loss 0.120, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3769, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3770, loss 0.074, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3771, loss 0.056, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3772, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3773, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3774, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3775, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3776, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3777, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3778, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3779, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3780, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3781, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3782, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3783, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3784, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3785, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3786, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3787, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3788, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3789, loss 0.227, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3790, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3791, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3792, loss 0.775, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3793, loss 0.134, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3794, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3795, loss 0.241, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3796, loss 0.504, batch accuracy 0.800\n",
      "Epoch 1, Iteration 3797, loss 0.042, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3798, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3799, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3800, loss 0.456, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3801, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3802, loss 0.212, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3803, loss 0.135, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3804, loss 0.554, batch accuracy 0.800\n",
      "Epoch 1, Iteration 3805, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3806, loss 0.115, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3807, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3808, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3809, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3810, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3811, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3812, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3813, loss 0.075, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3814, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3815, loss 0.042, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3816, loss 0.064, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3817, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3818, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3819, loss 0.381, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3820, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3821, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3822, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3823, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3824, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3825, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3826, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3827, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3828, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3829, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3830, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3831, loss 0.085, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3832, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3833, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3834, loss 0.110, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3835, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3836, loss 0.397, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3837, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3838, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3839, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3840, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3841, loss 0.085, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3842, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3843, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3844, loss 0.159, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3845, loss 0.112, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3846, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3847, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3848, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3849, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3850, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3851, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3852, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3853, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3854, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3855, loss 0.143, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3856, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3857, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3858, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3859, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3860, loss 0.053, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3861, loss 0.075, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3862, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3863, loss 0.047, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3864, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3865, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3866, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3867, loss 0.090, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3868, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3869, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3870, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3871, loss 0.085, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3872, loss 0.102, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 3873, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3874, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3875, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3876, loss 0.062, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3877, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3878, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3879, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3880, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3881, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3882, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3883, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3884, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3885, loss 0.094, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3886, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3887, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3888, loss 0.208, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3889, loss 0.056, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3890, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3891, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3892, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3893, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3894, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3895, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3896, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3897, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3898, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3899, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3900, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3901, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3902, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3903, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3904, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3905, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3906, loss 0.044, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3907, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3908, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3909, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3910, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3911, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3912, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3913, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3914, loss 0.241, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3915, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3916, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3917, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3918, loss 1.960, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3919, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3920, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3921, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3922, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3923, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3924, loss 0.049, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3925, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3926, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3927, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3928, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3929, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3930, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3931, loss 0.287, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3932, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3933, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3934, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3935, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3936, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3937, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3938, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3939, loss 0.177, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3940, loss 0.053, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3941, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3942, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3943, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3944, loss 0.079, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3945, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3946, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3947, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3948, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3949, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3950, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3951, loss 0.115, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3952, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3953, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3954, loss 0.334, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3955, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3956, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3957, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3958, loss 0.344, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3959, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3960, loss 0.174, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3961, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3962, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3963, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3964, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3965, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3966, loss 0.102, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3967, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3968, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3969, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3970, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3971, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3972, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3973, loss 0.188, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3974, loss 0.073, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3975, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3976, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3977, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3978, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3979, loss 0.225, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3980, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3981, loss 0.045, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3982, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3983, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3984, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3985, loss 0.153, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3986, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3987, loss 0.080, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3988, loss 0.080, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3989, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3990, loss 0.233, batch accuracy 0.900\n",
      "Epoch 1, Iteration 3991, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3992, loss 0.042, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3993, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3994, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3995, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3996, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3997, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3998, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 3999, loss 0.126, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4000, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4001, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4002, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4003, loss 0.949, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4004, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4005, loss 0.067, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4006, loss 0.243, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4007, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4008, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4009, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4010, loss 0.044, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4011, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4012, loss 0.492, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4013, loss 0.075, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4014, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4015, loss 0.057, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4016, loss 0.437, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4017, loss 0.150, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4018, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4019, loss 0.048, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4020, loss 0.692, batch accuracy 0.800\n",
      "Epoch 1, Iteration 4021, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4022, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4023, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4024, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4025, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4026, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4027, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4028, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4029, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4030, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4031, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4032, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4033, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4034, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4035, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4036, loss 0.242, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4037, loss 0.098, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4038, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4039, loss 0.135, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4040, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4041, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4042, loss 0.123, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4043, loss 0.116, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4044, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4045, loss 0.106, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4046, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4047, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4048, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4049, loss 0.112, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4050, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4051, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4052, loss 0.117, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4053, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4054, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4055, loss 0.090, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4056, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4057, loss 0.080, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4058, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4059, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4060, loss 0.011, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 4061, loss 0.103, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4062, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4063, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4064, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4065, loss 0.048, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4066, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4067, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4068, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4069, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4070, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4071, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4072, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4073, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4074, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4075, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4076, loss 0.135, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4077, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4078, loss 0.116, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4079, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4080, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4081, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4082, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4083, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4084, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4085, loss 0.249, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4086, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4087, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4088, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4089, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4090, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4091, loss 0.120, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4092, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4093, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4094, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4095, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4096, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4097, loss 0.216, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4098, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4099, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4100, loss 0.233, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4101, loss 0.357, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4102, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4103, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4104, loss 0.059, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4105, loss 0.079, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4106, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4107, loss 0.187, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4108, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4109, loss 0.585, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4110, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4111, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4112, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4113, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4114, loss 0.049, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4115, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4116, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4117, loss 0.059, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4118, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4119, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4120, loss 0.500, batch accuracy 0.800\n",
      "Epoch 1, Iteration 4121, loss 0.103, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4122, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4123, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4124, loss 0.427, batch accuracy 0.800\n",
      "Epoch 1, Iteration 4125, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4126, loss 0.314, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4127, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4128, loss 0.089, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4129, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4130, loss 0.052, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4131, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4132, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4133, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4134, loss 0.153, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4135, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4136, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4137, loss 0.489, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4138, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4139, loss 0.062, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4140, loss 0.217, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4141, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4142, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4143, loss 0.113, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4144, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4145, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4146, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4147, loss 0.084, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4148, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4149, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4150, loss 0.306, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4151, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4152, loss 0.125, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4153, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4154, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4155, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4156, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4157, loss 0.240, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4158, loss 0.133, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4159, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4160, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4161, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4162, loss 0.095, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4163, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4164, loss 0.042, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4165, loss 0.031, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4166, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4167, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4168, loss 0.437, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4169, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4170, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4171, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4172, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4173, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4174, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4175, loss 0.060, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4176, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4177, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4178, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4179, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4180, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4181, loss 0.058, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4182, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4183, loss 0.197, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4184, loss 0.164, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4185, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4186, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4187, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4188, loss 0.165, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4189, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4190, loss 0.491, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4191, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4192, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4193, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4194, loss 1.011, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4195, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4196, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4197, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4198, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4199, loss 0.031, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4200, loss 0.207, batch accuracy 0.800\n",
      "Epoch 1, Iteration 4201, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4202, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4203, loss 0.108, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4204, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4205, loss 0.072, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4206, loss 0.195, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4207, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4208, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4209, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4210, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4211, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4212, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4213, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4214, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4215, loss 0.097, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4216, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4217, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4218, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4219, loss 0.272, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4220, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4221, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4222, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4223, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4224, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4225, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4226, loss 0.072, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4227, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4228, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4229, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4230, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4231, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4232, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4233, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4234, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4235, loss 0.105, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4236, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4237, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4238, loss 0.109, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4239, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4240, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4241, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4242, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4243, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4244, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4245, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4246, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4247, loss 0.600, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4248, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4249, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4250, loss 0.009, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 4251, loss 0.118, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4252, loss 0.491, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4253, loss 0.079, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4254, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4255, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4256, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4257, loss 0.072, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4258, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4259, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4260, loss 0.618, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4261, loss 0.053, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4262, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4263, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4264, loss 0.048, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4265, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4266, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4267, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4268, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4269, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4270, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4271, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4272, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4273, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4274, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4275, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4276, loss 0.281, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4277, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4278, loss 0.055, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4279, loss 0.170, batch accuracy 0.800\n",
      "Epoch 1, Iteration 4280, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4281, loss 0.031, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4282, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4283, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4284, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4285, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4286, loss 0.208, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4287, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4288, loss 0.074, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4289, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4290, loss 0.586, batch accuracy 0.800\n",
      "Epoch 1, Iteration 4291, loss 0.418, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4292, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4293, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4294, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4295, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4296, loss 0.069, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4297, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4298, loss 0.078, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4299, loss 0.189, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4300, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4301, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4302, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4303, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4304, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4305, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4306, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4307, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4308, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4309, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4310, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4311, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4312, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4313, loss 0.121, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4314, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4315, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4316, loss 0.133, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4317, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4318, loss 0.097, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4319, loss 0.078, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4320, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4321, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4322, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4323, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4324, loss 0.049, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4325, loss 0.216, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4326, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4327, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4328, loss 0.044, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4329, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4330, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4331, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4332, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4333, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4334, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4335, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4336, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4337, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4338, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4339, loss 0.275, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4340, loss 0.062, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4341, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4342, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4343, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4344, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4345, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4346, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4347, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4348, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4349, loss 0.148, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4350, loss 0.091, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4351, loss 0.048, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4352, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4353, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4354, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4355, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4356, loss 0.042, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4357, loss 0.193, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4358, loss 0.165, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4359, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4360, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4361, loss 0.225, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4362, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4363, loss 0.186, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4364, loss 0.100, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4365, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4366, loss 0.049, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4367, loss 0.213, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4368, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4369, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4370, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4371, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4372, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4373, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4374, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4375, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4376, loss 0.056, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4377, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4378, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4379, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4380, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4381, loss 0.157, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4382, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4383, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4384, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4385, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4386, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4387, loss 0.165, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4388, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4389, loss 0.574, batch accuracy 0.800\n",
      "Epoch 1, Iteration 4390, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4391, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4392, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4393, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4394, loss 0.082, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4395, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4396, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4397, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4398, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4399, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4400, loss 0.126, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4401, loss 1.011, batch accuracy 0.800\n",
      "Epoch 1, Iteration 4402, loss 0.031, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4403, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4404, loss 0.212, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4405, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4406, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4407, loss 0.108, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4408, loss 0.075, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4409, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4410, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4411, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4412, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4413, loss 0.316, batch accuracy 0.800\n",
      "Epoch 1, Iteration 4414, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4415, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4416, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4417, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4418, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4419, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4420, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4421, loss 0.217, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4422, loss 0.055, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4423, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4424, loss 0.529, batch accuracy 0.800\n",
      "Epoch 1, Iteration 4425, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4426, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4427, loss 0.053, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4428, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4429, loss 0.420, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4430, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4431, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4432, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4433, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4434, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4435, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4436, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4437, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4438, loss 0.006, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 4439, loss 0.049, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4440, loss 0.055, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4441, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4442, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4443, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4444, loss 0.880, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4445, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4446, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4447, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4448, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4449, loss 0.477, batch accuracy 0.600\n",
      "Epoch 1, Iteration 4450, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4451, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4452, loss 0.141, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4453, loss 0.173, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4454, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4455, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4456, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4457, loss 0.104, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4458, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4459, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4460, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4461, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4462, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4463, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4464, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4465, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4466, loss 0.127, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4467, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4468, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4469, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4470, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4471, loss 0.078, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4472, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4473, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4474, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4475, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4476, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4477, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4478, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4479, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4480, loss 0.056, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4481, loss 0.278, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4482, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4483, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4484, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4485, loss 0.063, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4486, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4487, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4488, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4489, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4490, loss 0.194, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4491, loss 0.167, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4492, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4493, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4494, loss 0.079, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4495, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4496, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4497, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4498, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4499, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4500, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4501, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4502, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4503, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4504, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4505, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4506, loss 0.125, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4507, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4508, loss 0.331, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4509, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4510, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4511, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4512, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4513, loss 0.062, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4514, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4515, loss 0.167, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4516, loss 0.112, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4517, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4518, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4519, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4520, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4521, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4522, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4523, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4524, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4525, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4526, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4527, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4528, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4529, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4530, loss 0.584, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4531, loss 0.031, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4532, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4533, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4534, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4535, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4536, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4537, loss 0.238, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4538, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4539, loss 0.086, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4540, loss 0.082, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4541, loss 0.193, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4542, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4543, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4544, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4545, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4546, loss 0.282, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4547, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4548, loss 0.101, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4549, loss 0.073, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4550, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4551, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4552, loss 0.056, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4553, loss 0.049, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4554, loss 0.755, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4555, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4556, loss 0.602, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4557, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4558, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4559, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4560, loss 0.054, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4561, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4562, loss 0.056, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4563, loss 0.580, batch accuracy 0.800\n",
      "Epoch 1, Iteration 4564, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4565, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4566, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4567, loss 0.172, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4568, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4569, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4570, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4571, loss 0.513, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4572, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4573, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4574, loss 0.064, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4575, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4576, loss 0.133, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4577, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4578, loss 0.116, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4579, loss 0.085, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4580, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4581, loss 1.016, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4582, loss 0.339, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4583, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4584, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4585, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4586, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4587, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4588, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4589, loss 0.076, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4590, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4591, loss 0.238, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4592, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4593, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4594, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4595, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4596, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4597, loss 0.706, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4598, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4599, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4600, loss 0.178, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4601, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4602, loss 0.232, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4603, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4604, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4605, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4606, loss 0.140, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4607, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4608, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4609, loss 0.410, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4610, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4611, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4612, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4613, loss 0.126, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4614, loss 0.069, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4615, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4616, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4617, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4618, loss 0.131, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4619, loss 0.072, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4620, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4621, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4622, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4623, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4624, loss 0.256, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4625, loss 0.002, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 4626, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4627, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4628, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4629, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4630, loss 0.111, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4631, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4632, loss 0.381, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4633, loss 0.145, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4634, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4635, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4636, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4637, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4638, loss 0.057, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4639, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4640, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4641, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4642, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4643, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4644, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4645, loss 0.184, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4646, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4647, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4648, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4649, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4650, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4651, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4652, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4653, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4654, loss 0.213, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4655, loss 0.588, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4656, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4657, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4658, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4659, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4660, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4661, loss 0.062, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4662, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4663, loss 0.139, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4664, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4665, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4666, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4667, loss 0.065, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4668, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4669, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4670, loss 0.089, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4671, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4672, loss 0.472, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4673, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4674, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4675, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4676, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4677, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4678, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4679, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4680, loss 0.113, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4681, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4682, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4683, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4684, loss 0.053, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4685, loss 0.045, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4686, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4687, loss 0.082, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4688, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4689, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4690, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4691, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4692, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4693, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4694, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4695, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4696, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4697, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4698, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4699, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4700, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4701, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4702, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4703, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4704, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4705, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4706, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4707, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4708, loss 0.414, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4709, loss 0.299, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4710, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4711, loss 0.083, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4712, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4713, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4714, loss 0.114, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4715, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4716, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4717, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4718, loss 0.057, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4719, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4720, loss 0.286, batch accuracy 0.800\n",
      "Epoch 1, Iteration 4721, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4722, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4723, loss 0.389, batch accuracy 0.800\n",
      "Epoch 1, Iteration 4724, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4725, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4726, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4727, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4728, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4729, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4730, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4731, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4732, loss 0.091, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4733, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4734, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4735, loss 0.181, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4736, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4737, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4738, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4739, loss 0.195, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4740, loss 0.177, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4741, loss 0.245, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4742, loss 0.126, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4743, loss 0.165, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4744, loss 0.107, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4745, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4746, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4747, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4748, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4749, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4750, loss 0.075, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4751, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4752, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4753, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4754, loss 0.098, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4755, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4756, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4757, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4758, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4759, loss 0.068, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4760, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4761, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4762, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4763, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4764, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4765, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4766, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4767, loss 0.067, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4768, loss 0.048, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4769, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4770, loss 0.092, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4771, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4772, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4773, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4774, loss 0.126, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4775, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4776, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4777, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4778, loss 0.064, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4779, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4780, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4781, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4782, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4783, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4784, loss 0.088, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4785, loss 0.053, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4786, loss 0.410, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4787, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4788, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4789, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4790, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4791, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4792, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4793, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4794, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4795, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4796, loss 0.071, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4797, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4798, loss 0.432, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4799, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4800, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4801, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4802, loss 0.201, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4803, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4804, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4805, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4806, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4807, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4808, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4809, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4810, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4811, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4812, loss 0.078, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4813, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4814, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4815, loss 0.150, batch accuracy 0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 4816, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4817, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4818, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4819, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4820, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4821, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4822, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4823, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4824, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4825, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4826, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4827, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4828, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4829, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4830, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4831, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4832, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4833, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4834, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4835, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4836, loss 0.074, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4837, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4838, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4839, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4840, loss 0.162, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4841, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4842, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4843, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4844, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4845, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4846, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4847, loss 0.047, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4848, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4849, loss 0.057, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4850, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4851, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4852, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4853, loss 0.038, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4854, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4855, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4856, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4857, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4858, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4859, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4860, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4861, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4862, loss 0.086, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4863, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4864, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4865, loss 0.342, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4866, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4867, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4868, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4869, loss 0.150, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4870, loss 0.158, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4871, loss 0.581, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4872, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4873, loss 0.146, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4874, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4875, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4876, loss 0.143, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4877, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4878, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4879, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4880, loss 0.182, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4881, loss 0.056, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4882, loss 0.085, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4883, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4884, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4885, loss 0.233, batch accuracy 0.800\n",
      "Epoch 1, Iteration 4886, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4887, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4888, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4889, loss 0.103, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4890, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4891, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4892, loss 0.248, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4893, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4894, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4895, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4896, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4897, loss 0.405, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4898, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4899, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4900, loss 0.031, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4901, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4902, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4903, loss 0.494, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4904, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4905, loss 0.784, batch accuracy 0.800\n",
      "Epoch 1, Iteration 4906, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4907, loss 0.134, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4908, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4909, loss 0.072, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4910, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4911, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4912, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4913, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4914, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4915, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4916, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4917, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4918, loss 0.124, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4919, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4920, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4921, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4922, loss 0.530, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4923, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4924, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4925, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4926, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4927, loss 0.051, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4928, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4929, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4930, loss 0.120, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4931, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4932, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4933, loss 0.813, batch accuracy 0.700\n",
      "Epoch 1, Iteration 4934, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4935, loss 0.231, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4936, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4937, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4938, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4939, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4940, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4941, loss 0.613, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4942, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4943, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4944, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4945, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4946, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4947, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4948, loss 0.185, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4949, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4950, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4951, loss 0.106, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4952, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4953, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4954, loss 0.236, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4955, loss 0.063, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4956, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4957, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4958, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4959, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4960, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4961, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4962, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4963, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4964, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4965, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4966, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4967, loss 1.299, batch accuracy 0.800\n",
      "Epoch 1, Iteration 4968, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4969, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4970, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4971, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4972, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4973, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4974, loss 0.047, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4975, loss 0.120, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4976, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4977, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4978, loss 0.097, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4979, loss 0.204, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4980, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4981, loss 0.190, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4982, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4983, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4984, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4985, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4986, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4987, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4988, loss 0.588, batch accuracy 0.900\n",
      "Epoch 1, Iteration 4989, loss 0.045, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4990, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4991, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4992, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4993, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4994, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4995, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4996, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4997, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4998, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 4999, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5000, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5001, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5002, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5003, loss 0.005, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 5004, loss 0.136, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5005, loss 0.085, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5006, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5007, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5008, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5009, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5010, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5011, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5012, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5013, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5014, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5015, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5016, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5017, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5018, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5019, loss 0.047, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5020, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5021, loss 0.149, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5022, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5023, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5024, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5025, loss 0.048, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5026, loss 0.081, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5027, loss 0.487, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5028, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5029, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5030, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5031, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5032, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5033, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5034, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5035, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5036, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5037, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5038, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5039, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5040, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5041, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5042, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5043, loss 0.238, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5044, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5045, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5046, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5047, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5048, loss 0.274, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5049, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5050, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5051, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5052, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5053, loss 0.130, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5054, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5055, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5056, loss 0.198, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5057, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5058, loss 0.044, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5059, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5060, loss 0.217, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5061, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5062, loss 0.229, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5063, loss 0.265, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5064, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5065, loss 0.157, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5066, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5067, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5068, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5069, loss 0.324, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5070, loss 0.060, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5071, loss 0.079, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5072, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5073, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5074, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5075, loss 0.089, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5076, loss 0.101, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5077, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5078, loss 0.354, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5079, loss 0.114, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5080, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5081, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5082, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5083, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5084, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5085, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5086, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5087, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5088, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5089, loss 0.103, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5090, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5091, loss 0.177, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5092, loss 0.283, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5093, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5094, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5095, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5096, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5097, loss 0.112, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5098, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5099, loss 0.098, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5100, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5101, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5102, loss 0.431, batch accuracy 0.800\n",
      "Epoch 1, Iteration 5103, loss 0.198, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5104, loss 0.346, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5105, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5106, loss 0.091, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5107, loss 0.164, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5108, loss 0.054, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5109, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5110, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5111, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5112, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5113, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5114, loss 0.079, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5115, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5116, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5117, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5118, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5119, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5120, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5121, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5122, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5123, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5124, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5125, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5126, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5127, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5128, loss 0.044, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5129, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5130, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5131, loss 0.068, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5132, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5133, loss 0.246, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5134, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5135, loss 0.747, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5136, loss 0.326, batch accuracy 0.800\n",
      "Epoch 1, Iteration 5137, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5138, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5139, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5140, loss 0.173, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5141, loss 0.870, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5142, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5143, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5144, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5145, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5146, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5147, loss 0.238, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5148, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5149, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5150, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5151, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5152, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5153, loss 0.067, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5154, loss 0.267, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5155, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5156, loss 0.258, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5157, loss 0.172, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5158, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5159, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5160, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5161, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5162, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5163, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5164, loss 0.054, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5165, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5166, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5167, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5168, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5169, loss 0.478, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5170, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5171, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5172, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5173, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5174, loss 0.053, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5175, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5176, loss 0.044, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5177, loss 0.067, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5178, loss 0.298, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5179, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5180, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5181, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5182, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5183, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5184, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5185, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5186, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5187, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5188, loss 0.061, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5189, loss 0.012, batch accuracy 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 5190, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5191, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5192, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5193, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5194, loss 0.119, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5195, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5196, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5197, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5198, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5199, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5200, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5201, loss 0.223, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5202, loss 0.048, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5203, loss 0.159, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5204, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5205, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5206, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5207, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5208, loss 0.070, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5209, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5210, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5211, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5212, loss 0.264, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5213, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5214, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5215, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5216, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5217, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5218, loss 0.053, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5219, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5220, loss 0.165, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5221, loss 0.038, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5222, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5223, loss 0.186, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5224, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5225, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5226, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5227, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5228, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5229, loss 0.070, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5230, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5231, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5232, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5233, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5234, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5235, loss 0.268, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5236, loss 0.053, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5237, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5238, loss 0.079, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5239, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5240, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5241, loss 0.175, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5242, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5243, loss 0.089, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5244, loss 0.054, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5245, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5246, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5247, loss 0.084, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5248, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5249, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5250, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5251, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5252, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5253, loss 0.268, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5254, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5255, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5256, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5257, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5258, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5259, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5260, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5261, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5262, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5263, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5264, loss 0.151, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5265, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5266, loss 0.296, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5267, loss 0.325, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5268, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5269, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5270, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5271, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5272, loss 0.114, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5273, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5274, loss 0.047, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5275, loss 0.052, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5276, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5277, loss 0.044, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5278, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5279, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5280, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5281, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5282, loss 0.052, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5283, loss 0.072, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5284, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5285, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5286, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5287, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5288, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5289, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5290, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5291, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5292, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5293, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5294, loss 0.064, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5295, loss 0.094, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5296, loss 0.379, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5297, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5298, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5299, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5300, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5301, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5302, loss 0.291, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5303, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5304, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5305, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5306, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5307, loss 0.058, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5308, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5309, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5310, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5311, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5312, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5313, loss 0.052, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5314, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5315, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5316, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5317, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5318, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5319, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5320, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5321, loss 0.135, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5322, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5323, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5324, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5325, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5326, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5327, loss 0.208, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5328, loss 0.062, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5329, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5330, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5331, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5332, loss 0.247, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5333, loss 0.305, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5334, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5335, loss 0.069, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5336, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5337, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5338, loss 0.240, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5339, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5340, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5341, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5342, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5343, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5344, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5345, loss 0.049, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5346, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5347, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5348, loss 0.103, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5349, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5350, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5351, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5352, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5353, loss 0.056, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5354, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5355, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5356, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5357, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5358, loss 0.038, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5359, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5360, loss 0.143, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5361, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5362, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5363, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5364, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5365, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5366, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5367, loss 0.073, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5368, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5369, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5370, loss 0.060, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5371, loss 0.082, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5372, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5373, loss 0.825, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5374, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5375, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5376, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5377, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5378, loss 0.088, batch accuracy 0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 5379, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5380, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5381, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5382, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5383, loss 0.065, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5384, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5385, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5386, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5387, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5388, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5389, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5390, loss 0.041, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5391, loss 0.314, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5392, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5393, loss 0.060, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5394, loss 0.367, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5395, loss 0.135, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5396, loss 0.077, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5397, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5398, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5399, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5400, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5401, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5402, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5403, loss 0.188, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5404, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5405, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5406, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5407, loss 0.156, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5408, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5409, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5410, loss 0.213, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5411, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5412, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5413, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5414, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5415, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5416, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5417, loss 0.042, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5418, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5419, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5420, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5421, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5422, loss 0.415, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5423, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5424, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5425, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5426, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5427, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5428, loss 0.166, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5429, loss 0.818, batch accuracy 0.800\n",
      "Epoch 1, Iteration 5430, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5431, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5432, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5433, loss 1.006, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5434, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5435, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5436, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5437, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5438, loss 0.060, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5439, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5440, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5441, loss 0.130, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5442, loss 0.327, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5443, loss 0.076, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5444, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5445, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5446, loss 0.084, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5447, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5448, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5449, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5450, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5451, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5452, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5453, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5454, loss 0.042, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5455, loss 0.341, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5456, loss 0.045, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5457, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5458, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5459, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5460, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5461, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5462, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5463, loss 0.054, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5464, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5465, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5466, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5467, loss 0.098, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5468, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5469, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5470, loss 0.038, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5471, loss 0.075, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5472, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5473, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5474, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5475, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5476, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5477, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5478, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5479, loss 0.523, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5480, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5481, loss 0.089, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5482, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5483, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5484, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5485, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5486, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5487, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5488, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5489, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5490, loss 0.140, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5491, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5492, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5493, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5494, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5495, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5496, loss 0.572, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5497, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5498, loss 0.319, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5499, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5500, loss 0.176, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5501, loss 0.074, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5502, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5503, loss 0.246, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5504, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5505, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5506, loss 0.155, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5507, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5508, loss 0.369, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5509, loss 0.048, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5510, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5511, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5512, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5513, loss 0.082, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5514, loss 0.042, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5515, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5516, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5517, loss 0.090, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5518, loss 0.193, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5519, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5520, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5521, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5522, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5523, loss 0.120, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5524, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5525, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5526, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5527, loss 0.051, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5528, loss 0.300, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5529, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5530, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5531, loss 0.092, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5532, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5533, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5534, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5535, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5536, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5537, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5538, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5539, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5540, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5541, loss 0.276, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5542, loss 0.032, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5543, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5544, loss 0.456, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5545, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5546, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5547, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5548, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5549, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5550, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5551, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5552, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5553, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5554, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5555, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5556, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5557, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5558, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5559, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5560, loss 0.141, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5561, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5562, loss 0.246, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5563, loss 0.069, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5564, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5565, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5566, loss 0.090, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5567, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5568, loss 0.128, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5569, loss 0.252, batch accuracy 0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 5570, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5571, loss 0.075, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5572, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5573, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5574, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5575, loss 0.283, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5576, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5577, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5578, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5579, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5580, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5581, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5582, loss 0.600, batch accuracy 0.800\n",
      "Epoch 1, Iteration 5583, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5584, loss 0.110, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5585, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5586, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5587, loss 0.230, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5588, loss 0.094, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5589, loss 0.421, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5590, loss 0.281, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5591, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5592, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5593, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5594, loss 0.140, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5595, loss 0.044, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5596, loss 0.106, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5597, loss 0.597, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5598, loss 0.176, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5599, loss 0.657, batch accuracy 0.800\n",
      "Epoch 1, Iteration 5600, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5601, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5602, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5603, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5604, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5605, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5606, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5607, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5608, loss 0.638, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5609, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5610, loss 0.438, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5611, loss 0.205, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5612, loss 0.063, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5613, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5614, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5615, loss 0.345, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5616, loss 0.124, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5617, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5618, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5619, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5620, loss 0.383, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5621, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5622, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5623, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5624, loss 0.175, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5625, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5626, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5627, loss 0.496, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5628, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5629, loss 0.057, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5630, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5631, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5632, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5633, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5634, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5635, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5636, loss 0.031, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5637, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5638, loss 0.236, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5639, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5640, loss 0.050, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5641, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5642, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5643, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5644, loss 0.058, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5645, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5646, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5647, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5648, loss 0.083, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5649, loss 0.253, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5650, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5651, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5652, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5653, loss 0.039, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5654, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5655, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5656, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5657, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5658, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5659, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5660, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5661, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5662, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5663, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5664, loss 0.108, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5665, loss 0.079, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5666, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5667, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5668, loss 0.336, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5669, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5670, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5671, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5672, loss 0.167, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5673, loss 0.242, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5674, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5675, loss 0.232, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5676, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5677, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5678, loss 0.068, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5679, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5680, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5681, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5682, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5683, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5684, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5685, loss 0.179, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5686, loss 0.388, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5687, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5688, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5689, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5690, loss 0.027, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5691, loss 0.221, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5692, loss 0.244, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5693, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5694, loss 0.570, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5695, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5696, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5697, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5698, loss 0.301, batch accuracy 0.800\n",
      "Epoch 1, Iteration 5699, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5700, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5701, loss 0.136, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5702, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5703, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5704, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5705, loss 0.200, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5706, loss 0.182, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5707, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5708, loss 0.530, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5709, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5710, loss 0.063, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5711, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5712, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5713, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5714, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5715, loss 0.053, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5716, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5717, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5718, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5719, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5720, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5721, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5722, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5723, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5724, loss 0.054, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5725, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5726, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5727, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5728, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5729, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5730, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5731, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5732, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5733, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5734, loss 0.082, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5735, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5736, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5737, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5738, loss 0.139, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5739, loss 0.144, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5740, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5741, loss 0.084, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5742, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5743, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5744, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5745, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5746, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5747, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5748, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5749, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5750, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5751, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5752, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5753, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5754, loss 0.133, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5755, loss 0.056, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5756, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5757, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5758, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5759, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5760, loss 0.219, batch accuracy 0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 5761, loss 0.088, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5762, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5763, loss 0.031, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5764, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5765, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5766, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5767, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5768, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5769, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5770, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5771, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5772, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5773, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5774, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5775, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5776, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5777, loss 0.035, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5778, loss 0.067, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5779, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5780, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5781, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5782, loss 0.051, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5783, loss 0.074, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5784, loss 0.046, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5785, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5786, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5787, loss 0.078, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5788, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5789, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5790, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5791, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5792, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5793, loss 0.028, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5794, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5795, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5796, loss 0.050, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5797, loss 0.275, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5798, loss 0.067, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5799, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5800, loss 0.146, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5801, loss 0.090, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5802, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5803, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5804, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5805, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5806, loss 0.176, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5807, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5808, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5809, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5810, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5811, loss 0.036, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5812, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5813, loss 0.138, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5814, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5815, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5816, loss 0.081, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5817, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5818, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5819, loss 0.145, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5820, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5821, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5822, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5823, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5824, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5825, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5826, loss 0.023, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5827, loss 0.092, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5828, loss 0.150, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5829, loss 0.061, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5830, loss 0.162, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5831, loss 0.324, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5832, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5833, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5834, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5835, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5836, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5837, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5838, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5839, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5840, loss 0.093, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5841, loss 0.017, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5842, loss 0.016, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5843, loss 0.056, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5844, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5845, loss 0.044, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5846, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5847, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5848, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5849, loss 0.030, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5850, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5851, loss 0.053, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5852, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5853, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5854, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5855, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5856, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5857, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5858, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5859, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5860, loss 0.022, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5861, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5862, loss 0.037, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5863, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5864, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5865, loss 0.026, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5866, loss 0.011, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5867, loss 1.058, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5868, loss 0.047, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5869, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5870, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5871, loss 0.073, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5872, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5873, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5874, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5875, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5876, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5877, loss 0.024, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5878, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5879, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5880, loss 0.126, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5881, loss 0.297, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5882, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5883, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5884, loss 0.059, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5885, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5886, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5887, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5888, loss 0.118, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5889, loss 0.009, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5890, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5891, loss 0.033, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5892, loss 0.025, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5893, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5894, loss 0.040, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5895, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5896, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5897, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5898, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5899, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5900, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5901, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5902, loss 0.380, batch accuracy 0.800\n",
      "Epoch 1, Iteration 5903, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5904, loss 0.076, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5905, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5906, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5907, loss 0.014, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5908, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5909, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5910, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5911, loss 0.100, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5912, loss 0.164, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5913, loss 0.048, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5914, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5915, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5916, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5917, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5918, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5919, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5920, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5921, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5922, loss 0.070, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5923, loss 0.089, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5924, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5925, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5926, loss 0.741, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5927, loss 0.166, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5928, loss 0.084, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5929, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5930, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5931, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5932, loss 0.376, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5933, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5934, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5935, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5936, loss 0.029, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5937, loss 0.442, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5938, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5939, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5940, loss 0.021, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5941, loss 0.015, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5942, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5943, loss 0.872, batch accuracy 0.700\n",
      "Epoch 1, Iteration 5944, loss 0.443, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5945, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5946, loss 1.484, batch accuracy 0.800\n",
      "Epoch 1, Iteration 5947, loss 0.013, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5948, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5949, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5950, loss 0.408, batch accuracy 0.900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Iteration 5951, loss 0.089, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5952, loss 0.277, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5953, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5954, loss 0.351, batch accuracy 0.800\n",
      "Epoch 1, Iteration 5955, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5956, loss 0.005, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5957, loss 0.031, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5958, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5959, loss 0.333, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5960, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5961, loss 0.034, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5962, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5963, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5964, loss 0.007, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5965, loss 0.019, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5966, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5967, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5968, loss 0.020, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5969, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5970, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5971, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5972, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5973, loss 0.012, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5974, loss 0.001, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5975, loss 0.018, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5976, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5977, loss 0.587, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5978, loss 0.008, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5979, loss 0.047, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5980, loss 0.006, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5981, loss 0.137, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5982, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5983, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5984, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5985, loss 0.003, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5986, loss 0.051, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5987, loss 0.072, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5988, loss 0.086, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5989, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5990, loss 0.010, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5991, loss 0.043, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5992, loss 0.002, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5993, loss 0.158, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5994, loss 0.092, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5995, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5996, loss 0.000, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5997, loss 0.601, batch accuracy 0.900\n",
      "Epoch 1, Iteration 5998, loss 0.004, batch accuracy 1.000\n",
      "Epoch 1, Iteration 5999, loss 0.000, batch accuracy 1.000\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(model.nb_epochs):\n",
    "    randomize = np.arange(x_train.shape[0])\n",
    "    np.random.shuffle(randomize)\n",
    "    x_in = model.x_train[randomize,:]\n",
    "    y_in = model.y_train[randomize,:]\n",
    "    for i in range(model.nb_iterations):\n",
    "        input_x_train = x_in[i*model.batch_size: (i+1)*model.batch_size]\n",
    "        input_y_train = y_in[i*model.batch_size: (i+1)*model.batch_size]\n",
    "        _ , preds, loss, loss_summ = sess.run([model.trainer, model.preds, model.loss, model.loss_summ], \n",
    "                                 feed_dict={model.im: input_x_train, \n",
    "                                            model.labels: input_y_train})\n",
    "        y_preds = np.argmax(preds, axis=1)\n",
    "        y_real = np.argmax(input_y_train, axis=1)\n",
    "        acc_train = np.mean((y_preds==y_real)*1)\n",
    "        print('Epoch %d, Iteration %d, loss %.3f, batch accuracy %.3f' %(epoch, i, loss, acc_train))\n",
    "        writer.add_summary(loss_summ, epoch * model.nb_iterations + i)\n",
    "    saver.save(sess, model.output_dir, global_step=epoch)  \n",
    "# sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we loop over the test dataset and compute the corresponding classification accuracy. \n",
    "\n",
    "- Similar to Task 3.1, include a figure to visualize your training & testing(see below) performances during iterations and discuss your observations in your report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy achieved: 0.982\n"
     ]
    }
   ],
   "source": [
    "batch_size_test = 20\n",
    "nb_test_points = x_test.shape[0] \n",
    "nb_iterations = nb_test_points//batch_size_test\n",
    "preds = []\n",
    "for i in range(nb_iterations):\n",
    "    input_x_test = x_test[i*batch_size_test: (i+1)*batch_size_test]\n",
    "    input_x_test = input_x_test[:, :, :,np.newaxis]\n",
    "    preds_test = sess.run(model.preds, \n",
    "                             feed_dict={model.im: input_x_test})\n",
    "    preds.append(np.argmax(preds_test, axis=1))\n",
    "    if np.mod(nb_test_points, batch_size_test) !=0:\n",
    "        input_x_test = x_test[i*batch_size_test: -1]\n",
    "        preds_test = sess.run(model.preds, \n",
    "                             feed_dict={model.im: input_x_test})\n",
    "        preds.append(np.argmax(preds, axis=1))\n",
    "all_preds = np.concatenate(preds, axis =0)\n",
    "y_real = np.argmax(y_test, axis=1)\n",
    "acc_test = np.mean((all_preds==y_real)*1)\n",
    "print('Test accuracy achieved: %.3f' %acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 4.2\n",
    "Similar to task 3.2, discuss \n",
    "- Plot a graph showing complexity (number of paramters) vs. accuracy vs. depth of networks. For this part you need to train four additional CNNs of different depths/widths (again, your choice) and report the results in a Table. Discuss the results and provide conclusion.\n",
    "\n",
    "\n",
    "- In addition discuss and analyze the differences in term of performance, number of model parameters (i.e. weights/biases) and training/testing times between CNNs and MLPs. Provide a concusion. (For these discussions you should compare your results in Table 4.2 to Table 3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualizing learned filters and activations (6 points)\n",
    "It is sometimes useful to visualize what kind of filters a CNN have learned. One way to do so is to plot each filter of size [kernel_size $\\times$ kerne_size]. \n",
    "\n",
    "- Once your CNN (in Question 6) is trained, access its filters via 'tf.get_collection' and plot them on a grid for each layer. What patterns do you observe, why?\n",
    "- In addition, plot the activations of each layer for two images chosen from digit-classes '2' and '9'. Discuss your observations\n",
    "\n",
    "Hint: \n",
    "+ Activations are for example the outputs of tf.layers.conv2D.\n",
    "+ Use tf.get_collection to access the learned filters of each layers. For this, you need to know how they are named (which can be accessed by tf.trainable_variables among other means of doing so).\n",
    "\n",
    "The plotted feature maps and learned filters should be plotted in the same way as in the images bellow. (left: Feature Maps, right: learned Filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Examples of activation maps (left), and learned features (right))](im.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Multi Task Learning (12 points)\n",
    "\n",
    "This question concerns the practice of multi-task learning (MTL). \n",
    "The aim of multi task learning is to leverage two (or more) related tasks in the learning process with the hope that leanring one task aids perfromance in learning the other task(s) and thus improves predicitve power for at least one (ideally all) of the tasks. \n",
    "\n",
    "There are two distinct flavours of MTL: Hard parameter  sharing and soft parameter sharing. We will be focusing on the former in this question.\n",
    "Hard paramter sharing occurs when two tasks share a common network which then splits into task specific paths (e.g. a series of convolutional layers with two paths of dense layers for two seperate tasks). \n",
    "\n",
    "In this question, you will explore the FASHION MNIST dataset and be coding up your own MTL model and considering the pros and cons of MTL compared to single task learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have written the code to pre-load this dataset and split it into two related tasks for you:\n",
    "\n",
    "- Task 1 - Clothing item 10 class classification (e.g. shoes, t-shirts etc) across 10 goups - $ y \\in \\mathbb{R^{10}} $\n",
    "- Task 2 - Clothing group three class classification - predicitng whether a viewed clothing image belongs to one of three groups - $ y \\in \\mathbb{R^{3}} $\n",
    "    - These groups are shoes (Sandal, Sneaker and Ankle Boot),  Gendered (Dress, Shirt and Bag) and Uni-Sex (T-shirt, Trouser, Pullover and Coat). \n",
    "\n",
    "\n",
    "#### Note : Alternativley use the tf.nn module. \n",
    "\n",
    "#### Note  : We advise the use of only a single epoch for this question for the sake of computation time.  However, if you want to utilise additional epochs feel free to do so just be aware of the longer training time and be consistent over all networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Code for loading the dataset\n",
    "\"\"\"\n",
    "import keras.datasets.fashion_mnist as fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def load_data(): \n",
    "    # train_X: (60000, 28, 28)\n",
    "    # train_y: (60000,)\n",
    "    # test_X: (10000, 28, 28)\n",
    "    # test_y: (10000,)\n",
    "    (train_X, train_y_1), (test_X, test_y_1) = fashion_mnist.load_data()\n",
    "    n_class_1 = 10\n",
    "    # map to new label\n",
    "    train_y_2 = list(0 if y in [5, 7, 9] else 1 if y in [3, 6, 8] else 2 for y in train_y_1)  \n",
    "    test_y_2 = list(0 if y in [5, 7, 9] else 1 if y in [3, 6, 8] else 2 for y in test_y_1)\n",
    "    n_class_2 = 3\n",
    "    # train_X: (60000, 28, 28, 1)\n",
    "    # test_X: (10000, 28, 28, 1)\n",
    "    # train_y: (60000, n_class = 10)\n",
    "    # test_y: (10000, n_class = 3)\n",
    "    train_X = np.expand_dims(train_X, axis=3)\n",
    "    test_X = np.expand_dims(test_X, axis=3)\n",
    "    train_y_1 = to_categorical(train_y_1, n_class_1)\n",
    "    test_y_1 = to_categorical(test_y_1, n_class_1)\n",
    "    train_y_2 = to_categorical(train_y_2, n_class_2)\n",
    "    test_y_2 = to_categorical(test_y_2, n_class_2)\n",
    "    return train_X, train_y_1, train_y_2, test_X, test_y_1, test_y_2\n",
    "\n",
    "\n",
    "x_train, y_train_1, y_train_2, x_test, y_test_1, y_test_2 = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6.1\n",
    "\n",
    "In this question you will construct two seperate networks of identical structure (excpet the logits and pred layers) one for each of the two tasks.\n",
    "\n",
    "In other words, create a network for item classification and a network for item group classification. \n",
    "\n",
    "\n",
    "Complete the Task_1_NN and Task_2_NN below. These single task networks will form the basis of your work in this question. \n",
    "\n",
    "For the sake of convieience, we will use the same CNN filters as Question 4 - $[32, 64, 128]$. However our kernel size will be 3 $\\times$ 3 and a stride of 1 for all convolutional layers. Maxpooling layers will also need to be implemented after the first and second convolutional layers. These maxpooling layers have a kernel size of two and a stride of 2. \n",
    "\n",
    "After the final convolution, flatten the outputs and pass them to dense layers $[3136, 1024, 100 , N]$ where $N$ is the number of outputs required (10 or 3). \n",
    "\n",
    "As with Question 4, the function 'create_model' to be cpomplemted defines the class variables:\n",
    " - Task 1\n",
    "     - self.logits $\\in \\mathbb{R^{10}}$ containing the output without activation of the last __<font color='red'>fully connected (i.e. dense) layer</font>.__ \n",
    "     - self.preds $\\in \\mathbb{R^{10}}$ containing posterior probabilities.\n",
    " - Task 2\n",
    "      - self.logits $\\in \\mathbb{R^{3}}$ containing the output without activation of the last __<font color='red'>fully connected layer</font>.__ \n",
    "      - self.preds $\\in \\mathbb{R^{3}}$ containing posterior probabilities.\n",
    "      \n",
    "The method definitons remain the same  as in previous questions. \n",
    "      \n",
    "      \n",
    "#### Note: We advise you save the number of parameters and accuracy of the models in order to save time later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    def create_model(self):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class Task_1_NN():\n",
    "    def __init__(self, x_train, y_train_1,  output_dir, lr=0.001, nb_epochs=10, batch_size=50):\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.nb_images, self.edge, _, _ = x_train.shape\n",
    "        self.nb_iterations = self.nb_images // batch_size\n",
    "        self.output_dir = output_dir\n",
    "        self.x_train = x_train\n",
    "        self.y_train_1 = y_train_1\n",
    "        self.m = x_train.shape[0]\n",
    "        self.n_output_1 = y_train_1.shape[1]\n",
    "        \n",
    "        self.X = tf.placeholder(tf.float32, (None, 28, 28, 1), \"X\")\n",
    "        self.y_1 = tf.placeholder(tf.float32, (None, self.n_output_1), \"y_1\")\n",
    "    \n",
    "     def create_model(self):            \n",
    "        with tf.variable_scope(\"Task_1\", reuse=tf.AUTO_REUSE):\n",
    "            \n",
    "            ######### Complete the function ######### \n",
    "            self.logits = \n",
    "            self.preds =\n",
    "            #########################################\n",
    "                \n",
    "                \n",
    "                \n",
    "    def compute_loss(self):\n",
    "        with tf.variable_scope('loss'):\n",
    "            ######### Complete the function ######### \n",
    "            self.loss_task_1 = \n",
    "            #########################################\n",
    "            self.loss_summ = tf.summary.scalar(\"softmax_loss\", self.loss_task_1) \n",
    "                \n",
    "                \n",
    "    def optimizer(self):\n",
    "        with tf.variable_scope('optimizer', reuse=tf.AUTO_REUSE):\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=self.lr, beta1=0.5)\n",
    "            self.model_vars = tf.trainable_variables()\n",
    "            self.trainer = optimizer.minimize(self.loss_task_1, var_list=self.model_vars)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task_2_NN():\n",
    "    def __init__(self, x_train, y_train_2,  output_dir, lr=0.001, nb_epochs=10, batch_size=50):\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.nb_images, self.edge, _, _ = x_train.shape\n",
    "        self.nb_iterations = self.nb_images // batch_size\n",
    "        self.output_dir = output_dir\n",
    "        self.x_train = x_train\n",
    "        self.y_train_2 = y_train_2\n",
    "        self.m = x_train.shape[0]\n",
    "        self.n_output_2 = y_train_2.shape[1]\n",
    "        \n",
    "        self.X = tf.placeholder(tf.float32, (None, 28, 28, 1), \"X\")\n",
    "        self.y_2 = tf.placeholder(tf.float32, (None, self.n_output_2), \"y_2\")\n",
    "    \n",
    "     def create_model(self):            \n",
    "        with tf.variable_scope(\"Task_2\", reuse=tf.AUTO_REUSE):\n",
    "            \n",
    "            ######### Complete the function ######### \n",
    "            self.logits = \n",
    "            self.preds =\n",
    "            #########################################\n",
    "                \n",
    "                \n",
    "                \n",
    "    def compute_loss(self):\n",
    "        with tf.variable_scope('loss'):\n",
    "            ######### Complete the function ######### \n",
    "            self.loss_task_2 = \n",
    "            #########################################\n",
    "            self.loss_summ = tf.summary.scalar(\"softmax_loss\", self.loss_task_2) \n",
    "                \n",
    "                \n",
    "    def optimizer(self):\n",
    "        with tf.variable_scope('optimizer', reuse=tf.AUTO_REUSE):\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=self.lr, beta1=0.5)\n",
    "            self.model_vars = tf.trainable_variables()\n",
    "            self.trainer = optimizer.minimize(self.loss_task_2, var_list=self.model_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now train and test Task 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_1 = Task_1_NN(x_train, y_train_1, './Task1_logdir/', 0.001, 2, 10)            \n",
    "model_1.create_model()     \n",
    "\n",
    "model_1.compute_loss()\n",
    "model_1.optimizer()   \n",
    "\n",
    "model_1.optimizer()\n",
    "init = (tf.global_variables_initializer(),\n",
    "        tf.local_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "summary =tf.Summary()\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "writer = tf.summary.FileWriter(model_1.output_dir)\n",
    "writer.add_graph(sess.graph)\n",
    "if not os.path.exists(model_1.output_dir):\n",
    "    os.makedirs(model_1.output_dir)  \n",
    "\n",
    "\"\"\"\n",
    "Train\n",
    "\"\"\"\n",
    "\n",
    "for epoch in range(model_1.nb_epochs):\n",
    "    randomize = np.arange(x_train.shape[0])\n",
    "    np.random.shuffle(randomize)\n",
    "    x_in = model_1.x_train[randomize,:]\n",
    "    y_in_1 = model_1.y_train_1[randomize,:]\n",
    "    for i in range(model_1.nb_iterations):\n",
    "        input_x_train = x_in[i*model_1.batch_size: (i+1)*model_1.batch_size]\n",
    "        input_y_train_1 = y_in_1[i*model_1.batch_size: (i+1)*model_1.batch_size]\n",
    "        _ , preds_1, loss_1, loss_summ = sess.run([model_1.trainer, model_1.pred_1,  model_1.loss_task_1, model_1.loss_summ], \n",
    "                                 feed_dict={model_1.X: input_x_train, \n",
    "                                            model_1.y_1: input_y_train_1})\n",
    "\n",
    "        y_preds_1 = np.argmax(preds_1, axis=1)\n",
    "        y_real_1 = np.argmax(input_y_train_1, axis=1)\n",
    "        acc_train_1 = np.mean((y_preds_1==y_real_1)*1)\n",
    "        print('Epoch %d, Iteration %d, loss_1 %.3f,  batch accuracy_1 %.3f' %(epoch, i, loss_1,acc_train_1))\n",
    "        writer.add_summary(loss_summ, epoch * model_1.nb_iterations + i)\n",
    "    saver.save(sess, model_1.output_dir, global_step=epoch) \n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "batch_size_test = 20\n",
    "nb_test_points = x_test.shape[0] \n",
    "nb_iterations = nb_test_points//batch_size_test\n",
    "preds_1 = []\n",
    "for i in range(nb_iterations):\n",
    "    input_x_test = x_test[i*batch_size_test: (i+1)*batch_size_test]\n",
    "    preds_test_1 = sess.run(model_1.pred_1, \n",
    "                             feed_dict={model_1.X: input_x_test})\n",
    "    preds_1.append(np.argmax(preds_test_1, axis=1))\n",
    "    if np.mod(nb_test_points, batch_size_test) !=0:\n",
    "        input_x_test = x_test[i*batch_size_test: -1]\n",
    "        preds_test_1= sess.run(model_1.pred_1, \n",
    "                             feed_dict={model_1.X: input_x_test})\n",
    "        preds_1.append(np.argmax(preds_test_1, axis=1))\n",
    "all_preds_1 = np.concatenate(preds_1, axis =0)\n",
    "y_real_1 = np.argmax(y_test_1, axis=1)\n",
    "print(all_preds_1)\n",
    "print(y_real_1)\n",
    "acc_test_1 = np.mean((all_preds_1==y_real_1)*1)\n",
    "print('Test accuracy - task 1 achieved: %.3f' %acc_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now train and test Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Task_2_NN(x_train, y_train_2, './Task2_logdir/', 0.001, 2, 10)            \n",
    "model_2.create_model()     \n",
    "\n",
    "model_2.compute_loss()\n",
    "model_2.optimizer()   \n",
    "\n",
    "model_2.optimizer()\n",
    "init = (tf.global_variables_initializer(),\n",
    "        tf.local_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "summary =tf.Summary()\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "writer = tf.summary.FileWriter(model_2.output_dir)\n",
    "writer.add_graph(sess.graph)\n",
    "if not os.path.exists(model_2.output_dir):\n",
    "    os.makedirs(model_2.output_dir)\n",
    "\n",
    "\"\"\"\n",
    "Train\n",
    "\"\"\"\n",
    "for epoch in range(model_2.nb_epochs):\n",
    "    randomize = np.arange(x_train.shape[0])\n",
    "    np.random.shuffle(randomize)\n",
    "    x_in = model_2.x_train[randomize,:]\n",
    "    y_in_2 = model_2.y_train_2[randomize,:]\n",
    "    for i in range(model_2.nb_iterations):\n",
    "        input_x_train = x_in[i*model_2.batch_size: (i+1)*model_2.batch_size]\n",
    "        input_y_train_2 = y_in_2[i*model_2.batch_size: (i+1)*model_2.batch_size]\n",
    "        _ , preds_2, loss_2, loss_sum = sess.run([model_2.trainer, model_2.pred_2,  model_2.loss_task_2, model_2.loss_sum], \n",
    "                                 feed_dict={model_2.X: input_x_train, \n",
    "                                            model_2.y_2: input_y_train_2})\n",
    "        y_preds_2 = np.argmax(preds_2, axis=1)\n",
    "        y_real_2 = np.argmax(input_y_train_2, axis=1)\n",
    "        acc_train_2 = np.mean((y_preds_2==y_real_2)*1)\n",
    "        print('Epoch %d, Iteration %d, loss_2 %.3f, batch accuracy_2 %.3f' %(epoch, i, loss_2,acc_train_2))\n",
    "        writer.add_summary(loss_sum, epoch * model_2.nb_iterations + i)\n",
    "    saver.save(sess, model_2.output_dir, global_step=epoch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test\n",
    "\"\"\"\n",
    "batch_size_test = 20\n",
    "nb_test_points = x_test.shape[0]\n",
    "nb_iterations = nb_test_points//batch_size_test\n",
    "preds_2 = []\n",
    "for i in range(nb_iterations):\n",
    "    input_x_test = x_test[i*batch_size_test: (i+1)*batch_size_test]\n",
    "    preds_test_2 = sess.run(model_2.pred_2, \n",
    "                             feed_dict={model_2.X: input_x_test})\n",
    "    preds_2.append(np.argmax(preds_test_2, axis=1))\n",
    "    if np.mod(nb_test_points, batch_size_test) !=0:\n",
    "        input_x_test = x_test[i*batch_size_test: -1]\n",
    "        preds_test_2= sess.run([model_2.pred_2], \n",
    "                             feed_dict={model_2.X: input_x_test})\n",
    "        preds_2.append(np.argmax(preds_test_2, axis=1))\n",
    "all_preds_2 = np.concatenate(preds_2, axis =0)\n",
    "y_real_2 = np.argmax(y_test_2, axis=1)\n",
    "acc_test_2 = np.mean((all_preds_2==y_real_2)*1)\n",
    "\n",
    "print('Test accuracy - task 2 achieved: %.3f' %acc_test_2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6.2 - Building a MTL Network\n",
    "\n",
    "In this question, we wish for you to complete the MTL class below and use it to train and test a MTL model on the two MNIST fashion tasks. \n",
    "\n",
    "Similar to Questions 3 and 4, our MTL class is initiliased via\n",
    " - x_train, the training matrix\n",
    " - y_train_1, the fashion labels for task 1 (Fashion Item  classification)\n",
    " - y_train_2, the labels for task 2 (Fashion Group classification)\n",
    " - $\\lambda \\in [0,1]$ , lambda_, the loss weight for task 1 (1- $\\lambda$) is the loss weight for task 2\n",
    " - output_dir, the directory where model parameters and tensorbaord event files will be stored. \n",
    " - lr, the learning rate of the ADAM optimiser \n",
    " - nb_epochs, the number of epochs to use\n",
    " - batch_size, the number of data points in each mini-batch\n",
    "\n",
    "Our MTL architecture will be comprised of a shared CNN backbone of three convolutional layers and a single shared dense layer with pooling between the first two pairs of convolutions.  The output of the shared dense layer is passed to two series of task specific dense layers, one for each of the two tasks. \n",
    "\n",
    "The architecture is as follows:\n",
    " - Shared Convolutional layers $[32, 64, 128]$ with max pooling after the first and second conv layers\n",
    "     - kernel size ($ 3 \\times 3$) for conv and ($2 \\times 2$) for max pool\n",
    "     - stride 1 for conv and 2 for max pooling\n",
    " - Flatten \n",
    " - Shared Dense Layer $[3136]$ - the outputs of which are passed to the two task dense layers\n",
    " - Task 1 Dense Layers $[1024, 100, 10]$ - 10 is the dimenson of the logits/preds\n",
    " - Task 2 Dense Layers $[1024, 100, 3]$ - 3 is the dimenson of the logits/preds \n",
    " - Task 1 Activation Layer - as earlier we use softmax\n",
    " - Task 2 Activation Layer  - as earlier we use softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This architecture is illustrated in the figure below minus the flattening layer.\n",
    "\n",
    "\n",
    "<img src=\"mtl_2.jpg\" alt=\"The MTL network\" title=\"MTL Architecture\" />\n",
    "\n",
    " \n",
    " The function 'create_model' defines the class variables:\n",
    "  - self.logits_1 $\\in \\mathbb{R^{10}}$ containing the output without activation of the last <font color='red'>fully connected layer</font> of the Task 1 task layers. \n",
    "  - self.logits_2 $\\in \\mathbb{R^{3}}$ containing the output without activation of the last <font color='red'>fully connected layer</font> of the Task 2 task layers\n",
    "  - self.preds_1 $\\in \\mathbb{R^{10}}$ containing posterior probabilities for the first task.\n",
    "  - self.preds_2 $\\in \\mathbb{R^{3}}$ containing posterior probabilities for the second task.\n",
    "  \n",
    "As above, use self.logits to complete the method 'compute_loss' that takes the labels and the predicted logits to return the corresponfing cross-entropy loss albeit for each task. \n",
    "\n",
    "The total loss which is a sum of the weighted losses from tasks 1 and 2 ($\\lambda * L_1 + (1-\\lambda) * L_2$) is passed to the optimiser. \n",
    "\n",
    "#### For this question set $\\lambda$ to be 0.5 for equal weighting. \n",
    "\n",
    " #### Note: Do not worry about the optimiser - we still only need one optimiser for joint training of the MTL network \n",
    "      - The tasks can be trained alternately but this has its drawbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTL:\n",
    "    def __init__(self, x_train, y_train_1, y_train_2, lambda_, output_dir, lr=0.001, nb_epochs=10, batch_size=50):\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.nb_images, self.edge, _, _ = x_train.shape\n",
    "        self.nb_iterations = self.nb_images // batch_size\n",
    "        self.output_dir = output_dir\n",
    "        self.x_train = x_train\n",
    "        self.y_train_1 = y_train_1\n",
    "        self.y_train_2 = y_train_2\n",
    "        self.lambda_ = lambda_\n",
    "        \n",
    "        self.m = x_train.shape[0]\n",
    "        self.n_output_1 = y_train_1.shape[1]\n",
    "        self.n_output_2 = y_train_2.shape[1]\n",
    "        \n",
    "        self.X = tf.placeholder(tf.float32, (None, 28, 28, 1), \"X\")\n",
    "        self.y_1 = tf.placeholder(tf.float32, (None, self.n_output_1), \"y_1\")\n",
    "        self.y_2 = tf.placeholder(tf.float32, (None, self.n_output_2), \"y_2\")\n",
    "\n",
    "    \n",
    "    def create_model(self):            \n",
    "        with tf.variable_scope(\"MTL\", reuse=tf.AUTO_REUSE):\n",
    "            \n",
    "            ### Complete the function #####\n",
    "            \n",
    "            self.logits_1 = \n",
    "            self.pred_1 = \n",
    "            \n",
    "            self.logits_2 = \n",
    "            self.pred_2 = \n",
    "        \n",
    "    def compute_loss(self):\n",
    "        with tf.variable_scope('loss'):\n",
    "            ######### Complete the function ######### \n",
    "            self.loss_task_1 =\n",
    "\n",
    "            self.loss_task_2 = \n",
    "\n",
    "            self.loss_total = self.lambda_*self.loss_task_1 + (1-self.lambda_)*self.loss_task_2 \n",
    "            #########################################\n",
    "            self.loss_task_1_graph = tf.summary.scalar(\"softmax_loss_task_1\", self.loss_task_1) \n",
    "            self.loss_task_2_graph = tf.summary.scalar(\"softmax_loss_task_2\", self.loss_task_2)             \n",
    "            self.loss_sum = tf.summary.scalar(\"softmax_loss\", self.loss_total) \n",
    "            \n",
    "                \n",
    "                \n",
    "    def optimizer(self):\n",
    "        with tf.variable_scope('optimizer', reuse=tf.AUTO_REUSE):\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=self.lr, beta1=0.5)\n",
    "            self.model_vars = tf.trainable_variables()\n",
    "            self.trainer = optimizer.minimize(self.loss_total, var_list=self.model_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create model and initialise it and tensorflow session\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "model = MTL(x_train, y_train_1, y_train_2, 0.5, './MTL_logdir/', 0.001, 2, 10)             #       \n",
    "model.create_model()     \n",
    "\n",
    "model.compute_loss()\n",
    "model.optimizer()   \n",
    "\n",
    "model.optimizer()\n",
    "init = (tf.global_variables_initializer(),\n",
    "        tf.local_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "summary =tf.Summary()\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "writer = tf.summary.FileWriter(model.output_dir)\n",
    "writer.add_graph(sess.graph)\n",
    "if not os.path.exists(model.output_dir):\n",
    "    os.makedirs(model.output_dir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now train and test your MTL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(model.nb_epochs):\n",
    "    randomize = np.arange(x_train.shape[0])\n",
    "    np.random.shuffle(randomize)\n",
    "    x_in = model.x_train[randomize,:]\n",
    "    y_in_1 = model.y_train_1[randomize,:]\n",
    "    y_in_2 = model.y_train_2[randomize,:]\n",
    "    for i in range(model.nb_iterations):\n",
    "        input_x_train = x_in[i*model.batch_size: (i+1)*model.batch_size]\n",
    "        input_y_train_1 = y_in_1[i*model.batch_size: (i+1)*model.batch_size]\n",
    "        input_y_train_2 = y_in_2[i*model.batch_size: (i+1)*model.batch_size]\n",
    "        _ , preds_1, preds_2, loss_1, loss_2, loss_summ= sess.run([model.trainer, model.pred_1, model.pred_2, model.loss_task_1, model.loss_task_2, model.loss_sum], \n",
    "                                 feed_dict={model.X: input_x_train, \n",
    "                                            model.y_1: input_y_train_1,\n",
    "                                            model.y_2: input_y_train_2})\n",
    "\n",
    "        y_preds_1 = np.argmax(preds_1, axis=1)\n",
    "        y_preds_2 = np.argmax(preds_2, axis=1)\n",
    "        y_real_1 = np.argmax(input_y_train_1, axis=1)\n",
    "        y_real_2 = np.argmax(input_y_train_2, axis=1)\n",
    "        acc_train_1 = np.mean((y_preds_1==y_real_1)*1)\n",
    "        acc_train_2 = np.mean((y_preds_2==y_real_2)*1)\n",
    "        print('Epoch %d, Iteration %d, loss_1 %.3f, loss_2 %.3f, batch accuracy_1 %.3f, batch accuracy_2 %.3f' %(epoch, i, loss_1, loss_2, acc_train_1, acc_train_2))\n",
    "        writer.add_summary(loss_summ, epoch * model.nb_iterations + i)\n",
    "    saver.save(sess, model.output_dir, global_step=epoch) \n",
    "end = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test\n",
    "\"\"\"\n",
    "batch_size_test = 20\n",
    "nb_test_points = x_test.shape[0] \n",
    "nb_iterations = nb_test_points//batch_size_test\n",
    "preds_1 = []\n",
    "preds_2 = []\n",
    "for i in range(nb_iterations):\n",
    "    input_x_test = x_test[i*batch_size_test: (i+1)*batch_size_test]\n",
    "    preds_test_1, preds_test_2 = sess.run([model.pred_1, model.pred_2], \n",
    "                             feed_dict={model.X: input_x_test})\n",
    "    preds_1.append(np.argmax(preds_test_1, axis=1))\n",
    "    preds_2.append(np.argmax(preds_test_2, axis=1))\n",
    "    if np.mod(nb_test_points, batch_size_test) !=0:\n",
    "        input_x_test = x_test[i*batch_size_test: -1]\n",
    "        preds_test_1, preds_test_2 = sess.run([model.pred_1, model.pred_2], \n",
    "                             feed_dict={model.X: input_x_test})\n",
    "        preds_1.append(np.argmax(preds_test_1, axis=1))\n",
    "        preds_2.append(np.argmax(preds_test_2, axis=1))\n",
    "all_preds_1 = np.concatenate(preds_1, axis =0)\n",
    "all_preds_2 = np.concatenate(preds_2, axis =0)\n",
    "y_real_1 = np.argmax(y_test_1, axis=1)\n",
    "y_real_2 = np.argmax(y_test_2, axis=1)\n",
    "acc_test_1 = np.mean((all_preds_1==y_real_1)*1)\n",
    "acc_test_2 = np.mean((all_preds_2==y_real_2)*1)\n",
    "print('Test accuracy - task 1 achieved: %.3f' %acc_test_1)\n",
    "print('Test accuracy - task 2 achieved: %.3f' %acc_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discuss the performance of the MTL network compared to the single task networks. What do think are the most important things to consider when using MTL?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 6.3\n",
    "\n",
    "In this task we want you to compare the MTL's results for different values of $\\lambda$. We want you to coampre $5$ different values of $\\lambda$ with the stipulation that two of them must be $0$ and $1$; the other 3 are up to you. All other hyperparameters (e.g. number of dense shared layers) can be left as they were in Task 6.2. \n",
    "\n",
    "Plot a graph showing the Task 1 and Task 2 accuracies against values of $\\lambda$. \n",
    "Comment on your results. \n",
    "Whats so special about the cases of $\\lambda = 0$ and $\\lambda = 1$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task 6.4\n",
    "\n",
    "##### Similar to tasks  3.2 and 4.2\n",
    "\n",
    " - Plot a graph showing complexity (number of paramters) vs. accuracy for each of the to tasks in the MTL network. As above you will need to train four other additional MTL networks where you vary the number/size of the shared and  task specific layers (we advise not making the layers too large or too numerous to avoid very long training times). \n",
    " - You should also include plots of the number of parameters vs accuracy for the individual task 1 and 2 networks - use different colours to distinguish these single task networks.\n",
    "     - Note 1 : There is no need to train additional Task 1 and Task 2 networks simply use the formats from Question 6.1\n",
    "     - Note 2: For all MTL formats set $\\lambda$ to $0.5$ for equal weighting\n",
    "     - Note 3: Due to the sub task structure, we will ignore depth in this evaluation as the two tasks can have different depth levels in the MTL architecture. \n",
    "     - Note 4: It is advised to include pooling layers (we leave the type of pooling up to you but recommned maxpooling) for the sake of training time - alternativly use larger strides. \n",
    " \n",
    " - Discuss the effect of the number/size of the shared and task specific layers in terms of performance and training/testing times. Also compare the performance to the task specific networks from 6.1. \n",
    " \n",
    " - Discuss the main pros and cons for multi-task learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Denoising Auto-Encoder (10 points)\n",
    "\n",
    "While CNNs make very good classifiers, they can also be used for many various tasks such as regression, image generation, image reconstruction and so on. In this part of the coursework you should implement a fully convolutional de-noising auto-encoder, i.e. a network that takes a noisy image as input and outputs the corresponding cleaned output. In this exercise we will introduce a gaussian noise on each input. Our goal is to recover the original noiseless images in the output. We will be using the MNIST dataset here.\n",
    "\n",
    "Similarly as before we will define the class DAE, and you will need to complete the method 'create_model' and 'compute_loss' accordingly. \n",
    "\n",
    "Using the functions tf.layers.conv2d and tf.layers.conv2d_transpose complete the method 'create_model' in the class DAE below. \n",
    "\n",
    "conv2d should be used for the encoding part while conv2d_transpose should be used for the decoding part. \n",
    "We will use ReLu as the non linear activation for the hidden layers and tanh as the activation for the output layer. \n",
    "The network architecture is as follows:\n",
    "\n",
    "+ Encoding part: a series of conv2d layers with [32, 64, 128] filters of size 4\\times4, a stride of 1 in the first layer and a stride of 2 for the second and third layers.  \n",
    "+ Decodind part: a series of two conv2d_transpose followed by one, one strided conv2d with [64,32,1] filters of size 4\\times4. \n",
    "\n",
    "The output dimension of the final layer should match the input dimension [batch_size, 28, 28]. If necesseray use the argument padding or the function tf.pad to make the input and ouput dimensions match. \n",
    "\n",
    "Complete the method compute_loss. Note that we don't have a classification problem anymore but a regression problem consisting of reconstructing the noiseless version of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAE:\n",
    "    def __init__(self, x_train, output_dir, lr=0.001, nb_epochs=10, batch_size=50):\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.nb_images, self.edge, _ = x_train.shape\n",
    "        self.nb_iterations = self.nb_images // batch_size\n",
    "        self.output_dir = output_dir\n",
    "        self.im = tf.placeholder(tf.float32, [None, 28, 28,1])\n",
    "        self.im_n = self.im + tf.random_normal(tf.shape(self.im), mean=0, stddev=1) #inject noise\n",
    "        self.x_train = x_train\n",
    "        \n",
    "    def create_model(self):\n",
    "        with tf.variable_scope('DAE', reuse=tf.AUTO_REUSE):\n",
    "            ######### Complete the function ######### \n",
    "            self.recon_im = \n",
    "            #########################################\n",
    "            \n",
    "            tf.summary.image('denoising', tf.concat([self.im_n, self.recon_im], axis=2)\n",
    "    \n",
    "    def compute_loss(self):\n",
    "        with tf.variable_scope('loss'):\n",
    "            ######### Complete the function ######### \n",
    "            self.loss\n",
    "            #########################################\n",
    "            self.loss_summ = tf.summary.scalar(\"reconstruction_loss\", self.loss)\n",
    "                             \n",
    "    def optimizer(self):\n",
    "        with tf.variable_scope('optimizer'):\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=self.lr, beta1=0.5)\n",
    "            self.model_vars = tf.trainable_variables()\n",
    "            self.trainer = optimizer.minimize(self.loss, var_list=self.model_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DAE(x_train, './DAE_logdir/', 0.001, 2, 10)\n",
    "model.create_model()\n",
    "model.compute_loss()\n",
    "model.optimizer()\n",
    "init = (tf.global_variables_initializer(),\n",
    "        tf.local_variables_initializer())\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "summary =tf.Summary()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "writer = tf.summary.FileWriter(model.output_dir)\n",
    "writer.add_graph(sess.graph)\n",
    "if not os.path.exists(model.output_dir):\n",
    "    os.makedirs(model.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the previous questions, train the DAE by looping over all the mini-batches. For proper training you should input enough noisy versions per image. \n",
    "- Plot the training/validation curves and discuss why your trained model is not under/over fitting.\n",
    "When the training is finished, inject noise into the test data and reconstruct them through a forward pass. For each test image, input 20 noisy versions of it and compute the average accuracies. \n",
    "\n",
    "- Test the robustness of the trained network to different levels of noise, demonstrate the results (figure or Table) and discuss them in your report. \n",
    "- Why this architecture is able to remove noise from data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8 - Building a Variational AutoEncoder (VAE) 12 Points\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Why use a VAE?\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style='text-align: justify;'>\n",
    "Building on the standard AutoEncoder which was a way of learning some lower dimensional manifold the data could lie on, we want to impose a form of regularisation, that is, we want some topology structure. We want inputs to the AutoEncoder that have a certain structure to be mapped to similar areas in this lower dimensional latent space. But the standard AutoEncoder merely learns how to essentially compress data. In this task, we are interested in learning a more structured latent space where we can sample in this space to then generate a new image that theoretically belongs to the same dataset.\n",
    "    \n",
    "In this exercise, we will assume the structure in the latent space follows a standard bi-variate Gaussian i.e. mean $\\begin{bmatrix}0\\\\0\\end{bmatrix}$ and covariance $\\begin{bmatrix}1&0\\\\0&1\\end{bmatrix}$. This assumption is for simplicity but we can infact assume other distributions (outside the scope for this exercise). We will be using the MNIST dataset for this task.\n",
    "    \n",
    "</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Architecture\n",
    "\n",
    "<img src=\"vae-diagram.png\" alt=\"The Variational AutoEncoder\" title=\"VAE Architecture\" />\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Notation\n",
    "\n",
    "<br>\n",
    "\n",
    "Before diving into some maths, lets define a few terms:\n",
    "1. $\\mathbf{X}$: the dataset distribution we wish to generate from\n",
    "2. $\\mathbf{z}$: the compressed latent variable which quantifies a set of attributes of our dataset\n",
    "3. $\\boldsymbol{\\theta}$ : the parameters for the ***encoder*** network\n",
    "4. $\\boldsymbol{\\phi}$: the parameters for the ***decoder*** network\n",
    "5. $p(\\mathbf{z})$: the probability of the compressed latent space (given it should follow a standard normal)\n",
    "6. $q_{\\boldsymbol{\\phi}}(\\mathbf{z}|\\mathbf{X})$: the conditional probability distribution of sampling the compressed latent variable given the dataset approximated by our encoder network with parameters $\\boldsymbol{\\phi}$\n",
    "7. $p_{\\boldsymbol{\\theta}}(\\mathbf{X}|\\mathbf{z})$: the conditional probability distribution of generating the dataset given the compressed latent space by our decoder network with parameters $\\boldsymbol{\\theta}$\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Optimisation\n",
    "\n",
    "<br>\n",
    "\n",
    "The quantity we are interested in maximising for the $i$-th observation is:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "    \\log p (\\mathbf{x}_i) && \\text{which can be rewritten as...}\\\\\n",
    "    &= \\int_{\\mathbf{z}\\in\\mathcal{Z}} q_{\\boldsymbol{\\phi}}(\\mathbf{z}|\\mathbf{x}_i) \\log p (\\mathbf{x}_i) \\text{d}\\mathbf{z} & \\text{as the integral over a distribution is 1...}\\\\\n",
    "    &= \\int_{\\mathbf{z}\\in\\mathcal{Z}} q_{\\boldsymbol{\\phi}}(\\mathbf{z}|\\mathbf{x}_i)[\\log p (\\mathbf{z}|\\mathbf{x}_i) - \\log p(\\mathbf{z}) + \\log p_\\boldsymbol{\\theta}(\\mathbf{x}_i|\\mathbf{z})]\\text{d}\\mathbf{z} & \\text{consider Baye's rule...}\\\\\n",
    "    &= \\int_{\\mathbf{z}\\in\\mathcal{Z}} q_{\\boldsymbol{\\phi}}(\\mathbf{z}|\\mathbf{x}_i) \\log \\frac{p (\\mathbf{z}|\\mathbf{x}_i)}{q_{\\boldsymbol{\\phi}} (\\mathbf{z}|\\mathbf{x}_i)} - q_{\\boldsymbol{\\phi}}(\\mathbf{z}|\\mathbf{x}_i)\\log \\frac{p (\\mathbf{z})}{q_{\\boldsymbol{\\phi}} (\\mathbf{z}|\\mathbf{x}_i)} + q_{\\boldsymbol{\\phi}}(\\mathbf{z}|\\mathbf{x}_i) \\log p_\\boldsymbol{\\theta}(\\mathbf{x}_i|\\mathbf{z})\\text{d}\\mathbf{z}\\\\\n",
    "    &= \\text{D}_{\\text{KL}}(q_{\\boldsymbol{\\phi}}(\\mathbf{z}|\\mathbf{x}_i) || p (\\mathbf{z}|\\mathbf{x}_i)) - \\text{D}_{\\text{KL}}(q_{\\boldsymbol{\\phi}}(\\mathbf{z}|\\mathbf{x}_i) || p (\\mathbf{z})) + \\mathbb{E}_{q_{\\boldsymbol{\\phi}} (\\mathbf{z}|\\mathbf{x}_i)} [\\log p_{\\boldsymbol{\\theta}} (\\mathbf{x}_i|\\mathbf{z})]\\\\\n",
    "    &=  \\text{D}_{\\text{KL}}(q_{\\boldsymbol{\\phi}}(\\mathbf{z}|\\mathbf{x}_i) || p (\\mathbf{z}|\\mathbf{x}_i)) + \\mathcal{L}(\\boldsymbol{\\theta}, \\boldsymbol{\\phi}; \\mathbf{x}_i) &\\text{where the last two terms have been grouped as $\\mathcal{L}$}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "As the first term in the line above is intractable to compute, we can say that $\\log p_\\boldsymbol{\\theta} (\\mathbf{x}_i) \\ge \\mathcal{L}(\\boldsymbol{\\theta}, \\boldsymbol{\\phi}; \\mathbf{x}_i)$ as the KL-divergence is a distance measure (and hence non-negative) and $\\mathcal{L}(\\boldsymbol{\\theta}, \\boldsymbol{\\phi}; \\mathbf{x}_i)$ is known as the **variational lower bound**. Instead of maximising the log probability directly, we can instead maximise this lower bound! If you are unfamiliar with the KL-divergence, check out this [Wikipedia](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence).\n",
    "\n",
    "<br>\n",
    "\n",
    "The lower bound can be clearly seen as two main components:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\mathcal{L}(\\boldsymbol{\\theta}, \\boldsymbol{\\phi}; \\mathbf{x}_i) = \\color{blue}{\\mathbb{E}_{q_{\\boldsymbol{\\phi}} (\\mathbf{z}|\\mathbf{x}_i)} [\\log p_{\\boldsymbol{\\theta}} (\\mathbf{x}_i|\\mathbf{z})]} - \\color{green}{\\text{D}_{\\text{KL}}(q_{\\boldsymbol{\\phi}}(\\mathbf{z}|\\mathbf{x}_i) || p (\\mathbf{z}))}\n",
    "\\end{align}\n",
    "$\n",
    "+ <font color='blue'> How well can we reconstruct our original data from the latent space?</font>\n",
    "+ <font color='green'> How similar is the latent space to a standard Gaussian?</font>\n",
    "\n",
    "A remark on the second point - we are trying to find a Gaussian distribution manifold in latent space for our dataset. This is known as a *variational* method which should be part of the Bayesian Machine Learning module.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Derivations\n",
    "\n",
    "Given that $\\mathbf{\\hat{x}}_i$ is a draw from $p_{\\boldsymbol{\\theta}} (\\mathbf{x}_i|\\mathbf{z})\\sim\\mathcal{N}(\\mathbf{x},\\sigma^2\\mathbf{I})$, the expectation of $\\log p_{\\boldsymbol{\\theta}} (\\mathbf{x}_i|\\mathbf{z})$ can be computed as:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\mathbb{E}_{q_{\\boldsymbol{\\phi}} (\\mathbf{z}|\\mathbf{x}_i)} [\\log p_{\\boldsymbol{\\theta}} (\\mathbf{x}_i|\\mathbf{z})] &= -\\frac{m}{2}\\log 2\\pi\\sigma^2 - \\frac{1}{2}(\\mathbf{\\hat{x}}_i - \\mathbf{x}_i)^\\text{T}(\\sigma^2\\mathbf{I})^{-1}(\\mathbf{\\hat{x}}_i - \\mathbf{x}_i)\\\\\n",
    "\\mathbb{E}_{q_{\\boldsymbol{\\phi}} (\\mathbf{Z}|\\mathbf{X})} [\\log p_{\\boldsymbol{\\theta}} (\\mathbf{X}|\\mathbf{Z})] &\\propto \\sum_{i = 1}^{i = n}\\sum_{j = 1}^{j = m} (\\hat{x}_{ij} - x_{ij})^2 & \\text{as everything else is just a constant}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "<font color='red'>Given that $q_{\\boldsymbol{\\phi}} (\\mathbf{z}|\\mathbf{x}_i) \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\sigma}^2\\mathbf{I})$, derive the KL-divergence term between this and $p_\\boldsymbol{\\theta} (\\mathbf{z})$ i.e. $\\text{D}_{\\text{KL}} (\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\sigma}^2\\mathbf{I}), \\mathcal{N}(0, \\mathbf{I}))$:</font>\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\text{D}_{\\text{KL}} (\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\sigma}^2\\mathbf{I}), \\mathcal{N}(0, \\mathbf{I})) &= \\int_{\\mathbf{z}\\in\\mathcal{Z}} ?\\text{ d}\\mathbf{z}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "Further readings: There are many useful online tutorials that provide deep insight as how VAEs work or to implement them; for instace [tutorial1](https://arxiv.org/abs/1606.05908) [tutorial2](http://ruishu.io/2018/03/14/vae/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the Data and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "\n",
    "image_size       = x_train.shape[1]\n",
    "original_dim     = image_size * image_size\n",
    "\n",
    "# Flatten each image to be a vector (you can try convolutional layers as an extension)\n",
    "x_train          = np.reshape(x_train, [-1, original_dim])\n",
    "x_test           = np.reshape(x_test, [-1, original_dim])\n",
    "x_train          = x_train.astype('float32') / 255\n",
    "x_test           = x_test.astype('float32') / 255\n",
    "\n",
    "# Visualisation parameters (for after the implementation of the VAE - start playing with these after the VAE seems to work!)\n",
    "n                = 29 # Number of digits to show per row / col\n",
    "dsize            = 28 # Digit size\n",
    "\n",
    "z1               = norm.ppf(np.linspace(0.01, 0.99, n))\n",
    "z2               = norm.ppf(np.linspace(0.01, 0.99, n))\n",
    "z_grid           = np.dstack(np.meshgrid(z1, z2))\n",
    "\n",
    "Zf               = lambda x : sess.run(z_mean, feed_dict = {t_X : x})\n",
    "Xf               = lambda z_grid : sess.run(t_X_hat, feed_dict = {z : z_grid.reshape(n * n, nlatent)}).reshape(n, n, dsize, dsize)\n",
    "\n",
    "def get_batch(*args, size):\n",
    "    \"\"\" Loops through each argument in batches of [size] \"\"\"\n",
    "    \n",
    "    n = len(args[0])\n",
    "    if size is None or size >= n:\n",
    "        yield from args\n",
    "        return None\n",
    "    r = np.random.permutation(n)\n",
    "    for i in range(n // size + 1):\n",
    "        yield (arg[r[i * size : (i + 1) * size]] for arg in args)\n",
    "        \n",
    "def visualise(X, y, sep = 2):\n",
    "     \"\"\" Visualise the mapped 2D manifold \"\"\"\n",
    "    # Feel free to modify this code for your visualisations...\n",
    "    \n",
    "    Z  = Zf(x_test)\n",
    "    Xh = Xf(z_grid)\n",
    "    \n",
    "    plt.figure(figsize = (12, 10))\n",
    "    plt.scatter(Z[:, 0], Z[:, 1], c = y)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    \n",
    "    plt.figure(figsize = (12, 10))\n",
    "    plt.imshow(np.block(list(map(list, Xh))), cmap = 'gray')\n",
    "    start_range    = dsize // 2\n",
    "    end_range      = n * dsize + start_range\n",
    "    pixel_range    = np.arange(start_range, end_range, dsize)\n",
    "    sample_range_x = np.round(z1, 2)\n",
    "    sample_range_y = np.round(z2, 2)\n",
    "    plt.xticks(pixel_range[::sep], sample_range_x[::sep])\n",
    "    plt.yticks(pixel_range[::sep], sample_range_y[::sep])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 8.1 Implementation of VAE\n",
    "\n",
    "<br>\n",
    "\n",
    "The simpler implementation of the VAE is to build off the MLP i.e. no convolutional layers. The code below is designed for this but feel free to swap out this assumption for convolutions should you feel more confident. Feel free to add `tf.summary` definitions in a similar way to previous tasks for tensorboard visualisations.\n",
    "\n",
    " #### Note: If implementing task 8.1 in TF (as guided bellow) is not straightforward for you, use an easier option: [Keras](https://keras.io/examples/variational_autoencoder/) implementation of VAE. In these case, you will be marked down 4 points but you can immediately proceed to task 8.2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters...\n",
    "layers   = [512, 256, 128]\n",
    "nlatent  = 2\n",
    "batch    = 64\n",
    "epochs   = 20\n",
    "alpha    = 1e-3\n",
    "\n",
    "# General dtype to use\n",
    "dtype    = 'float32'\n",
    "\n",
    "# Number of features\n",
    "m        = x_train.shape[1]\n",
    "\n",
    "# Reset the graph to ensure blank graph initially...\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Define placeholder for 'X' data\n",
    "t_X      = tf.placeholder(dtype = dtype, shape = [None, m], name = 'X')\n",
    "\n",
    "# Define how t_X maps to the layer before the latent space\n",
    "with tf.name_scope('Encoder'):\n",
    "    h        = t_X\n",
    "    for i, layer in enumerate(layers, 1):\n",
    "        with tf.name_scope(f'Layer_{i}'):\n",
    "            ######### Map how we get from the previous layer to the next hidden layer #########\n",
    "            h    = \n",
    "    \n",
    "# Define how we get the mean and variance from the previous hidden layer\n",
    "with tf.name_scope('Latent'):\n",
    "    with tf.name_scope('Mean'):\n",
    "        z_mean   = \n",
    "\n",
    "    with tf.name_scope('Variance'):\n",
    "        z_var    = \n",
    "        \n",
    "    # Code the \"reparameterisation trick\"\n",
    "    with tf.name_scope('Sample'):\n",
    "        epsilon  = \n",
    "        z_sample = \n",
    "        z        = tf.placeholder_with_default(z_sample, shape = [None, nlatent], name = 'z')\n",
    "    \n",
    "# Define how \"z\" decodes to our reconstructed \"t_X\" estimate\n",
    "with tf.name_scope('Decoder'):\n",
    "    h        = z\n",
    "    for i, layer in enumerate(layers[::-1], 1):\n",
    "        with tf.name_scope(f'Layer_{i}'):\n",
    "            h    = \n",
    "    \n",
    "    with tf.name_scope('Final'):\n",
    "        t_X_hat  = \n",
    "\n",
    "# Define the loss function as defined in the derivation section\n",
    "with tf.name_scope('Loss'):\n",
    "    with tf.name_scope('AutoEncoder'):\n",
    "        # The normal AutoEncoder loss should measure how far our t_X_hat is from t_X\n",
    "        loss_ae  = \n",
    "        \n",
    "    with tf.name_scope('KL_Divergence'):\n",
    "        # The KL-divergence between z and a standard normal you derived earlier\n",
    "        loss_kl  = \n",
    "        \n",
    "    loss = tf.reduce_mean(loss_ae + loss_kl, name = 'loss')\n",
    "\n",
    "# Define final components before training the model\n",
    "optim    = tf.train.AdamOptimizer(alpha).minimize(loss)\n",
    "train    = {t_X : x_train}\n",
    "\n",
    "sess     = tf.InteractiveSession()\n",
    "writer   = tf.summary.FileWriter('./VAE_MLP_logdir', sess.graph)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Gradient descent loop with verbose loss check...\n",
    "# Hopefully we see our loss reduce!\n",
    "for i in range(epochs):\n",
    "    losses  = []\n",
    "    for xb, in get_batch(x_train, size = batch):\n",
    "        nb = len(xb)\n",
    "        sess.run(optim, feed_dict = {t_X : xb})\n",
    "        losses.append(nb * sess.run(loss, feed_dict = {t_X : xb}))\n",
    "        print(f'\\rIteration {i:2d}: loss = {losses[-1] / nb:6,.2f}', end = '')\n",
    "    print(f'\\rIteration {i:2d}: loss = {sum(losses) / len(x_train):6,.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task 8.2\n",
    "\n",
    "<br>\n",
    "\n",
    " - Plot the learning curve for your VAE\n",
    " - Generate new handwritten digits from your model by sampling `Z` = $\\mathbf{z}\\in\\mathbb{R}^{n,2}$ and running `sess.run(t_X_hat, feed_dict = {z : Z))` in a separate code cell\n",
    "     - Discuss how good / bad are these images?\n",
    "         - Why are they good / bad? (consider the assumptions of your implementation of the VAE)\n",
    " - From observing your learnt manifold (by using the `visualise` function or otherwise), draw a comparison between the direct mapped points on your manifold (scatter plot) and the images that lay on the manifold (imshow)\n",
    "     - Why are some points images more mixed than others?\n",
    "     - Can we be smarter in where we should sample to get *better* generated handwritten digits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
